{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80aaadf9",
   "metadata": {},
   "source": [
    "# 2. Optimisation demostration \n",
    "\n",
    "This notebook demostrates optimisation functionality. It covers:\n",
    "\n",
    "2.1 Optimization Problem Setup\n",
    "- Understand objective functions and constraints\n",
    "- Configure optimization parameters\n",
    "\n",
    "2.2 Single Optimization Run\n",
    "- Configure PSO algorithm\n",
    "- Run optimization with monitoring\n",
    "- Analyze results and constraint violations\n",
    "\n",
    "2.3 Multi-Run Analysis\n",
    "- Statistical robustness testing\n",
    "- Algorithm parameter sensitivity\n",
    "- Convergence analysis\n",
    "\n",
    "2.4 Advanced Scenarios\n",
    "- Multiple constraint types\n",
    "- Different objective functions\n",
    "- Parameter tuning strategies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "\n",
    "# Add src to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(\"=== TRANSIT OPTIMIZATION SETUP ===\")\n",
    "print(\"üöÄ Starting self-contained optimization workflow\")\n",
    "print(\"üìä This notebook will prepare data from scratch and run PSO optimization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44008cd3",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "## 2.1 Data Preparation and Problem Setup\n",
    "\n",
    "### GTFS Data Loading\n",
    "\n",
    "First, we'll load the GTFS feed and transform it into optimization data structure.\n",
    "This replicates the key steps from notebook 1 but focuses only on what's needed for optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d99ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transit_opt.preprocessing.prepare_gtfs import GTFSDataPreparator\n",
    "\n",
    "print(\"=== LOADING GTFS DATA ===\")\n",
    "\n",
    "# Create GTFS preparator with same settings as notebook 1\n",
    "preparator = GTFSDataPreparator(\n",
    "    gtfs_path='../data/external/study_area_gtfs_bus.zip',\n",
    "    interval_hours=3,  # 8 periods per day\n",
    "    date=None,  # Use full GTFS feed\n",
    "    turnaround_buffer=1.15,  # 15% buffer\n",
    "    max_round_trip_minutes=240.0,  # Maximum round-trip time\n",
    "    no_service_threshold_minutes=480.0,  # Threshold for no-service mapping\n",
    "    log_level=\"INFO\"  # Less verbose than notebook 1\n",
    ")\n",
    "\n",
    "# Define allowed headways for optimization\n",
    "allowed_headways = [5, 10, 15, 30, 60, 90, 120]\n",
    "\n",
    "print(f\"üìã Allowed headways: {allowed_headways} minutes\")\n",
    "print(\"üîÑ Extracting optimization data...\")\n",
    "\n",
    "# Extract optimization data structure\n",
    "opt_data = preparator.extract_optimization_data(allowed_headways)\n",
    "\n",
    "print(f\"\\n‚úÖ GTFS DATA PROCESSED:\")\n",
    "print(f\"   üìä Routes: {opt_data['n_routes']}\")\n",
    "print(f\"   ‚è∞ Time intervals: {opt_data['n_intervals']} (3h each)\")\n",
    "print(f\"   üéØ Decision variables: {opt_data['decision_matrix_shape'][0]} √ó {opt_data['decision_matrix_shape'][1]} = {np.prod(opt_data['decision_matrix_shape'])}\")\n",
    "print(f\"   üöó Current peak fleet: {opt_data['constraints']['fleet_analysis']['total_current_fleet_peak']} vehicles\")\n",
    "print(f\"   üî¢ Headway choices: {opt_data['n_choices']} (including no-service)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa85ca5",
   "metadata": {},
   "source": [
    "\n",
    "### Spatial Boundary Setup\n",
    "\n",
    "Load the study area boundary for spatial filtering and analysis.\n",
    "This ensures optimization focuses on the relevant geographic area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec69b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transit_opt.optimisation.spatial.boundaries import StudyAreaBoundary\n",
    "\n",
    "print(\"\\n=== SPATIAL BOUNDARY SETUP ===\")\n",
    "\n",
    "# Load boundary geometry\n",
    "boundary_gdf = gpd.read_file(\"../data/external/boundaries/study_area_boundary.geojson\")\n",
    "print(f\"üìç Loaded boundary with {len(boundary_gdf)} feature(s)\")\n",
    "\n",
    "# Create study area boundary with buffer\n",
    "study_boundary = StudyAreaBoundary(\n",
    "    boundary_gdf=boundary_gdf,\n",
    "    crs=\"EPSG:3857\",  # Web Mercator for spatial analysis\n",
    "    buffer_km=2.0     # 2km buffer around boundary\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Study area boundary created:\")\n",
    "print(f\"   üìê CRS: {study_boundary.target_crs}\")\n",
    "print(f\"   üìè Buffer: 2km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb484783",
   "metadata": {},
   "source": [
    "### Optimization Problem Structure\n",
    "\n",
    "Before diving into objectives and constraints, let's understand the mathematical structure\n",
    "of our transit optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4088dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== OPTIMIZATION PROBLEM STRUCTURE ===\")\n",
    "print(\"üî¢ DECISION VARIABLES:\")\n",
    "print(f\"   ‚Ä¢ Each route-interval combination = 1 optimization variable\")\n",
    "print(f\"   ‚Ä¢ Matrix structure: {opt_data['decision_matrix_shape']} (routes √ó intervals)\")\n",
    "print(f\"   ‚Ä¢ Total variables: {opt_data['decision_matrix_shape'][0] * opt_data['decision_matrix_shape'][1]}\")\n",
    "print(f\"   ‚Ä¢ Each variable chooses from {opt_data['n_choices']} discrete headway options\")\n",
    "\n",
    "print(f\"\\nüéØ DISCRETE CHOICES:\")\n",
    "print(f\"   ‚Ä¢ Continuous headways (e.g., 17.3 minutes) ‚Üí Discrete choices (e.g., 15 minutes)\")\n",
    "print(f\"   ‚Ä¢ Algorithms choose indices (0-{opt_data['n_choices']-1}) representing allowed headways\")\n",
    "print(f\"   ‚Ä¢ Variable bounds: {opt_data['variable_bounds']} (choice indices)\")\n",
    "\n",
    "print(\"\\nüïê ALLOWED HEADWAYS:\")\n",
    "for i, headway in enumerate(opt_data['allowed_headways']):\n",
    "    if headway >= 9000:\n",
    "        print(f\"   Index {i}: No Service ({headway})\")\n",
    "    else:\n",
    "        print(f\"   Index {i}: {headway:.0f} minutes\")\n",
    "\n",
    "print(\"\\n‚è∞ TIME STRUCTURE:\")\n",
    "for i, (label, hours) in enumerate(zip(opt_data['intervals']['labels'], opt_data['intervals']['hours'])):\n",
    "    print(f\"   Interval {i}: {label} ({hours[0]:02d}:00-{hours[1]:02d}:00)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09306924",
   "metadata": {},
   "source": [
    "### Objective Functions\n",
    "\n",
    "Transit optimization typically involves competing objectives:\n",
    "\n",
    "We'll focus on **Service Coverage** using spatial analysis. TODO: More complex objectives will be added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transit_opt.optimisation.objectives import HexagonalCoverageObjective\n",
    "\n",
    "print(\"\\n=== OBJECTIVE FUNCTION: SERVICE COVERAGE ===\")\n",
    "print(\"Hexagonal Coverage Objective measures spatial equity by:\")\n",
    "print(\"‚Ä¢ Dividing study area into hexagonal zones\")\n",
    "print(\"‚Ä¢ Calculating vehicle service per zone based on headways\")\n",
    "print(\"‚Ä¢ Minimizing variance in service distribution\")\n",
    "print(\"‚Ä¢ Lower variance = more equitable service coverage\")\n",
    "\n",
    "# Create coverage objective with boundary filtering\n",
    "coverage_objective = HexagonalCoverageObjective(\n",
    "    optimization_data=opt_data,\n",
    "    spatial_resolution_km=3.0,\n",
    "    crs=\"EPSG:3857\",\n",
    "    boundary=study_boundary,  # This filters spatial analysis to study area\n",
    "    spatial_lag=True,\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\nüìç Spatial System Created:\")\n",
    "print(f\"   üî∏ Hexagonal zones: {len(coverage_objective.spatial_system.hex_grid)}\")\n",
    "print(f\"   üöè Transit stops (filtered): {len(coverage_objective.spatial_system.stops_gdf)}\")\n",
    "print(f\"   üìê Zone size: ~{3.0} km diameter hexagons\")\n",
    "\n",
    "# Evaluate current service coverage\n",
    "current_objective_value = coverage_objective.evaluate(opt_data['initial_solution'])\n",
    "print(f\"\\nüéØ CURRENT SERVICE COVERAGE:\")\n",
    "print(f\"   Objective value (variance): {current_objective_value:.4f}\")\n",
    "print(f\"   Lower values = more equitable coverage\")\n",
    "\n",
    "# Get detailed analysis of current coverage\n",
    "current_analysis = coverage_objective.get_detailed_analysis(opt_data['initial_solution'])\n",
    "print(f\"   Zones with service: {current_analysis['zones_with_service_average']}\")\n",
    "print(f\"   Mean vehicles per zone: {current_analysis['total_vehicles_average']:.1f}\")\n",
    "print(f\"   Coefficient of variation: {current_analysis['coefficient_of_variation_average']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0477bd",
   "metadata": {},
   "source": [
    "### Constraint Types\n",
    "\n",
    "Optimization constraints ensure solutions are operationally feasible:\n",
    "\n",
    "1. **Fleet Total Constraint**: Limits peak vehicle requirements\n",
    "2. **Fleet Per-Interval**: Limits vehicles needed in each time period  \n",
    "3. **Minimum Service**: Ensures minimum service levels are maintained\n",
    "\n",
    "All constraints work with headway decisions to calculate vehicle requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db167a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transit_opt.optimisation.problems.base import (\n",
    "    FleetTotalConstraintHandler,\n",
    "    FleetPerIntervalConstraintHandler, \n",
    "    MinimumFleetConstraintHandler\n",
    ")\n",
    "\n",
    "print(\"\\n=== CONSTRAINT SYSTEM OVERVIEW ===\")\n",
    "print(\"Constraints ensure optimization produces deployable solutions:\\n\")\n",
    "\n",
    "# Show current fleet analysis\n",
    "current_fleet = opt_data['constraints']['fleet_analysis']\n",
    "print(\"üìä CURRENT FLEET ANALYSIS:\")\n",
    "print(f\"   Peak vehicles needed: {current_fleet['total_current_fleet_peak']}\")\n",
    "print(f\"   Fleet by interval: {current_fleet['current_fleet_by_interval'].tolist()}\")\n",
    "print(f\"   Peak interval: {current_fleet['fleet_stats']['peak_interval']} ({opt_data['intervals']['labels'][current_fleet['fleet_stats']['peak_interval']]})\")\n",
    "\n",
    "print(f\"\\nüîí CONSTRAINT EXAMPLES:\")\n",
    "\n",
    "# Fleet Total Constraint\n",
    "print(\"1. Fleet Total Constraint:\")\n",
    "print(\"   ‚Ä¢ Limits peak vehicles across all time periods\")\n",
    "print(\"   ‚Ä¢ Example: ‚â§ 120% of current peak fleet\")\n",
    "print(f\"   ‚Ä¢ Current peak: {current_fleet['total_current_fleet_peak']} vehicles\")\n",
    "print(f\"   ‚Ä¢ 120% limit: {int(current_fleet['total_current_fleet_peak'] * 1.2)} vehicles\")\n",
    "\n",
    "print(\"\\n2. Fleet Per-Interval Constraint:\")\n",
    "print(\"   ‚Ä¢ Limits vehicles needed in each 3-hour period\")  \n",
    "print(\"   ‚Ä¢ Prevents unrealistic concentration in one time period\")\n",
    "print(\"   ‚Ä¢ Example: ‚â§ 150% of current interval fleet\")\n",
    "\n",
    "print(\"\\n3. Minimum Fleet Constraint:\")\n",
    "print(\"   ‚Ä¢ Ensures minimum service levels are maintained\")\n",
    "print(\"   ‚Ä¢ Prevents optimization from eliminating essential routes\")\n",
    "print(\"   ‚Ä¢ Example: ‚â• 80% of current system-wide service\")\n",
    "\n",
    "# Show service coverage by time interval\n",
    "print(f\"\\nüìä CURRENT SERVICE ACTIVITY:\")\n",
    "for i, label in enumerate(opt_data['intervals']['labels']):\n",
    "    active_routes = np.sum(~np.isnan(opt_data['routes']['current_headways'][:, i]))\n",
    "    coverage_pct = 100 * active_routes / opt_data['n_routes']\n",
    "    fleet_needed = current_fleet['current_fleet_by_interval'][i]\n",
    "    print(f\"   {label}: {active_routes}/{opt_data['n_routes']} routes ({coverage_pct:.0f}%), {fleet_needed:.0f} vehicles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb64b0",
   "metadata": {},
   "source": [
    "### Problem Configuration\n",
    "\n",
    "We'll use the configuration manager system to set up PSO optimization with multiple constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c392a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPTIMIZATION CONFIGURATION ===\n",
      "üéØ PENALTY METHOD vs HARD CONSTRAINTS\n",
      "Choose between two constraint handling approaches:\n",
      "‚Ä¢ Hard Constraints: Reject infeasible solutions completely\n",
      "‚Ä¢ Penalty Method: Add constraint violations to objective (explore infeasible regions)\n",
      "\n",
      "ü§ñ SELECTED: Penalty Method\n",
      "   Algorithm: Particle Swarm Optimization (PSO)\n",
      "   Population size: 50 particles\n",
      "   Max generations: 100\n",
      "   Penalty weights: Budget=2000.0, \n",
      "                   Operational=1000.0, \n",
      "                   Service=5000.0\n",
      "   Adaptive penalties: True\n",
      "   Penalty increase: 1.3x per generation (~497929x after 50 gens)\n",
      "\n",
      "üéØ Objective: Service Coverage (Spatial Equity)\n",
      "   Minimize variance in vehicle distribution across hexagonal zones\n",
      "\n",
      "üîí Constraints: 3 active\n",
      "   1. FleetTotal: 0.2\n",
      "   2. FleetPerInterval: 0.3\n",
      "   3. MinimumFleet: 0.3\n",
      "\n",
      "üìä Constraint Handling Method:\n",
      "   üéØ PENALTY METHOD:\n",
      "   ‚Ä¢ Violations added as penalties to objective function\n",
      "   ‚Ä¢ Allows temporary exploration of infeasible regions\n",
      "   ‚Ä¢ Penalties increase over generations ‚Üí convergence to feasibility\n",
      "   ‚Ä¢ Better exploration, potentially better final solutions\n"
     ]
    }
   ],
   "source": [
    "# Update the configuration cell (around line 294) with penalty method options:\n",
    "\n",
    "print(\"=== OPTIMIZATION CONFIGURATION ===\")\n",
    "print(\"üéØ PENALTY METHOD vs HARD CONSTRAINTS\")\n",
    "print(\"Choose between two constraint handling approaches:\")\n",
    "print(\"‚Ä¢ Hard Constraints: Reject infeasible solutions completely\")\n",
    "print(\"‚Ä¢ Penalty Method: Add constraint violations to objective (explore infeasible regions)\")\n",
    "\n",
    "# Configuration with PENALTY METHOD (recommended for exploration)\n",
    "config_penalty = {\n",
    "    'problem': {\n",
    "        'objective': {\n",
    "            'type': 'HexagonalCoverageObjective',\n",
    "            'spatial_resolution_km': 3.0,\n",
    "            'crs': 'EPSG:3857',\n",
    "            'boundary_file': '../data/external/boundaries/study_area_boundary.geojson',\n",
    "            'boundary_buffer_km': 2.0\n",
    "        },\n",
    "        'constraints': [\n",
    "            {\n",
    "                'type': 'FleetTotalConstraintHandler',\n",
    "                'baseline': 'current_peak',\n",
    "                'tolerance': 0.2,  # 20% increase allowed\n",
    "                'measure': 'peak'\n",
    "            },\n",
    "            {\n",
    "                'type': 'FleetPerIntervalConstraintHandler',\n",
    "                'baseline': 'current_by_interval',\n",
    "                'tolerance': 0.3,  # 30% increase per interval\n",
    "                'allow_borrowing': False\n",
    "            },\n",
    "            {\n",
    "                'type': 'MinimumFleetConstraintHandler',\n",
    "                'min_fleet_fraction': 0.3,  # Maintain 30% of current service\n",
    "                'level': 'system',\n",
    "                'measure': 'peak', \n",
    "                'baseline': 'current_peak'\n",
    "            }\n",
    "        ],\n",
    "        # üîß NEW: Constraint-specific penalty weights\n",
    "        'penalty_weights': {\n",
    "            'fleet_total': 2000.0,        # High penalty for budget violations\n",
    "            'fleet_per_interval': 1000.0, # Medium penalty for operational violations\n",
    "            'minimum_fleet': 5000.0       # Very high penalty for service cuts\n",
    "        }\n",
    "    },\n",
    "    'optimization': {\n",
    "        'algorithm': {\n",
    "            'type': 'PSO',\n",
    "            'pop_size': 50,\n",
    "            'inertia_weight': 0.9,\n",
    "            'inertia_weight_final': 0.4,\n",
    "            'cognitive_coeff': 2.0,\n",
    "            'social_coeff': 2.0,\n",
    "            # üîß NEW: Penalty method configuration\n",
    "            'use_penalty_method': True,      # Enable penalty method\n",
    "            'penalty_weight': 1500.0,        # Default penalty for unspecified constraints\n",
    "            'adaptive_penalty': True,        # Increase penalties over generations\n",
    "            'penalty_increase_rate': 1.3     # 30% penalty increase per generation\n",
    "        },\n",
    "        'termination': {\n",
    "            'max_generations': 100  # More generations for penalty method convergence\n",
    "        },\n",
    "        'monitoring': {\n",
    "            'progress_frequency': 10,\n",
    "            'save_history': True,\n",
    "            'detailed_logging': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Alternative: Hard constraints configuration (traditional approach)\n",
    "config_hard = {\n",
    "    'problem': {\n",
    "        'objective': {\n",
    "            'type': 'HexagonalCoverageObjective',\n",
    "            'spatial_resolution_km': 3.0,\n",
    "            'crs': 'EPSG:3857',\n",
    "            'boundary_file': '../data/external/boundaries/study_area_boundary.geojson',\n",
    "            'boundary_buffer_km': 2.0\n",
    "        },\n",
    "        'constraints': [\n",
    "            {\n",
    "                'type': 'FleetTotalConstraintHandler',\n",
    "                'baseline': 'current_peak',\n",
    "                'tolerance': 0.25,  # More lenient for hard constraints\n",
    "                'measure': 'peak'\n",
    "            },\n",
    "            {\n",
    "                'type': 'MinimumFleetConstraintHandler',\n",
    "                'min_fleet_fraction': 0.25,  # More lenient for hard constraints\n",
    "                'level': 'system',\n",
    "                'measure': 'peak',\n",
    "                'baseline': 'current_peak'\n",
    "            }\n",
    "        ]\n",
    "        # No penalty_weights section - not used for hard constraints\n",
    "    },\n",
    "    'optimization': {\n",
    "        'algorithm': {\n",
    "            'type': 'PSO',\n",
    "            'pop_size': 50,\n",
    "            'inertia_weight': 0.9,\n",
    "            'inertia_weight_final': 0.4,\n",
    "            'cognitive_coeff': 2.0,\n",
    "            'social_coeff': 2.0,\n",
    "            # Hard constraints mode (default)\n",
    "            'use_penalty_method': False      # Traditional constraint handling\n",
    "        },\n",
    "        'termination': {\n",
    "            'max_generations': 50   # Fewer generations often sufficient for hard constraints\n",
    "        },\n",
    "        'monitoring': {\n",
    "            'progress_frequency': 10,\n",
    "            'save_history': True,\n",
    "            'detailed_logging': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# üîß CHOOSE CONFIGURATION MODE\n",
    "USE_PENALTY_METHOD = True  # Set to False to try hard constraints\n",
    "\n",
    "config = config_penalty if USE_PENALTY_METHOD else config_hard\n",
    "method_name = \"Penalty Method\" if USE_PENALTY_METHOD else \"Hard Constraints\"\n",
    "\n",
    "print(f\"\\nü§ñ SELECTED: {method_name}\")\n",
    "print(f\"   Algorithm: Particle Swarm Optimization (PSO)\")\n",
    "print(f\"   Population size: {config['optimization']['algorithm']['pop_size']} particles\")\n",
    "print(f\"   Max generations: {config['optimization']['termination']['max_generations']}\")\n",
    "\n",
    "if USE_PENALTY_METHOD:\n",
    "    print(f\"   Penalty weights: Budget={config['problem']['penalty_weights']['fleet_total']}, \")\n",
    "    print(f\"                   Operational={config['problem']['penalty_weights']['fleet_per_interval']}, \")\n",
    "    print(f\"                   Service={config['problem']['penalty_weights']['minimum_fleet']}\")\n",
    "    print(f\"   Adaptive penalties: {config['optimization']['algorithm']['adaptive_penalty']}\")\n",
    "    if config['optimization']['algorithm']['adaptive_penalty']:\n",
    "        rate = config['optimization']['algorithm']['penalty_increase_rate']\n",
    "        print(f\"   Penalty increase: {rate}x per generation (~{rate**50:.0f}x after 50 gens)\")\n",
    "\n",
    "print(f\"\\nüéØ Objective: Service Coverage (Spatial Equity)\")\n",
    "print(f\"   Minimize variance in vehicle distribution across hexagonal zones\")\n",
    "\n",
    "print(f\"\\nüîí Constraints: {len(config['problem']['constraints'])} active\")\n",
    "for i, constraint in enumerate(config['problem']['constraints'], 1):\n",
    "    constraint_type = constraint['type'].replace('ConstraintHandler', '')\n",
    "    tolerance = constraint.get('tolerance', constraint.get('min_fleet_fraction', 'N/A'))\n",
    "    print(f\"   {i}. {constraint_type}: {tolerance}\")\n",
    "\n",
    "print(f\"\\nüìä Constraint Handling Method:\")\n",
    "if USE_PENALTY_METHOD:\n",
    "    print(\"   üéØ PENALTY METHOD:\")\n",
    "    print(\"   ‚Ä¢ Violations added as penalties to objective function\")\n",
    "    print(\"   ‚Ä¢ Allows temporary exploration of infeasible regions\")\n",
    "    print(\"   ‚Ä¢ Penalties increase over generations ‚Üí convergence to feasibility\")\n",
    "    print(\"   ‚Ä¢ Better exploration, potentially better final solutions\")\n",
    "else:\n",
    "    print(\"   üö¶ HARD CONSTRAINTS:\")\n",
    "    print(\"   ‚Ä¢ Infeasible solutions completely rejected\")\n",
    "    print(\"   ‚Ä¢ Search restricted to feasible region only\")\n",
    "    print(\"   ‚Ä¢ Direct constraint enforcement\")\n",
    "    print(\"   ‚Ä¢ More predictable but potentially limited exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b050d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transit_opt.optimisation.config.config_manager import OptimizationConfigManager\n",
    "from transit_opt.optimisation.runners.pso_runner import PSORunner\n",
    "\n",
    "# Create optimization configuration\n",
    "config = {\n",
    "    'problem': {\n",
    "        'objective': {\n",
    "            'type': 'HexagonalCoverageObjective',\n",
    "            'spatial_resolution_km': 3.0,\n",
    "            'crs': 'EPSG:3857',\n",
    "            'boundary_file': '../data/external/boundaries/study_area_boundary.geojson',\n",
    "            'boundary_buffer_km': 2.0\n",
    "        },\n",
    "        'constraints': [\n",
    "            # Fleet total constraint: Allow 20% increase\n",
    "            {\n",
    "                'type': 'FleetTotalConstraintHandler',\n",
    "                'baseline': 'current_peak',\n",
    "                'tolerance': 0.20,  # 20% increase allowed\n",
    "                'measure': 'peak'\n",
    "            },\n",
    "            # Per-interval constraint: More lenient\n",
    "            # {\n",
    "            #     'type': 'FleetPerIntervalConstraintHandler', \n",
    "            #     'baseline': 'current_by_interval',\n",
    "            #     'tolerance': 0.5,  # allowed % increase per interval \n",
    "            #     'allow_borrowing': False  # Explicit setting\n",
    "\n",
    "            # },\n",
    "            # Minimum service: Maintain 70% of current\n",
    "            {\n",
    "                'type': 'MinimumFleetConstraintHandler',\n",
    "                'min_fleet_fraction': 0.30,\n",
    "                'level': 'system', \n",
    "                'measure': 'peak',\n",
    "                'baseline': 'current_peak'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    'optimization': {\n",
    "        'algorithm': {\n",
    "            'type': 'PSO',\n",
    "            'pop_size': 25,  # Population size\n",
    "            'inertia_weight': 0.9,  # Initial inertia\n",
    "            #'inertia_weight_final': 0.4,  # Final inertia (adaptive)\n",
    "            'cognitive_coeff': 2.0,  # Cognitive coefficient\n",
    "            'social_coeff': 2.0  # Social coefficient\n",
    "        },\n",
    "        'termination': {\n",
    "            'max_generations':10 # Reduced for quicker testing \n",
    "        },\n",
    "        'monitoring': {\n",
    "            'progress_frequency': 10,\n",
    "            'save_history': True,\n",
    "            'detailed_logging': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== OPTIMIZATION CONFIGURATION ===\")\n",
    "print(\"ü§ñ Algorithm: Particle Swarm Optimization (PSO)\")\n",
    "print(f\"   Population size: {config['optimization']['algorithm']['pop_size']} particles\")\n",
    "print(f\"   Max generations: {config['optimization']['termination']['max_generations']}\")\n",
    "#print(f\"   Adaptive inertia: {config['optimization']['algorithm']['inertia_weight']} ‚Üí {config['optimization']['algorithm']['inertia_weight_final']}\")\n",
    "\n",
    "print(f\"\\nüéØ Objective: Service Coverage (Spatial Equity)\")\n",
    "print(f\"   Minimize variance in vehicle distribution\")\n",
    "print(f\"   Spatial resolution: {config['problem']['objective']['spatial_resolution_km']} km hexagons\")\n",
    "\n",
    "print(f\"\\nüîí Constraints: {len(config['problem']['constraints'])} active\")\n",
    "for i, constraint in enumerate(config['problem']['constraints'], 1):\n",
    "    constraint_type = constraint['type'].replace('Handler', '').replace('Constraint', '')\n",
    "    print(f\"   {i}. {constraint_type}: {constraint.get('tolerance', constraint.get('min_fleet_fraction', 'N/A'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914914d",
   "metadata": {},
   "source": [
    "## 2.2 Single Optimization Run\n",
    "\n",
    "Let's run a single PSO optimization to see how the algorithm improves service coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40873d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run PSO\n",
    "print(\"üöÄ STARTING PSO OPTIMIZATION\")\n",
    "print(\"This may take 2-5 minutes depending on problem size...\\n\")\n",
    "\n",
    "config_manager = OptimizationConfigManager(config_dict=config)\n",
    "pso_runner = PSORunner(config_manager)\n",
    "\n",
    "# Run optimization\n",
    "result = pso_runner.optimize(opt_data)\n",
    "\n",
    "print(f\"\\n‚úÖ OPTIMIZATION COMPLETED\")\n",
    "print(f\"‚è±Ô∏è  Total time: {result.optimization_time:.1f} seconds\")\n",
    "print(f\"üìä Generations: {result.generations_completed}\")\n",
    "print(f\"üéØ Best objective: {result.best_objective:.6f}\")\n",
    "print(f\"üìà Improvement: {((current_objective_value - result.best_objective) / current_objective_value * 100):+.1f}%\")\n",
    "\n",
    "# Check constraint feasibility  \n",
    "violations = result.constraint_violations\n",
    "if violations['feasible']:\n",
    "    print(\"‚úÖ Solution is feasible (satisfies all constraints)\")\n",
    "else:\n",
    "    print(f\"‚ùå Solution violates {violations['total_violations']} constraints\")\n",
    "    print(\"   Constraint violation details:\")\n",
    "    for detail in violations['violation_details']:\n",
    "        if detail['violation'] < -0.001:  # Threshold for numerical precision\n",
    "            print(f\"   ‚Ä¢ Constraint {detail['constraint_idx']}: {detail['violation']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b97839",
   "metadata": {},
   "source": [
    "# Debugging start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e72af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to test the inertia weight schedule\n",
    "from transit_opt.optimisation.runners.pso_runner import AdaptivePSO\n",
    "\n",
    "print(\"üîç TESTING ADAPTIVE INERTIA WEIGHT:\")\n",
    "pso = AdaptivePSO(inertia_weight=0.9, inertia_weight_final=0.4)\n",
    "\n",
    "max_gen = 10\n",
    "for gen in [0, 1, 2, 5, 8, 9]:\n",
    "    weight = pso._calculate_adaptive_weight(gen, max_gen)\n",
    "    print(f\"   Generation {gen}: {weight:.3f}\")\n",
    "\n",
    "print(\"\\n   Expected: 0.9 ‚Üí 0.4 (decreasing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç DETAILED CONSTRAINT DIAGNOSIS:\")\n",
    "\n",
    "# Test different tolerances with current solution (should always pass)\n",
    "test_tolerances = [0.2, 1.0, 5.0, 10.0, 100.0]\n",
    "\n",
    "for tol in test_tolerances:\n",
    "    print(f\"\\nüìä Testing tolerance = {tol} ({tol*100:.0f}% increase):\")\n",
    "    \n",
    "    config_test = {\n",
    "        'baseline': 'current_by_interval',\n",
    "        'tolerance': tol\n",
    "    }\n",
    "    \n",
    "    handler_test = FleetPerIntervalConstraintHandler(config_test, opt_data)\n",
    "    \n",
    "    # Get limits\n",
    "    baseline_vals = np.array(opt_data['constraints']['fleet_analysis']['current_fleet_by_interval'])\n",
    "    limits = handler_test._get_interval_limits()\n",
    "    \n",
    "    print(f\"   Baseline: {baseline_vals[:3]}... (first 3 intervals)\")\n",
    "    print(f\"   Limits: {limits[:3]}... (first 3 intervals)\")\n",
    "    print(f\"   Multiplier: {(limits[0]/baseline_vals[0]):.2f}x\")\n",
    "    \n",
    "    # Test with CURRENT solution (should always pass)\n",
    "    violations = handler_test.evaluate(opt_data['initial_solution'])\n",
    "    max_violation = np.max(violations)\n",
    "    num_violated = np.sum(violations > 0)\n",
    "    \n",
    "    print(f\"   Current solution max violation: {max_violation:.1f}\")\n",
    "    print(f\"   Intervals violated: {num_violated}/{len(violations)}\")\n",
    "    \n",
    "    if num_violated > 0:\n",
    "        print(\"   ‚ùå PROBLEM: Current solution violates its own baseline!\")\n",
    "        violating_intervals = np.where(violations > 0)[0][:3]  # First 3\n",
    "        for i in violating_intervals:\n",
    "            print(f\"      Interval {i}: needs {violations[i] + limits[i]:.1f}, limit {limits[i]:.1f}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Current solution satisfies constraint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceeb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç BASELINE CONSISTENCY CHECK:\")\n",
    "\n",
    "# Get baseline from data structure\n",
    "baseline_from_data = np.array(opt_data['constraints']['fleet_analysis']['current_fleet_by_interval'])\n",
    "print(f\"Baseline from data: {baseline_from_data}\")\n",
    "\n",
    "# Calculate what current solution actually requires\n",
    "from transit_opt.optimisation.utils.fleet_calculations import calculate_fleet_requirements\n",
    "\n",
    "try:\n",
    "    current_fleet_calc = calculate_fleet_requirements(\n",
    "        headways_matrix=opt_data['initial_solution'],\n",
    "        round_trip_times=opt_data['routes']['round_trip_times'],\n",
    "        operational_buffer=1.15,\n",
    "        no_service_threshold=480,\n",
    "        allowed_headways=opt_data['allowed_headways'],\n",
    "        no_service_index=opt_data.get('no_service_index')\n",
    "    )\n",
    "    \n",
    "    actual_fleet_by_interval = current_fleet_calc['fleet_per_interval']\n",
    "    print(f\"Actual from calculation: {actual_fleet_by_interval}\")\n",
    "    \n",
    "    # Compare\n",
    "    difference = actual_fleet_by_interval - baseline_from_data\n",
    "    print(f\"Difference: {difference}\")\n",
    "    print(f\"Max difference: {np.max(np.abs(difference)):.1f} vehicles\")\n",
    "    \n",
    "    if np.max(np.abs(difference)) > 1.0:\n",
    "        print(\"‚ùå MAJOR INCONSISTENCY: Baseline and actual fleet don't match!\")\n",
    "        print(\"This explains why low tolerances don't work.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Baseline and actual fleet are consistent\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fleet calculation failed: {e}\")\n",
    "    print(\"This confirms the division-by-zero bug is causing constraint issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç CHECKING FLEET CALCULATION RETURN STRUCTURE:\")\n",
    "\n",
    "try:\n",
    "    result = calculate_fleet_requirements(\n",
    "        headways_matrix=opt_data['initial_solution'],\n",
    "        round_trip_times=opt_data['routes']['round_trip_times'],\n",
    "        operational_buffer=1.15,\n",
    "        no_service_threshold=480,\n",
    "        allowed_headways=opt_data['allowed_headways'],\n",
    "        no_service_index=opt_data.get('no_service_index')\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Fleet calculation succeeded!\")\n",
    "    print(f\"   Return type: {type(result)}\")\n",
    "    print(f\"   Available keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}\")\n",
    "    \n",
    "    if isinstance(result, dict):\n",
    "        for key, value in result.items():\n",
    "            print(f\"   {key}: {type(value)} - {np.array(value).shape if hasattr(value, 'shape') else 'scalar'}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fleet calculation failed: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37156389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this diagnostic to see what's happening\n",
    "print(\"üîç HEADWAY MAPPING ANALYSIS:\")\n",
    "print(\"Real GTFS headways vs. Discrete choices:\")\n",
    "\n",
    "for route_idx in range(min(7, opt_data['n_routes'])):  # First 5 routes\n",
    "    gtfs_headways = opt_data['routes']['current_headways'][route_idx]\n",
    "    initial_choices = opt_data['initial_solution'][route_idx]\n",
    "    \n",
    "    print(f\"\\nRoute {route_idx}:\")\n",
    "    for interval_idx in range(opt_data['n_intervals']):\n",
    "        real_hw = gtfs_headways[interval_idx] \n",
    "        choice_idx = initial_choices[interval_idx]\n",
    "        discrete_hw = opt_data['allowed_headways'][choice_idx] if choice_idx < len(opt_data['allowed_headways']) else 'No Service'\n",
    "        \n",
    "        print(f\"  Interval {interval_idx}: {real_hw:.1f}min ‚Üí {discrete_hw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac9912",
   "metadata": {},
   "source": [
    "# Debugging end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9abfca",
   "metadata": {},
   "source": [
    "### Solution Analysis\n",
    "\n",
    "Let's analyze how the optimization changed the transit service patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SOLUTION ANALYSIS ===\")\n",
    "\n",
    "# Get detailed analysis from objective function\n",
    "solution_analysis = coverage_objective.get_detailed_analysis(result.best_solution)\n",
    "current_analysis = coverage_objective.get_detailed_analysis(opt_data['initial_solution'])\n",
    "\n",
    "print(\"üìä SERVICE COVERAGE COMPARISON:\")\n",
    "print(f\"                     Before      After       Change\")\n",
    "print(f\"   Variance:         {current_analysis['variance_average']:.4f}    {solution_analysis['variance_average']:.4f}    {((solution_analysis['variance_average'] - current_analysis['variance_average']) / current_analysis['variance_average'] * 100):+.1f}%\")\n",
    "print(f\"   Mean vehicles:    {current_analysis['total_vehicles_average']:.1f}      {solution_analysis['total_vehicles_average']:.1f}       {((solution_analysis['total_vehicles_average'] - current_analysis['total_vehicles_average']) / current_analysis['total_vehicles_average'] * 100):+.1f}%\")\n",
    "print(f\"   Zones with service: {current_analysis['zones_with_service_average']}        {solution_analysis['zones_with_service_average']}         {solution_analysis['zones_with_service_average'] - current_analysis['zones_with_service_average']:+.0f}\")\n",
    "print(f\"   Coeff of variation: {current_analysis['coefficient_of_variation_average']:.3f}     {solution_analysis['coefficient_of_variation_average']:.3f}     {((solution_analysis['coefficient_of_variation_average'] - current_analysis['coefficient_of_variation_average']) / current_analysis['coefficient_of_variation_average'] * 100):+.1f}%\")\n",
    "\n",
    "# Fleet requirement comparison\n",
    "from transit_opt.optimisation.utils import calculate_fleet_requirements\n",
    "\n",
    "current_fleet_reqs = calculate_fleet_requirements(\n",
    "    opt_data['initial_solution'], \n",
    "    opt_data['routes']['round_trip_times'], \n",
    "    opt_data\n",
    ")\n",
    "\n",
    "optimized_fleet_reqs = calculate_fleet_requirements(\n",
    "    result.best_solution,\n",
    "    opt_data['routes']['round_trip_times'], \n",
    "    opt_data  \n",
    ")\n",
    "\n",
    "print(f\"\\nüöó FLEET REQUIREMENTS COMPARISON:\")\n",
    "print(f\"   Current peak fleet: {np.max(current_fleet_reqs['fleet_by_interval']):.1f} vehicles\")\n",
    "print(f\"   Optimized peak fleet: {np.max(optimized_fleet_reqs['fleet_by_interval']):.1f} vehicles\") \n",
    "print(f\"   Fleet change: {((np.max(optimized_fleet_reqs['fleet_by_interval']) - np.max(current_fleet_reqs['fleet_by_interval'])) / np.max(current_fleet_reqs['fleet_by_interval']) * 100):+.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b60125",
   "metadata": {},
   "source": [
    "### Convergence Analysis\n",
    "\n",
    "Analyze how PSO converged to the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ebe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence\n",
    "history = result.optimization_history\n",
    "\n",
    "if history:\n",
    "    generations = [gen['generation'] for gen in history]\n",
    "    best_objectives = [gen['best_objective'] for gen in history]\n",
    "    mean_objectives = [gen['mean_objective'] for gen in history]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot convergence\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(generations, best_objectives, 'b-', label='Best', linewidth=2)\n",
    "    plt.plot(generations, mean_objectives, 'r--', label='Population Mean', alpha=0.7)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Objective Value (Variance)')\n",
    "    plt.title('PSO Convergence')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot improvement rate\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(best_objectives) > 1:\n",
    "        improvements = [best_objectives[i] - best_objectives[i-1] for i in range(1, len(best_objectives))]\n",
    "        plt.plot(generations[1:], improvements, 'g-', linewidth=2)\n",
    "        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Objective Improvement')  \n",
    "    plt.title('Generation-to-Generation Improvement')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Convergence statistics\n",
    "    final_improvement = best_objectives[-1] - best_objectives[0]\n",
    "    print(f\"\\nüìà CONVERGENCE STATISTICS:\")\n",
    "    print(f\"   Initial objective: {best_objectives[0]:.6f}\")\n",
    "    print(f\"   Final objective: {best_objectives[-1]:.6f}\")\n",
    "    print(f\"   Total improvement: {final_improvement:.6f} ({(final_improvement/best_objectives[0]*100):+.2f}%)\")\n",
    "    \n",
    "    # Find when major improvements stopped\n",
    "    if len(improvements) > 10:\n",
    "        recent_improvements = improvements[-10:]\n",
    "        avg_recent_improvement = np.mean(recent_improvements)\n",
    "        print(f\"   Recent improvement rate: {avg_recent_improvement:.8f} per generation\")\n",
    "        if abs(avg_recent_improvement) < abs(final_improvement) * 0.01:\n",
    "            print(\"   üèÅ Algorithm appears to have converged (minimal recent progress)\")\n",
    "        else:\n",
    "            print(\"   üîÑ Algorithm still making progress when terminated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce312d44",
   "metadata": {},
   "source": [
    "### Solution Visualization  \n",
    "\n",
    "Visualize the spatial changes in service coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a159a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== SPATIAL COVERAGE VISUALIZATION ===\")\n",
    "\n",
    "# Visualize current vs optimized coverage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Current solution\n",
    "coverage_objective.spatial_system.visualize_spatial_coverage(\n",
    "    solution_matrix=opt_data['initial_solution'],\n",
    "    optimization_data=opt_data,\n",
    "    figsize=None,  # Use subplot\n",
    "    ax=axes[0],\n",
    "    show_stops=True\n",
    ")\n",
    "axes[0].set_title(f'Current Service Coverage\\nVariance: {current_analysis[\"variance_average\"]:.4f}', fontsize=14)\n",
    "\n",
    "# Optimized solution  \n",
    "coverage_objective.spatial_system.visualize_spatial_coverage(\n",
    "    solution_matrix=result.best_solution,\n",
    "    optimization_data=opt_data,\n",
    "    figsize=None,  # Use subplot\n",
    "    ax=axes[1], \n",
    "    show_stops=True\n",
    ")\n",
    "axes[1].set_title(f'Optimized Service Coverage\\nVariance: {solution_analysis[\"variance_average\"]:.4f}', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "variance_improvement = ((current_analysis['variance_average'] - solution_analysis['variance_average']) / current_analysis['variance_average']) * 100\n",
    "print(f\"üéØ Spatial equity improvement: {variance_improvement:+.1f}% reduction in coverage variance\")\n",
    "\n",
    "print(\"\\n‚úÖ Single optimization analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418bfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transit_opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
