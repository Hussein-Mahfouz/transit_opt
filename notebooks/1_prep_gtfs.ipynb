{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba9b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import gtfs_kit as gk\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "from shapely.geometry import Point, Polygon \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9531ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STREAMLINED GTFS DATA PREPARATOR FOR DISCRETE OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "class GTFSDataPreparator:\n",
    "    \"\"\"\n",
    "    Streamlined GTFS data extraction focused on optimization essentials.\n",
    "    \n",
    "    Extracts only what's needed:\n",
    "    - Headways by interval (current values from GTFS)\n",
    "    - Round-trip times for vehicle constraints\n",
    "    \n",
    "    Supports discrete headway optimization where user specifies allowed values.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 gtfs_path: str,\n",
    "                 interval_hours: int,\n",
    "                 date: Optional[str] = None,\n",
    "                 turnaround_buffer: float = 1.15,\n",
    "                 default_round_trip_time: float = 60.0,\n",
    "                 max_round_trip_minutes: float = 240.0):\n",
    "        \"\"\"\n",
    "        Initialize GTFS data preparator.\n",
    "        \n",
    "        Args:\n",
    "            gtfs_path: Path to GTFS ZIP file or directory\n",
    "            interval_hours: Time interval duration in HOURS (must divide 24 evenly)\n",
    "            date: Optional service date filter (YYYYMMDD format)\n",
    "            turnaround_buffer: Round-trip time multiplier (1.15 = 15% buffer)\n",
    "            default_round_trip_time: Fallback round-trip time in MINUTES\n",
    "            max_round_trip_minutes: Maximum allowed round-trip time in MINUTES (GTFS may have regional trips longer than this)\n",
    "\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if 24 % interval_hours != 0:\n",
    "            raise ValueError(f\"interval_hours ({interval_hours}) must divide 24 evenly. \"\n",
    "                           f\"Valid values: 1, 2, 3, 4, 6, 8, 12, 24\")\n",
    "            \n",
    "        # Store configuration\n",
    "        self.gtfs_path = gtfs_path\n",
    "        self.date = date\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.turnaround_buffer = turnaround_buffer\n",
    "        self.default_round_trip_time = default_round_trip_time\n",
    "        self.max_round_trip_minutes = max_round_trip_minutes\n",
    "        \n",
    "        # Load and cache GTFS data\n",
    "        self._load_gtfs()\n",
    "    \n",
    "    def _load_gtfs(self) -> None:\n",
    "        \"\"\"Load GTFS feed and cache for optimization and reconstruction.\"\"\"\n",
    "        print(f\"‚è±Ô∏è  Loading GTFS feed from {self.gtfs_path}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load original feed (keep for reconstruction)\n",
    "        self.feed = gk.read_feed(self.gtfs_path, dist_units='km')\n",
    "        \n",
    "        # Apply date filtering if specified\n",
    "        if self.date:\n",
    "            print(f\"üìÖ Filtering GTFS for date: {self.date}\")\n",
    "            try:\n",
    "                self.feed = gk.filter_feed_by_dates(self.feed, [self.date])\n",
    "                print(f\"   ‚úÖ Filtered to {len(self.feed.trips)} trips for date {self.date}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Date filtering failed: {e}, using full feed\")\n",
    "        else:\n",
    "            print(\"üìÖ Using full GTFS feed (all service periods)\")\n",
    "        \n",
    "        # Cache tables for processing\n",
    "        self.trips_df = self.feed.trips.copy()\n",
    "        self.stop_times_df = self.feed.stop_times.copy()\n",
    "        self.routes_df = self.feed.routes.copy()\n",
    "        \n",
    "        # Convert times to seconds for calculations\n",
    "        self.stop_times_df['departure_seconds'] = self.stop_times_df['departure_time'].apply(\n",
    "            self._safe_timestr_to_seconds\n",
    "        )\n",
    "        self.stop_times_df['arrival_seconds'] = self.stop_times_df['arrival_time'].apply(\n",
    "            self._safe_timestr_to_seconds\n",
    "        )\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"‚úÖ GTFS loaded and cached in {load_time:.2f} seconds\")\n",
    "        print(f\"   üìä {len(self.trips_df):,} trips, {len(self.stop_times_df):,} stop times\")\n",
    "    \n",
    "    def _safe_timestr_to_seconds(self, time_value: Any) -> float:\n",
    "        \"\"\"Safely convert GTFS time values to seconds from midnight.\"\"\"\n",
    "        try:\n",
    "            if pd.isna(time_value):\n",
    "                return np.nan\n",
    "            if isinstance(time_value, str):\n",
    "                return gk.helpers.timestr_to_seconds(time_value)\n",
    "            else:\n",
    "                return float(time_value)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    def extract_optimization_data(self, allowed_headways: List[float]) -> Dict[str, Any]:\n",
    "        \"\"\"IMPROVED: Extract data optimized for downstream algorithms.\"\"\"\n",
    "        \n",
    "        # Extract route data first\n",
    "        route_data = self._extract_route_essentials()\n",
    "        n_routes = len(route_data)\n",
    "        \n",
    "        # Create headway mappings\n",
    "        allowed_values = np.array(allowed_headways + [9999.0], dtype=np.float64)\n",
    "        headway_to_index = {float(h): i for i, h in enumerate(allowed_values)}\n",
    "        no_service_index = len(allowed_values) - 1\n",
    "        \n",
    "        # Create aligned arrays\n",
    "        route_ids = [r['service_id'] for r in route_data]\n",
    "        round_trip_times = np.array([r['round_trip_time'] for r in route_data], dtype=np.float64)\n",
    "        current_headways = np.array([r['headways_by_interval'] for r in route_data], dtype=np.float64)\n",
    "        \n",
    "        # Create initial solution matrix\n",
    "        initial_solution = self._create_initial_solution(current_headways, headway_to_index)\n",
    "        \n",
    "        # Build optimized structure\n",
    "        return {\n",
    "            'problem_type': 'discrete_headway_optimization',\n",
    "            'n_routes': n_routes,\n",
    "            'n_intervals': self.n_intervals,\n",
    "            'n_choices': len(allowed_values),\n",
    "            \n",
    "            'decision_matrix_shape': (n_routes, self.n_intervals),\n",
    "            'variable_bounds': (0, len(allowed_values)-1),\n",
    "            'initial_solution': initial_solution,\n",
    "            \n",
    "            'allowed_headways': allowed_values,\n",
    "            'headway_to_index': headway_to_index,\n",
    "            'no_service_index': no_service_index,\n",
    "            \n",
    "            'routes': {\n",
    "                'ids': route_ids,\n",
    "                'round_trip_times': round_trip_times,\n",
    "                'current_headways': current_headways,\n",
    "            },\n",
    "            \n",
    "            'constraints': {\n",
    "                'fleet_data': {\n",
    "                    'round_trip_times': round_trip_times,  # Reference, not copy\n",
    "                    'min_fleet_factor': 0.8,\n",
    "                },\n",
    "                'service_coverage': {\n",
    "                    'min_service_ratio': 0.4,\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'intervals': {\n",
    "                'labels': [f\"{i*self.interval_hours:02d}-{(i+1)*self.interval_hours:02d}h\" \n",
    "                        for i in range(self.n_intervals)],\n",
    "                'hours': [(i*self.interval_hours, (i+1)*self.interval_hours) \n",
    "                        for i in range(self.n_intervals)],\n",
    "                'duration_minutes': self.interval_hours * 60,\n",
    "            },\n",
    "            \n",
    "            'metadata': {\n",
    "                'gtfs_source': self.gtfs_path,\n",
    "                'date_filter': self.date,\n",
    "                'creation_timestamp': datetime.now().isoformat(),\n",
    "                'filter_stats': {\n",
    "                    'final_routes': n_routes,\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            'reconstruction': {\n",
    "                'gtfs_feed': self.feed,\n",
    "                'route_mapping': {route_id: i for i, route_id in enumerate(route_ids)},\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _extract_route_essentials(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract only essential data: headways and round-trip times.\"\"\"\n",
    "        print(f\"‚è±Ô∏è  Extracting route essentials with {self.interval_hours}-hour intervals...\")\n",
    "        \n",
    "        all_services = self.trips_df['service_id'].unique()\n",
    "        route_data = []\n",
    "\n",
    "        # Keep track of number of routes filtered out because they exceed max_round_trip_minutes\n",
    "        filtered_count = 0\n",
    "        \n",
    "        for service_id in all_services:\n",
    "            service_trips = self.trips_df[self.trips_df['service_id'] == service_id]\n",
    "            \n",
    "            if len(service_trips) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate headways by interval\n",
    "            headways_by_interval = self._calculate_service_headways(service_id, service_trips)\n",
    "            \n",
    "            # Skip if no service found\n",
    "            if np.all(np.isnan(headways_by_interval)):\n",
    "                continue\n",
    "            \n",
    "            # Calculate round-trip time\n",
    "            round_trip_time = self._calculate_round_trip_time(service_id, service_trips)\n",
    "\n",
    "            # Filter out services with excessive round-trip times\n",
    "            if round_trip_time > self.max_round_trip_minutes:\n",
    "                print(f\"   ‚ö†Ô∏è  Filtered out route {service_id}: {round_trip_time:.1f} min round-trip (>{self.max_round_trip_minutes} min)\")\n",
    "                filtered_count += 1\n",
    "                continue\n",
    "            \n",
    "            route_data.append({\n",
    "                'service_id': service_id,\n",
    "                'headways_by_interval': headways_by_interval,\n",
    "                'round_trip_time': round_trip_time\n",
    "            })\n",
    "        \n",
    "        print(f\"‚úÖ Extracted {len(route_data)} routes\")\n",
    "        return route_data\n",
    "    \n",
    "    def _calculate_service_headways(self, service_id: str, service_trips: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Calculate headway values for each time interval.\"\"\"\n",
    "        headways = np.full(self.n_intervals, np.nan)\n",
    "        \n",
    "        try:\n",
    "            trip_ids = service_trips['trip_id'].tolist()\n",
    "            service_stop_times = self.stop_times_df[\n",
    "                self.stop_times_df['trip_id'].isin(trip_ids)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(service_stop_times) == 0:\n",
    "                return headways\n",
    "            \n",
    "            # Get first departure for each trip\n",
    "            first_departures = service_stop_times.loc[\n",
    "                service_stop_times.groupby('trip_id')['stop_sequence'].idxmin()\n",
    "            ][['trip_id', 'departure_seconds']].copy()\n",
    "            \n",
    "            first_departures['departure_hour'] = (first_departures['departure_seconds'] // 3600) % 24\n",
    "            first_departures = first_departures.dropna()\n",
    "            \n",
    "            # Calculate headways for each interval\n",
    "            for interval in range(self.n_intervals):\n",
    "                start_hour = interval * self.interval_hours\n",
    "                end_hour = (interval + 1) * self.interval_hours\n",
    "                \n",
    "                interval_departures = first_departures[\n",
    "                    (first_departures['departure_hour'] >= start_hour) &\n",
    "                    (first_departures['departure_hour'] < end_hour)\n",
    "                ]['departure_seconds'].values\n",
    "                \n",
    "                if len(interval_departures) >= 2:\n",
    "                    # Calculate average interval between departures\n",
    "                    interval_departures = np.sort(interval_departures)\n",
    "                    intervals = np.diff(interval_departures) / 60  # Convert to minutes\n",
    "                    valid_intervals = intervals[intervals > 0]\n",
    "                    if len(valid_intervals) > 0:\n",
    "                        headways[interval] = np.mean(valid_intervals)\n",
    "                elif len(interval_departures) == 1:\n",
    "                    # Single trip - once per day service\n",
    "                    headways[interval] = 24 * 60  # 1440 minutes\n",
    "            \n",
    "            return headways\n",
    "            \n",
    "        except Exception:\n",
    "            return headways\n",
    "    \n",
    "    def _calculate_round_trip_time(self, service_id: str, service_trips: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate round-trip time with turnaround buffer.\"\"\"\n",
    "        try:\n",
    "            trip_ids = service_trips['trip_id'].tolist()\n",
    "            service_stop_times = self.stop_times_df[\n",
    "                self.stop_times_df['trip_id'].isin(trip_ids)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(service_stop_times) == 0:\n",
    "                return self.default_round_trip_time\n",
    "            \n",
    "            trip_durations = []\n",
    "            for trip_id, trip_stops in service_stop_times.groupby('trip_id'):\n",
    "                if len(trip_stops) >= 2:\n",
    "                    trip_stops = trip_stops.sort_values('stop_sequence')\n",
    "                    first_departure = trip_stops.iloc[0]['departure_seconds']\n",
    "                    last_arrival = trip_stops.iloc[-1]['arrival_seconds']\n",
    "                    \n",
    "                    if pd.notna(first_departure) and pd.notna(last_arrival):\n",
    "                        duration_minutes = (last_arrival - first_departure) / 60.0\n",
    "                        if duration_minutes > 0:\n",
    "                            trip_durations.append(duration_minutes)\n",
    "            \n",
    "            if trip_durations:\n",
    "                median_one_way = np.median(trip_durations)\n",
    "                return median_one_way * 2.0 * self.turnaround_buffer\n",
    "            else:\n",
    "                return self.default_round_trip_time\n",
    "                \n",
    "        except Exception:\n",
    "            return self.default_round_trip_time\n",
    "        \n",
    "    def _create_initial_solution(self, current_headways: np.ndarray, headway_to_index: Dict[float, int]) -> np.ndarray:\n",
    "        \"\"\"Create initial solution matrix by mapping current headways to allowed indices.\"\"\"\n",
    "        n_routes, n_intervals = current_headways.shape\n",
    "        initial_solution = np.zeros((n_routes, n_intervals), dtype=int)\n",
    "        \n",
    "        allowed_headway_values = list(headway_to_index.keys())[:-1]  # Exclude 9999\n",
    "        no_service_index = headway_to_index[9999.0]\n",
    "        \n",
    "        for i in range(n_routes):\n",
    "            for j in range(n_intervals):\n",
    "                current_headway = current_headways[i, j]\n",
    "                \n",
    "                if np.isnan(current_headway):\n",
    "                    # No service - use no_service_index\n",
    "                    initial_solution[i, j] = no_service_index\n",
    "                else:\n",
    "                    # Find nearest allowed headway\n",
    "                    distances = [abs(current_headway - h) for h in allowed_headway_values]\n",
    "                    best_idx = np.argmin(distances)\n",
    "                    initial_solution[i, j] = best_idx\n",
    "        \n",
    "        return initial_solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78532779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIXED GTFS RECONSTRUCTOR\n",
    "# =============================================================================\n",
    "\n",
    "class SimplifiedGTFSReconstructor:\n",
    "    \"\"\"\n",
    "    UPDATED: Reconstructor compatible with improved optimization data structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimization_data: Dict[str, Any], optimization_result: Dict[str, Any]):\n",
    "        self.optimization_data = optimization_data\n",
    "        self.optimization_result = optimization_result\n",
    "        \n",
    "        # UPDATED: Access GTFS feed from new structure\n",
    "        self.feed = optimization_data['reconstruction']['gtfs_feed']\n",
    "        \n",
    "        # Decode solution\n",
    "        self.optimized_headways = self._decode_headway_solution()\n",
    "    \n",
    "    def _decode_headway_solution(self) -> np.ndarray:\n",
    "        \"\"\"Convert optimization solution indices to actual headway values.\"\"\"\n",
    "        solution_indices = self.optimization_result['headway_solution']\n",
    "        allowed_headways = self.optimization_data['allowed_headways']\n",
    "        no_service_index = self.optimization_data['no_service_index']\n",
    "        \n",
    "        n_routes, n_intervals = solution_indices.shape\n",
    "        headways = np.full((n_routes, n_intervals), np.nan)\n",
    "        \n",
    "        for i in range(n_routes):\n",
    "            for j in range(n_intervals):\n",
    "                choice_idx = solution_indices[i, j]\n",
    "                headway_value = allowed_headways[choice_idx]\n",
    "                \n",
    "                if choice_idx == no_service_index or headway_value >= 9000:\n",
    "                    headways[i, j] = np.nan  # No service\n",
    "                else:\n",
    "                    headways[i, j] = headway_value\n",
    "        \n",
    "        return headways\n",
    "    \n",
    "    def reconstruct_gtfs(self, use_frequencies: bool = False) -> Any:\n",
    "        \"\"\"Reconstruct GTFS with proper stop_times.txt.\"\"\"\n",
    "        print(\"=== RECONSTRUCTING GTFS WITH OPTIMIZED HEADWAYS ===\")\n",
    "        \n",
    "        # Start with copy of original feed\n",
    "        new_feed = self.feed.copy()\n",
    "        \n",
    "        # Generate new stop_times and trips\n",
    "        new_stop_times, new_trips = self._generate_stop_times_and_trips()\n",
    "        \n",
    "        # Update feed\n",
    "        new_feed.stop_times = new_stop_times\n",
    "        new_feed.trips = new_trips\n",
    "        \n",
    "        # Handle frequencies (optional)\n",
    "        if use_frequencies and len(new_trips) > 0:\n",
    "            frequencies_df = self._create_frequencies_table(new_trips)\n",
    "            if len(frequencies_df) > 0:\n",
    "                new_feed.frequencies = frequencies_df\n",
    "                print(f\"   üìä Added {len(frequencies_df):,} frequency entries\")\n",
    "            else:\n",
    "                new_feed.frequencies = None\n",
    "                print(f\"   ‚ö†Ô∏è  No frequencies generated - skipping frequencies.txt\")\n",
    "        else:\n",
    "            new_feed.frequencies = None\n",
    "            print(f\"   üìä Frequencies.txt disabled - using stop_times.txt only\")\n",
    "        \n",
    "        print(f\"‚úÖ Reconstructed GTFS with stop_times.txt:\")\n",
    "        print(f\"   üìä {len(new_trips):,} trips\")\n",
    "        print(f\"   üìä {len(new_stop_times):,} stop times\")\n",
    "        \n",
    "        return new_feed\n",
    "    \n",
    "    def _generate_stop_times_and_trips(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Generate both stop_times and trips tables with proper relationships.\"\"\"\n",
    "        new_stop_times_list = []\n",
    "        new_trips_list = []\n",
    "        trip_id_counter = 1\n",
    "        \n",
    "        # UPDATED: Use new data structure\n",
    "        route_ids = self.optimization_data['routes']['ids']\n",
    "        n_intervals = self.optimization_data['n_intervals']\n",
    "        interval_hours = self.optimization_data['intervals']['duration_minutes'] // 60\n",
    "        \n",
    "        print(f\"   üîÑ Generating trips and stop_times for {len(route_ids)} routes\")\n",
    "        \n",
    "        for route_idx, service_id in enumerate(route_ids):\n",
    "            # Get original trips for this service\n",
    "            original_trips = self.feed.trips[self.feed.trips['service_id'] == service_id]\n",
    "            \n",
    "            if len(original_trips) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Use first trip as template\n",
    "            template_trip = original_trips.iloc[0]\n",
    "            template_trip_id = template_trip['trip_id']\n",
    "            \n",
    "            # Get template stop_times\n",
    "            template_stops = self.feed.stop_times[\n",
    "                self.feed.stop_times['trip_id'] == template_trip_id\n",
    "            ].sort_values('stop_sequence').copy()\n",
    "            \n",
    "            if len(template_stops) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Convert template times to seconds for calculations\n",
    "            template_stops['departure_seconds'] = template_stops['departure_time'].apply(\n",
    "                self._safe_timestr_to_seconds\n",
    "            )\n",
    "            template_stops['arrival_seconds'] = template_stops['arrival_time'].apply(\n",
    "                self._safe_timestr_to_seconds\n",
    "            )\n",
    "            \n",
    "            # Generate trips for each interval with service\n",
    "            route_trips_generated = 0\n",
    "            for interval_idx in range(n_intervals):\n",
    "                headway = self.optimized_headways[route_idx, interval_idx]\n",
    "                \n",
    "                # Skip intervals with no service\n",
    "                if np.isnan(headway):\n",
    "                    continue\n",
    "                \n",
    "                # UPDATED: Use interval hours from data structure\n",
    "                start_hour, end_hour = self.optimization_data['intervals']['hours'][interval_idx]\n",
    "                interval_duration_minutes = end_hour * 60 - start_hour * 60\n",
    "                \n",
    "                # Calculate number of trips needed in this interval\n",
    "                n_trips = max(1, int(interval_duration_minutes / headway))\n",
    "                \n",
    "                # Generate trips spaced by optimized headway\n",
    "                for trip_num in range(n_trips):\n",
    "                    # Calculate start time for this trip\n",
    "                    trip_start_minutes = start_hour * 60 + (trip_num * headway)\n",
    "                    \n",
    "                    # Don't exceed interval boundary\n",
    "                    if trip_start_minutes >= end_hour * 60:\n",
    "                        break\n",
    "                    \n",
    "                    # Create new trip with unique ID\n",
    "                    new_trip_id = f\"opt_{service_id}_{interval_idx}_{trip_num}\"\n",
    "                    new_trip = template_trip.copy()\n",
    "                    new_trip['trip_id'] = new_trip_id\n",
    "                    \n",
    "                    # Clear any block_id to avoid conflicts\n",
    "                    if 'block_id' in new_trip:\n",
    "                        new_trip['block_id'] = f\"block_{trip_id_counter}\"\n",
    "                    \n",
    "                    new_trips_list.append(new_trip)\n",
    "                    \n",
    "                    # Generate stop_times for this trip\n",
    "                    trip_stop_times = self._create_trip_stop_times(\n",
    "                        template_stops, new_trip_id, trip_start_minutes\n",
    "                    )\n",
    "                    \n",
    "                    if trip_stop_times is not None:\n",
    "                        new_stop_times_list.append(trip_stop_times)\n",
    "                        route_trips_generated += 1\n",
    "                    \n",
    "                    trip_id_counter += 1\n",
    "            \n",
    "            if route_trips_generated > 0 and route_idx < 5:  # Log first few routes\n",
    "                print(f\"   üìç Route {route_idx} ({service_id}): Generated {route_trips_generated} trips\")\n",
    "        \n",
    "        # Combine all data\n",
    "        if new_trips_list and new_stop_times_list:\n",
    "            new_trips = pd.DataFrame(new_trips_list).reset_index(drop=True)\n",
    "            new_stop_times = pd.concat(new_stop_times_list, ignore_index=True)\n",
    "            \n",
    "            print(f\"   ‚úÖ Generated {len(new_trips):,} trips with {len(new_stop_times):,} stop times\")\n",
    "        else:\n",
    "            # Create empty but valid DataFrames\n",
    "            new_trips = self.feed.trips.iloc[0:0].copy()\n",
    "            new_stop_times = self.feed.stop_times.iloc[0:0].copy()\n",
    "            print(f\"   ‚ö†Ô∏è  No trips generated - all routes mapped to no service\")\n",
    "        \n",
    "        return new_stop_times, new_trips\n",
    "    \n",
    "    def _create_trip_stop_times(self, template_stops: pd.DataFrame, \n",
    "                              new_trip_id: str, trip_start_minutes: float) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Create stop_times for a single trip based on template.\"\"\"\n",
    "        try:\n",
    "            # Calculate time offset\n",
    "            template_start_seconds = template_stops.iloc[0]['departure_seconds']\n",
    "            if pd.isna(template_start_seconds):\n",
    "                return None\n",
    "            \n",
    "            trip_start_seconds = trip_start_minutes * 60\n",
    "            time_offset = trip_start_seconds - template_start_seconds\n",
    "            \n",
    "            # Create new stop_times\n",
    "            new_stop_times = template_stops.copy()\n",
    "            new_stop_times['trip_id'] = new_trip_id\n",
    "            \n",
    "            # Adjust all times\n",
    "            new_stop_times['departure_seconds'] = template_stops['departure_seconds'] + time_offset\n",
    "            new_stop_times['arrival_seconds'] = template_stops['arrival_seconds'] + time_offset\n",
    "            \n",
    "            # Convert back to GTFS time strings\n",
    "            new_stop_times['departure_time'] = new_stop_times['departure_seconds'].apply(\n",
    "                self._seconds_to_timestr\n",
    "            )\n",
    "            new_stop_times['arrival_time'] = new_stop_times['arrival_seconds'].apply(\n",
    "                self._seconds_to_timestr\n",
    "            )\n",
    "            \n",
    "            # Remove helper columns\n",
    "            new_stop_times = new_stop_times.drop(['departure_seconds', 'arrival_seconds'], \n",
    "                                               axis=1, errors='ignore')\n",
    "            \n",
    "            return new_stop_times\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Failed to create stop_times for trip {new_trip_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_frequencies_table(self, trips_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create frequencies.txt that uses ACTUAL trip IDs from the new trips.\"\"\"\n",
    "        frequencies_list = []\n",
    "        n_intervals = self.optimization_data['n_intervals']\n",
    "        route_ids = self.optimization_data['routes']['ids']\n",
    "        \n",
    "        for route_idx, service_id in enumerate(route_ids):\n",
    "            # Get trips that were actually generated for this service\n",
    "            service_trips = trips_df[trips_df['service_id'] == service_id]\n",
    "            \n",
    "            if len(service_trips) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Create frequency entries for each interval that has service\n",
    "            for interval_idx in range(n_intervals):\n",
    "                headway = self.optimized_headways[route_idx, interval_idx]\n",
    "                \n",
    "                if np.isnan(headway):\n",
    "                    continue\n",
    "                \n",
    "                # Find a trip that was actually generated for this interval\n",
    "                interval_trips = service_trips[\n",
    "                    service_trips['trip_id'].str.contains(f'_{interval_idx}_', na=False)\n",
    "                ]\n",
    "                \n",
    "                if len(interval_trips) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Use the first trip from this interval as the frequency template\n",
    "                template_trip_id = interval_trips.iloc[0]['trip_id']\n",
    "                \n",
    "                # UPDATED: Get interval hours from data structure\n",
    "                start_hour, end_hour = self.optimization_data['intervals']['hours'][interval_idx]\n",
    "                \n",
    "                frequency_entry = {\n",
    "                    'trip_id': template_trip_id,\n",
    "                    'start_time': f\"{start_hour:02d}:00:00\",\n",
    "                    'end_time': f\"{end_hour:02d}:00:00\",\n",
    "                    'headway_secs': int(headway * 60),\n",
    "                    'exact_times': 0\n",
    "                }\n",
    "                \n",
    "                frequencies_list.append(frequency_entry)\n",
    "        \n",
    "        return pd.DataFrame(frequencies_list)\n",
    "    \n",
    "    # Helper methods remain the same\n",
    "    def _safe_timestr_to_seconds(self, time_value: Any) -> float:\n",
    "        \"\"\"Safely convert GTFS time strings to seconds.\"\"\"\n",
    "        try:\n",
    "            if pd.isna(time_value):\n",
    "                return np.nan\n",
    "            if isinstance(time_value, str):\n",
    "                return gk.helpers.timestr_to_seconds(time_value)\n",
    "            else:\n",
    "                return float(time_value)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    def _seconds_to_timestr(self, seconds: float) -> str:\n",
    "        \"\"\"Convert seconds to GTFS time string format.\"\"\"\n",
    "        if pd.isna(seconds):\n",
    "            return \"00:00:00\"\n",
    "        \n",
    "        # Handle times > 24 hours (GTFS allows this)\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        \n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c6da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: PREPARING OPTIMIZATION DATA ===\n",
      "‚è±Ô∏è  Loading GTFS feed from ../data/external/study_area_gtfs_bus.zip...\n",
      "üìÖ Using full GTFS feed (all service periods)\n",
      "‚úÖ GTFS loaded and cached in 4.89 seconds\n",
      "   üìä 13,974 trips, 703,721 stop times\n",
      "‚è±Ô∏è  Extracting route essentials with 3-hour intervals...\n",
      "   ‚ö†Ô∏è  Filtered out route 4075: 317.4 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 4122: 366.8 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 3985: 409.4 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 5496: 416.3 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 3986: 396.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 6790: 396.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 3228: 258.8 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 41: 609.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 42: 885.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 43: 575.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 44: 1023.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 45: 839.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 46: 885.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 47: 862.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 48: 885.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 49: 885.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 50: 989.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 51: 632.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 52: 621.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 53: 1150.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 54: 1152.3 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 55: 1173.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 56: 960.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 57: 1035.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 59: 1092.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 35: 1081.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 151: 1035.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 152: 782.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 3: 517.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 160: 552.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 170: 989.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 171: 1242.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 172: 1587.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 173: 1092.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 174: 1592.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 175: 1121.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 176: 1069.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 177: 1472.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 212: 678.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 189: 828.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 190: 793.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 213: 678.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 90: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 92: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 169: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 165: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 166: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 167: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 168: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 123: 494.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 2: 483.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 271: 1248.9 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 273: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 274: 488.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 275: 437.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 291: 1472.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 292: 1368.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 296: 1460.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 297: 1437.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 286: 1046.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 302: 1282.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 301: 1029.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 307: 1035.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 308: 931.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 101: 414.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 102: 1001.6 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 375: 494.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 376: 598.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 276: 529.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 414: 356.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 415: 971.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 416: 770.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 418: 437.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 421: 874.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 422: 862.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 424: 845.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 425: 782.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 426: 851.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 427: 1518.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 428: 1104.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 429: 989.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 431: 1184.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 115: 943.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 319: 1081.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 62: 862.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 37: 1109.8 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 71: 994.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 435: 1058.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 436: 1104.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 437: 1092.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 261: 1092.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 438: 1127.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 317: 1035.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 315: 1035.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 217: 690.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 70: 816.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 120: 736.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 464: 667.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 465: 770.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 466: 908.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 467: 966.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 468: 943.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 469: 690.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 310: 707.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 64: 690.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 110: 713.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 111: 724.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 68: 908.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 1: 747.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 114: 713.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 471: 701.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 311: 402.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 34: 718.8 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 251: 828.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 483: 1391.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 484: 1023.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 153: 960.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 530: 437.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 61: 546.2 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 542: 609.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 501: 575.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 552: 552.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 553: 506.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 554: 977.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 555: 885.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 556: 586.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 570: 402.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 577: 253.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 579: 373.7 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 581: 678.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 582: 1012.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 150: 1230.5 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 3973: 560.0 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 4852: 259.9 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 6360: 256.4 min round-trip (>240.0 min)\n",
      "   ‚ö†Ô∏è  Filtered out route 6359: 264.5 min round-trip (>240.0 min)\n",
      "‚úÖ Extracted 141 routes\n",
      "\n",
      "=== STEP 2: SIMULATING OPTIMIZATION RESULT ===\n",
      "‚úÖ Using initial solution as optimization result\n",
      "   üìä Solution shape: (141, 8)\n",
      "\n",
      "=== STEP 3: RECONSTRUCTING GTFS ===\n",
      "=== RECONSTRUCTING GTFS WITH OPTIMIZED HEADWAYS ===\n",
      "   üîÑ Generating trips and stop_times for 141 routes\n",
      "   üìç Route 0 (1221): Generated 55 trips\n",
      "   üìç Route 1 (1302): Generated 126 trips\n",
      "   üìç Route 2 (1303): Generated 37 trips\n",
      "   üìç Route 3 (1304): Generated 46 trips\n",
      "   üìç Route 4 (1305): Generated 22 trips\n",
      "   ‚úÖ Generated 7,403 trips with 425,798 stop times\n",
      "   üìä Frequencies.txt disabled - using stop_times.txt only\n",
      "‚úÖ Reconstructed GTFS with stop_times.txt:\n",
      "   üìä 7,403 trips\n",
      "   üìä 425,798 stop times\n",
      "\n",
      "=== STEP 4: SAVING OPTIMIZED GTFS ===\n",
      "‚úÖ Complete GTFS with stop_times.txt saved to: ../data/processed/optimized_gtfs.zip\n",
      "\n",
      "=== WORKFLOW COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# COMPLETE WORKFLOW: DATA PREPARATION ‚Üí OPTIMIZATION ‚Üí RECONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "# 1. PREPARE OPTIMIZATION DATA\n",
    "print(\"=== STEP 1: PREPARING OPTIMIZATION DATA ===\")\n",
    "preparator = GTFSDataPreparator(\n",
    "    gtfs_path='../data/external/study_area_gtfs_bus.zip',\n",
    "    interval_hours=3,  # 8 periods per day\n",
    "    date=None,  # Use full GTFS feed\n",
    "    turnaround_buffer=1.15,  # 15% buffer\n",
    "    max_round_trip_minutes= 240.0  # Maximum round-trip time in minutes\n",
    ")\n",
    "\n",
    "# Define allowed headway values for discrete optimization\n",
    "allowed_headways = [5, 10, 15, 20, 30, 45, 60, 90, 120]  # minutes\n",
    "\n",
    "# Extract optimization data\n",
    "optimization_data = preparator.extract_optimization_data(allowed_headways)\n",
    "\n",
    "# 2. SIMULATE OPTIMIZATION RESULT (since you don't have the actual optimizer yet)\n",
    "print(\"\\n=== STEP 2: SIMULATING OPTIMIZATION RESULT ===\")\n",
    "# For now, use initial solution as the \"optimized\" result\n",
    "simulated_result = {\n",
    "    'headway_solution': optimization_data['initial_solution'],\n",
    "    'objective_value': 1000.0,  # Placeholder\n",
    "    'solve_time': 5.0,  # Placeholder\n",
    "    'status': 'optimal'\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Using initial solution as optimization result\")\n",
    "print(f\"   üìä Solution shape: {simulated_result['headway_solution'].shape}\")\n",
    "\n",
    "# 3. RECONSTRUCT GTFS WITH OPTIMIZED HEADWAYS\n",
    "print(\"\\n=== STEP 3: RECONSTRUCTING GTFS ===\")\n",
    "reconstructor = SimplifiedGTFSReconstructor(optimization_data, simulated_result)\n",
    "\n",
    "# Generate GTFS with stop_times.txt (required for all simulations)\n",
    "new_gtfs_feed = reconstructor.reconstruct_gtfs(use_frequencies=False)\n",
    "\n",
    "\n",
    "# 4. SAVE THE COMPLETE GTFS FEED\n",
    "print(\"\\n=== STEP 4: SAVING OPTIMIZED GTFS ===\")\n",
    "if len(new_gtfs_feed.trips) > 0:\n",
    "    output_path = '../data/processed/optimized_gtfs.zip'\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    import os\n",
    "    os.makedirs('../data/processed', exist_ok=True)\n",
    "    \n",
    "    # Use gtfs-kit's to_file() method - it handles ZIP automatically\n",
    "    new_gtfs_feed.to_file(output_path)\n",
    "    print(f\"‚úÖ Complete GTFS with stop_times.txt saved to: {output_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No trips generated - check optimization solution\")\n",
    "\n",
    "print(\"\\n=== WORKFLOW COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcc2237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headway_solution': array([[8, 2, 4, ..., 9, 1, 2],\n",
       "        [8, 0, 4, ..., 8, 5, 4],\n",
       "        [9, 9, 2, ..., 1, 4, 9],\n",
       "        ...,\n",
       "        [9, 9, 3, ..., 4, 9, 9],\n",
       "        [9, 9, 9, ..., 8, 9, 9],\n",
       "        [9, 9, 9, ..., 9, 9, 9]]),\n",
       " 'objective_value': 1000.0,\n",
       " 'solve_time': 5.0,\n",
       " 'status': 'optimal'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0440b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 2, 4, ..., 9, 1, 2],\n",
       "       [8, 0, 4, ..., 8, 5, 4],\n",
       "       [9, 9, 2, ..., 1, 4, 9],\n",
       "       ...,\n",
       "       [9, 9, 3, ..., 4, 9, 9],\n",
       "       [9, 9, 9, ..., 8, 9, 9],\n",
       "       [9, 9, 9, ..., 9, 9, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the optimisation_data initial_solution dictionary\n",
    "\n",
    "optimization_data['initial_solution']  # Display the initial solution for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15ae9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>stop_direction_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>450030232</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:04:00</td>\n",
       "      <td>00:04:00</td>\n",
       "      <td>450010686</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>450032353</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:05:46</td>\n",
       "      <td>00:05:46</td>\n",
       "      <td>450032368</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:07:13</td>\n",
       "      <td>00:07:13</td>\n",
       "      <td>450010695</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:08:48</td>\n",
       "      <td>00:08:48</td>\n",
       "      <td>450011762</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:09:39</td>\n",
       "      <td>00:09:39</td>\n",
       "      <td>450011761</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:10:46</td>\n",
       "      <td>00:10:46</td>\n",
       "      <td>450011770</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:11:34</td>\n",
       "      <td>00:11:34</td>\n",
       "      <td>450010923</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>450011556</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:13:34</td>\n",
       "      <td>00:13:34</td>\n",
       "      <td>450010924</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:14:51</td>\n",
       "      <td>00:14:51</td>\n",
       "      <td>450011565</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:15:37</td>\n",
       "      <td>00:15:37</td>\n",
       "      <td>450011563</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:16:27</td>\n",
       "      <td>00:16:27</td>\n",
       "      <td>450011566</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:16:48</td>\n",
       "      <td>00:16:48</td>\n",
       "      <td>450014791</td>\n",
       "      <td>14</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:18:00</td>\n",
       "      <td>00:18:00</td>\n",
       "      <td>450011558</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:18:25</td>\n",
       "      <td>00:18:25</td>\n",
       "      <td>450011557</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:19:05</td>\n",
       "      <td>00:19:05</td>\n",
       "      <td>450011559</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:19:48</td>\n",
       "      <td>00:19:48</td>\n",
       "      <td>450011551</td>\n",
       "      <td>18</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:20:17</td>\n",
       "      <td>00:20:17</td>\n",
       "      <td>450011573</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:20:36</td>\n",
       "      <td>00:20:36</td>\n",
       "      <td>450011571</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:21:43</td>\n",
       "      <td>00:21:43</td>\n",
       "      <td>450011574</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:22:11</td>\n",
       "      <td>00:22:11</td>\n",
       "      <td>450011576</td>\n",
       "      <td>22</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:22:42</td>\n",
       "      <td>00:22:42</td>\n",
       "      <td>450011580</td>\n",
       "      <td>23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:23:04</td>\n",
       "      <td>00:23:04</td>\n",
       "      <td>450011579</td>\n",
       "      <td>24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:23:33</td>\n",
       "      <td>00:23:33</td>\n",
       "      <td>450011584</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:24:00</td>\n",
       "      <td>00:24:00</td>\n",
       "      <td>450011307</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:24:40</td>\n",
       "      <td>00:24:40</td>\n",
       "      <td>450014792</td>\n",
       "      <td>27</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:25:03</td>\n",
       "      <td>00:25:03</td>\n",
       "      <td>450018810</td>\n",
       "      <td>28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:26:07</td>\n",
       "      <td>00:26:07</td>\n",
       "      <td>450018807</td>\n",
       "      <td>29</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:26:52</td>\n",
       "      <td>00:26:52</td>\n",
       "      <td>450018805</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:27:41</td>\n",
       "      <td>00:27:41</td>\n",
       "      <td>450018803</td>\n",
       "      <td>31</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:28:02</td>\n",
       "      <td>00:28:02</td>\n",
       "      <td>450018801</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:28:37</td>\n",
       "      <td>00:28:37</td>\n",
       "      <td>450019799</td>\n",
       "      <td>33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:29:18</td>\n",
       "      <td>00:29:18</td>\n",
       "      <td>450019796</td>\n",
       "      <td>34</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:29:58</td>\n",
       "      <td>00:29:58</td>\n",
       "      <td>450019783</td>\n",
       "      <td>35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:30:31</td>\n",
       "      <td>00:30:31</td>\n",
       "      <td>450019781</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:30:57</td>\n",
       "      <td>00:30:57</td>\n",
       "      <td>450019779</td>\n",
       "      <td>37</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:31:44</td>\n",
       "      <td>00:31:44</td>\n",
       "      <td>450019757</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:32:27</td>\n",
       "      <td>00:32:27</td>\n",
       "      <td>450019759</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:33:07</td>\n",
       "      <td>00:33:07</td>\n",
       "      <td>450019761</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:34:22</td>\n",
       "      <td>00:34:22</td>\n",
       "      <td>450019786</td>\n",
       "      <td>41</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>opt_1221_0_0</td>\n",
       "      <td>00:35:00</td>\n",
       "      <td>00:35:00</td>\n",
       "      <td>450025387</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>450030232</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:04:00</td>\n",
       "      <td>03:04:00</td>\n",
       "      <td>450010686</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:05:00</td>\n",
       "      <td>03:05:00</td>\n",
       "      <td>450032353</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:05:46</td>\n",
       "      <td>03:05:46</td>\n",
       "      <td>450032368</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:07:13</td>\n",
       "      <td>03:07:13</td>\n",
       "      <td>450010695</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:08:48</td>\n",
       "      <td>03:08:48</td>\n",
       "      <td>450011762</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>opt_1221_1_0</td>\n",
       "      <td>03:09:39</td>\n",
       "      <td>03:09:39</td>\n",
       "      <td>450011761</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_id arrival_time departure_time    stop_id  stop_sequence  \\\n",
       "0   opt_1221_0_0     00:00:00       00:00:00  450030232              0   \n",
       "1   opt_1221_0_0     00:04:00       00:04:00  450010686              1   \n",
       "2   opt_1221_0_0     00:05:00       00:05:00  450032353              2   \n",
       "3   opt_1221_0_0     00:05:46       00:05:46  450032368              3   \n",
       "4   opt_1221_0_0     00:07:13       00:07:13  450010695              4   \n",
       "5   opt_1221_0_0     00:08:48       00:08:48  450011762              5   \n",
       "6   opt_1221_0_0     00:09:39       00:09:39  450011761              6   \n",
       "7   opt_1221_0_0     00:10:46       00:10:46  450011770              7   \n",
       "8   opt_1221_0_0     00:11:34       00:11:34  450010923              8   \n",
       "9   opt_1221_0_0     00:12:36       00:12:36  450011556              9   \n",
       "10  opt_1221_0_0     00:13:34       00:13:34  450010924             10   \n",
       "11  opt_1221_0_0     00:14:51       00:14:51  450011565             11   \n",
       "12  opt_1221_0_0     00:15:37       00:15:37  450011563             12   \n",
       "13  opt_1221_0_0     00:16:27       00:16:27  450011566             13   \n",
       "14  opt_1221_0_0     00:16:48       00:16:48  450014791             14   \n",
       "15  opt_1221_0_0     00:18:00       00:18:00  450011558             15   \n",
       "16  opt_1221_0_0     00:18:25       00:18:25  450011557             16   \n",
       "17  opt_1221_0_0     00:19:05       00:19:05  450011559             17   \n",
       "18  opt_1221_0_0     00:19:48       00:19:48  450011551             18   \n",
       "19  opt_1221_0_0     00:20:17       00:20:17  450011573             19   \n",
       "20  opt_1221_0_0     00:20:36       00:20:36  450011571             20   \n",
       "21  opt_1221_0_0     00:21:43       00:21:43  450011574             21   \n",
       "22  opt_1221_0_0     00:22:11       00:22:11  450011576             22   \n",
       "23  opt_1221_0_0     00:22:42       00:22:42  450011580             23   \n",
       "24  opt_1221_0_0     00:23:04       00:23:04  450011579             24   \n",
       "25  opt_1221_0_0     00:23:33       00:23:33  450011584             25   \n",
       "26  opt_1221_0_0     00:24:00       00:24:00  450011307             26   \n",
       "27  opt_1221_0_0     00:24:40       00:24:40  450014792             27   \n",
       "28  opt_1221_0_0     00:25:03       00:25:03  450018810             28   \n",
       "29  opt_1221_0_0     00:26:07       00:26:07  450018807             29   \n",
       "30  opt_1221_0_0     00:26:52       00:26:52  450018805             30   \n",
       "31  opt_1221_0_0     00:27:41       00:27:41  450018803             31   \n",
       "32  opt_1221_0_0     00:28:02       00:28:02  450018801             32   \n",
       "33  opt_1221_0_0     00:28:37       00:28:37  450019799             33   \n",
       "34  opt_1221_0_0     00:29:18       00:29:18  450019796             34   \n",
       "35  opt_1221_0_0     00:29:58       00:29:58  450019783             35   \n",
       "36  opt_1221_0_0     00:30:31       00:30:31  450019781             36   \n",
       "37  opt_1221_0_0     00:30:57       00:30:57  450019779             37   \n",
       "38  opt_1221_0_0     00:31:44       00:31:44  450019757             38   \n",
       "39  opt_1221_0_0     00:32:27       00:32:27  450019759             39   \n",
       "40  opt_1221_0_0     00:33:07       00:33:07  450019761             40   \n",
       "41  opt_1221_0_0     00:34:22       00:34:22  450019786             41   \n",
       "42  opt_1221_0_0     00:35:00       00:35:00  450025387             42   \n",
       "43  opt_1221_1_0     03:00:00       03:00:00  450030232              0   \n",
       "44  opt_1221_1_0     03:04:00       03:04:00  450010686              1   \n",
       "45  opt_1221_1_0     03:05:00       03:05:00  450032353              2   \n",
       "46  opt_1221_1_0     03:05:46       03:05:46  450032368              3   \n",
       "47  opt_1221_1_0     03:07:13       03:07:13  450010695              4   \n",
       "48  opt_1221_1_0     03:08:48       03:08:48  450011762              5   \n",
       "49  opt_1221_1_0     03:09:39       03:09:39  450011761              6   \n",
       "\n",
       "   stop_headsign  pickup_type  drop_off_type  shape_dist_traveled  timepoint  \\\n",
       "0           <NA>            0              1                  NaN          1   \n",
       "1           <NA>            0              0                  NaN          0   \n",
       "2           <NA>            0              0                  NaN          1   \n",
       "3           <NA>            0              0                  NaN          0   \n",
       "4           <NA>            0              0                  NaN          0   \n",
       "5           <NA>            0              0                  NaN          0   \n",
       "6           <NA>            0              0                  NaN          0   \n",
       "7           <NA>            0              0                  NaN          0   \n",
       "8           <NA>            0              0                  NaN          0   \n",
       "9           <NA>            0              0                  NaN          0   \n",
       "10          <NA>            0              0                  NaN          0   \n",
       "11          <NA>            0              0                  NaN          0   \n",
       "12          <NA>            0              0                  NaN          0   \n",
       "13          <NA>            0              0                  NaN          0   \n",
       "14          <NA>            0              0                  NaN          0   \n",
       "15          <NA>            0              0                  NaN          1   \n",
       "16          <NA>            0              0                  NaN          0   \n",
       "17          <NA>            0              0                  NaN          0   \n",
       "18          <NA>            0              0                  NaN          0   \n",
       "19          <NA>            0              0                  NaN          0   \n",
       "20          <NA>            0              0                  NaN          0   \n",
       "21          <NA>            0              0                  NaN          0   \n",
       "22          <NA>            0              0                  NaN          0   \n",
       "23          <NA>            0              0                  NaN          0   \n",
       "24          <NA>            0              0                  NaN          0   \n",
       "25          <NA>            0              0                  NaN          0   \n",
       "26          <NA>            0              0                  NaN          1   \n",
       "27          <NA>            0              0                  NaN          0   \n",
       "28          <NA>            0              0                  NaN          0   \n",
       "29          <NA>            0              0                  NaN          0   \n",
       "30          <NA>            0              0                  NaN          0   \n",
       "31          <NA>            0              0                  NaN          0   \n",
       "32          <NA>            0              0                  NaN          0   \n",
       "33          <NA>            0              0                  NaN          0   \n",
       "34          <NA>            0              0                  NaN          0   \n",
       "35          <NA>            0              0                  NaN          0   \n",
       "36          <NA>            0              0                  NaN          0   \n",
       "37          <NA>            0              0                  NaN          0   \n",
       "38          <NA>            0              0                  NaN          0   \n",
       "39          <NA>            0              0                  NaN          0   \n",
       "40          <NA>            0              0                  NaN          0   \n",
       "41          <NA>            0              0                  NaN          0   \n",
       "42          <NA>            1              0                  NaN          1   \n",
       "43          <NA>            0              1                  NaN          1   \n",
       "44          <NA>            0              0                  NaN          0   \n",
       "45          <NA>            0              0                  NaN          1   \n",
       "46          <NA>            0              0                  NaN          0   \n",
       "47          <NA>            0              0                  NaN          0   \n",
       "48          <NA>            0              0                  NaN          0   \n",
       "49          <NA>            0              0                  NaN          0   \n",
       "\n",
       "    stop_direction_name  \n",
       "0                  <NA>  \n",
       "1                  <NA>  \n",
       "2                  <NA>  \n",
       "3                  <NA>  \n",
       "4                  <NA>  \n",
       "5                  <NA>  \n",
       "6                  <NA>  \n",
       "7                  <NA>  \n",
       "8                  <NA>  \n",
       "9                  <NA>  \n",
       "10                 <NA>  \n",
       "11                 <NA>  \n",
       "12                 <NA>  \n",
       "13                 <NA>  \n",
       "14                 <NA>  \n",
       "15                 <NA>  \n",
       "16                 <NA>  \n",
       "17                 <NA>  \n",
       "18                 <NA>  \n",
       "19                 <NA>  \n",
       "20                 <NA>  \n",
       "21                 <NA>  \n",
       "22                 <NA>  \n",
       "23                 <NA>  \n",
       "24                 <NA>  \n",
       "25                 <NA>  \n",
       "26                 <NA>  \n",
       "27                 <NA>  \n",
       "28                 <NA>  \n",
       "29                 <NA>  \n",
       "30                 <NA>  \n",
       "31                 <NA>  \n",
       "32                 <NA>  \n",
       "33                 <NA>  \n",
       "34                 <NA>  \n",
       "35                 <NA>  \n",
       "36                 <NA>  \n",
       "37                 <NA>  \n",
       "38                 <NA>  \n",
       "39                 <NA>  \n",
       "40                 <NA>  \n",
       "41                 <NA>  \n",
       "42                 <NA>  \n",
       "43                 <NA>  \n",
       "44                 <NA>  \n",
       "45                 <NA>  \n",
       "46                 <NA>  \n",
       "47                 <NA>  \n",
       "48                 <NA>  \n",
       "49                 <NA>  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gtfs_feed.stop_times.head(50)  # Display the first few trips in the reconstructed GTFS feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb61c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this new cell to your notebook\n",
    "import numpy as np\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.variable import Real, Integer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SpatialEquityProblem(ElementwiseProblem):\n",
    "    \"\"\"\n",
    "    PyMOO problem definition for spatial equity optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimization_data, zone_system, min_fleet_factor=0.8):\n",
    "        self.opt_data = optimization_data\n",
    "        self.zone_system = zone_system\n",
    "        self.min_fleet_factor = min_fleet_factor\n",
    "        \n",
    "        # Problem dimensions\n",
    "        self.n_routes = optimization_data['n_routes']\n",
    "        self.n_intervals = optimization_data['n_intervals'] \n",
    "        self.n_choices = optimization_data['n_choices_per_variable']\n",
    "        self.n_vars = self.n_routes * self.n_intervals\n",
    "        \n",
    "        # Calculate fleet constraints\n",
    "        self.baseline_vehicles = self._calculate_baseline_fleet()\n",
    "        self.min_required_vehicles = int(self.baseline_vehicles * min_fleet_factor)\n",
    "        \n",
    "        print(f\"üöó Fleet constraints:\")\n",
    "        print(f\"   üìä Current fleet size: {self.baseline_vehicles} vehicles\")\n",
    "        print(f\"   üìä Minimum required: {self.min_required_vehicles} vehicles ({min_fleet_factor:.1%})\")\n",
    "        \n",
    "        # Define problem: discrete variables (0 to n_choices-1)\n",
    "        super().__init__(\n",
    "            n_var=self.n_vars,\n",
    "            n_obj=1,  # Single objective: minimize variance\n",
    "            n_ieq_constr=2,  # 2 inequality constraints\n",
    "            vars={\n",
    "                f'x{i}': Integer(bounds=(0, self.n_choices-1)) \n",
    "                for i in range(self.n_vars)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def _calculate_baseline_fleet(self):\n",
    "        \"\"\"Calculate current fleet size.\"\"\"\n",
    "        initial_solution = self.opt_data['initial_solution']\n",
    "        vehicles_per_zone = self.zone_system.calculate_vehicles_per_zone(\n",
    "            initial_solution, self.opt_data\n",
    "        )\n",
    "        return int(np.sum(vehicles_per_zone))\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Evaluate single solution.\n",
    "        \n",
    "        Args:\n",
    "            x: Decision variables (flattened array of discrete choices)\n",
    "        \"\"\"\n",
    "        # Convert to solution matrix\n",
    "        solution_matrix = x.reshape(self.n_routes, self.n_intervals)\n",
    "        \n",
    "        # Calculate vehicles per zone\n",
    "        vehicles_per_zone = self.zone_system.calculate_vehicles_per_zone(\n",
    "            solution_matrix, self.opt_data\n",
    "        )\n",
    "        \n",
    "        # Primary objective: minimize variance in vehicles per zone\n",
    "        if len(vehicles_per_zone) > 1 and np.sum(vehicles_per_zone) > 0:\n",
    "            objective = np.var(vehicles_per_zone)\n",
    "        else:\n",
    "            objective = 0.0\n",
    "        \n",
    "        # Constraint 1: Minimum fleet size\n",
    "        total_vehicles = np.sum(vehicles_per_zone)\n",
    "        fleet_constraint = self.min_required_vehicles - total_vehicles  # <= 0\n",
    "        \n",
    "        # Constraint 2: Maximum service reduction (no more than 60% no-service)\n",
    "        no_service_count = np.sum(solution_matrix == (self.n_choices - 1))\n",
    "        no_service_ratio = no_service_count / solution_matrix.size\n",
    "        service_constraint = no_service_ratio - 0.6  # <= 0\n",
    "        \n",
    "        # Set outputs\n",
    "        out[\"F\"] = [objective]  # Objective (minimize variance)\n",
    "        out[\"G\"] = [fleet_constraint, service_constraint]  # Constraints (‚â§ 0)\n",
    "\n",
    "def run_pymoo_optimization(optimization_data, zone_system, min_fleet_factor=0.8):\n",
    "    \"\"\"\n",
    "    Run spatial equity optimization using PyMOO PSO.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting PyMOO PSO Optimization...\")\n",
    "    \n",
    "    # Create problem\n",
    "    problem = SpatialEquityProblem(optimization_data, zone_system, min_fleet_factor)\n",
    "    \n",
    "    # Setup PSO algorithm\n",
    "    algorithm = PSO(\n",
    "        pop_size=30,           # Number of particles\n",
    "        w=0.9,                 # Inertia weight\n",
    "        c1=2.0,                # Cognitive parameter\n",
    "        c2=2.0,                # Social parameter\n",
    "        adaptive=True,         # Adaptive parameters\n",
    "        max_velocity_rate=0.2  # Max velocity as fraction of variable range\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    result = minimize(\n",
    "        problem,\n",
    "        algorithm,\n",
    "        termination=('n_gen', 100),  # 100 generations\n",
    "        verbose=True,\n",
    "        save_history=True\n",
    "    )\n",
    "    \n",
    "    # Extract best solution\n",
    "    best_x = result.X\n",
    "    best_solution_matrix = best_x.reshape(\n",
    "        optimization_data['n_routes'], \n",
    "        optimization_data['n_intervals']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ PyMOO PSO completed\")\n",
    "    print(f\"   üéØ Final objective value: {result.F[0]:.4f}\")\n",
    "    print(f\"   üìä Constraint violations: {result.G}\")\n",
    "    \n",
    "    return {\n",
    "        'headway_solution': best_solution_matrix,\n",
    "        'objective_value': result.F[0],\n",
    "        'constraints': result.G,\n",
    "        'solve_time': 0.0,  # PyMOO doesn't track this directly\n",
    "        'status': 'optimal',\n",
    "        'pymoo_result': result  # Keep full result for analysis\n",
    "    }\n",
    "\n",
    "def plot_pymoo_convergence(result):\n",
    "    \"\"\"Plot PyMOO optimization convergence.\"\"\"\n",
    "    if not hasattr(result, 'history'):\n",
    "        print(\"‚ö†Ô∏è  No history available for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Extract convergence data\n",
    "    generations = []\n",
    "    objectives = []\n",
    "    \n",
    "    for entry in result.history:\n",
    "        generations.append(entry.n_gen)\n",
    "        # Get best objective value in this generation\n",
    "        best_f = np.min(entry.pop.get(\"F\"))\n",
    "        objectives.append(best_f)\n",
    "    \n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Objective convergence\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(generations, objectives, 'b-', linewidth=2)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Best Objective (Variance)')\n",
    "    plt.title('PyMOO PSO - Objective Convergence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Constraint violations (if any)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if result.G is not None and len(result.G) > 0:\n",
    "        constraint_labels = ['Fleet Size', 'Service Level']\n",
    "        plt.bar(constraint_labels, result.G)\n",
    "        plt.ylabel('Constraint Violation')\n",
    "        plt.title('Final Constraint Status\\n(‚â§ 0 = satisfied)')\n",
    "        plt.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No Constraints\\nViolated', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Constraint Status')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6adbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ef987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c92a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HexagonalZoneSystem:\n",
    "    \"\"\"\n",
    "    Optimized hexagonal zoning system using spatial indexing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 gtfs_feed,\n",
    "                 hex_size_km: float = 2.0,\n",
    "                 crs: str = \"EPSG:4326\"):\n",
    "        self.gtfs_feed = gtfs_feed\n",
    "        self.hex_size_km = hex_size_km\n",
    "        self.crs = crs\n",
    "        \n",
    "        # Create stop locations GeoDataFrame\n",
    "        self.stops_gdf = self._create_stops_geodataframe()\n",
    "        \n",
    "        # Generate hexagonal grid\n",
    "        self.hex_grid = self._create_hexagonal_grid()\n",
    "        \n",
    "        # OPTIMIZED: Use spatial join instead of nested loops\n",
    "        self.stop_zone_mapping = self._fast_map_stops_to_zones()\n",
    "        \n",
    "        # OPTIMIZED: Pre-compute route-stop mappings\n",
    "        self._precompute_route_stop_mappings()\n",
    "    \n",
    "    def _fast_map_stops_to_zones(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        OPTIMIZED: Use spatial join - O(S + Z) instead of O(S √ó Z).\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Using spatial join for zone mapping...\")\n",
    "        \n",
    "        # Spatial join: finds containing zone for each stop in one operation\n",
    "        stops_with_zones = gpd.sjoin(\n",
    "            self.stops_gdf, \n",
    "            self.hex_grid, \n",
    "            how='left', \n",
    "            predicate='within'\n",
    "        )\n",
    "        \n",
    "        # Convert to dictionary\n",
    "        stop_zone_map = {}\n",
    "        for idx, row in stops_with_zones.iterrows():\n",
    "            if pd.notna(row['zone_id']):\n",
    "                stop_zone_map[row['stop_id']] = row['zone_id']\n",
    "            else:\n",
    "                # Handle stops not in any zone (find nearest)\n",
    "                stop_point = row.geometry\n",
    "                distances = self.hex_grid.geometry.distance(stop_point)\n",
    "                nearest_zone_idx = distances.idxmin()\n",
    "                stop_zone_map[row['stop_id']] = self.hex_grid.loc[nearest_zone_idx, 'zone_id']\n",
    "        \n",
    "        return stop_zone_map\n",
    "    \n",
    "    def _precompute_route_stop_mappings(self):\n",
    "        \"\"\"\n",
    "        OPTIMIZED: Pre-compute all route ‚Üí stops mappings to avoid repeated filtering.\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Pre-computing route-stop mappings...\")\n",
    "        \n",
    "        self.route_stops_cache = {}\n",
    "        \n",
    "        # Group trips by service_id once\n",
    "        trips_by_service = self.gtfs_feed.trips.groupby('service_id')['trip_id'].apply(list).to_dict()\n",
    "        \n",
    "        # Group stop_times by trip_id once  \n",
    "        stop_times_by_trip = self.gtfs_feed.stop_times.groupby('trip_id')['stop_id'].apply(set)\n",
    "        \n",
    "        for service_id, trip_ids in trips_by_service.items():\n",
    "            # Get all unique stops for this service\n",
    "            service_stops = set()\n",
    "            for trip_id in trip_ids:\n",
    "                if trip_id in stop_times_by_trip:\n",
    "                    service_stops.update(stop_times_by_trip[trip_id])\n",
    "            \n",
    "            self.route_stops_cache[service_id] = service_stops\n",
    "    \n",
    "    def calculate_vehicles_per_zone(self, \n",
    "                              solution_matrix: np.ndarray,\n",
    "                              optimization_data: Dict[str, Any]) -> np.ndarray:\n",
    "        \"\"\"UPDATED: Use new optimization data structure.\"\"\"\n",
    "        # Initialize zone counts\n",
    "        zone_counts = {zone_id: 0 for zone_id in self.hex_grid['zone_id']}\n",
    "        \n",
    "        # UPDATED: Access data from new structure\n",
    "        route_ids = optimization_data['routes']['ids']\n",
    "        allowed_headways = optimization_data['allowed_headways']\n",
    "        round_trip_times = optimization_data['routes']['round_trip_times']\n",
    "        no_service_index = optimization_data['no_service_index']\n",
    "        \n",
    "        for route_idx, service_id in enumerate(route_ids):\n",
    "            # Use cached stops instead of filtering DataFrames\n",
    "            if service_id not in self.route_stops_cache:\n",
    "                continue\n",
    "            \n",
    "            service_stops = self.route_stops_cache[service_id]\n",
    "            \n",
    "            # Calculate max vehicles for this route\n",
    "            max_vehicles = 0\n",
    "            for interval_idx in range(optimization_data['n_intervals']):\n",
    "                choice_idx = solution_matrix[route_idx, interval_idx]\n",
    "                \n",
    "                # Skip no-service choices\n",
    "                if choice_idx == no_service_index:\n",
    "                    continue\n",
    "                    \n",
    "                headway = allowed_headways[choice_idx]\n",
    "                \n",
    "                if headway < 9000:\n",
    "                    round_trip = round_trip_times[route_idx]\n",
    "                    vehicles_in_interval = max(1, int(round_trip / headway))\n",
    "                    max_vehicles = max(max_vehicles, vehicles_in_interval)\n",
    "            \n",
    "            # Add vehicles to zones served by this route\n",
    "            zones_served = {\n",
    "                self.stop_zone_mapping[stop_id] \n",
    "                for stop_id in service_stops \n",
    "                if stop_id in self.stop_zone_mapping\n",
    "            }\n",
    "            \n",
    "            for zone_id in zones_served:\n",
    "                zone_counts[zone_id] += max_vehicles\n",
    "        \n",
    "        return np.array(list(zone_counts.values()))\n",
    "\n",
    "    def _create_hexagonal_grid(self) -> gpd.GeoDataFrame:\n",
    "        \"\"\"\n",
    "        IMPROVED: Use proper hexagonal grid (H3 library recommended).\n",
    "        \"\"\"\n",
    "        # For now, keep your existing implementation\n",
    "        # TODO: Replace with H3 hexagons for true hexagonal tiling\n",
    "        bounds = self.stops_gdf.total_bounds\n",
    "        \n",
    "        buffer = self.hex_size_km / 111\n",
    "        minx, miny, maxx, maxy = bounds\n",
    "        minx -= buffer\n",
    "        miny -= buffer  \n",
    "        maxx += buffer\n",
    "        maxy += buffer\n",
    "        \n",
    "        hex_polygons = []\n",
    "        zone_ids = []\n",
    "        \n",
    "        x_steps = int((maxx - minx) / (self.hex_size_km / 111))\n",
    "        y_steps = int((maxy - miny) / (self.hex_size_km / 111))\n",
    "        \n",
    "        zone_id = 0\n",
    "        for i in range(x_steps):\n",
    "            for j in range(y_steps):\n",
    "                x = minx + i * (self.hex_size_km / 111)\n",
    "                y = miny + j * (self.hex_size_km / 111)\n",
    "                \n",
    "                from shapely.geometry import Polygon\n",
    "                cell = Polygon([\n",
    "                    (x, y), (x + self.hex_size_km/111, y),\n",
    "                    (x + self.hex_size_km/111, y + self.hex_size_km/111),\n",
    "                    (x, y + self.hex_size_km/111)\n",
    "                ])\n",
    "                \n",
    "                hex_polygons.append(cell)\n",
    "                zone_ids.append(f\"zone_{zone_id}\")\n",
    "                zone_id += 1\n",
    "        \n",
    "        return gpd.GeoDataFrame({\n",
    "            'zone_id': zone_ids,\n",
    "            'geometry': hex_polygons\n",
    "        }, crs=self.crs)\n",
    "    \n",
    "    def _create_stops_geodataframe(self) -> gpd.GeoDataFrame:\n",
    "        \"\"\"Same as original - this is already efficient.\"\"\"\n",
    "        stops = self.gtfs_feed.stops.copy()\n",
    "        geometry = [Point(lon, lat) for lon, lat in zip(stops['stop_lon'], stops['stop_lat'])]\n",
    "        return gpd.GeoDataFrame(stops, geometry=geometry, crs=self.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to your existing workflow (after Step 1)\n",
    "\n",
    "# 1.5. CREATE ZONING SYSTEM\n",
    "print(\"\\n=== STEP 1.5: CREATING HEXAGONAL ZONING SYSTEM ===\")\n",
    "zone_system = HexagonalZoneSystem(\n",
    "    gtfs_feed=optimization_data['gtfs_feed'],\n",
    "    hex_size_km=2.0  # 2km hexagons\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created {len(zone_system.hex_grid)} hexagonal zones\")\n",
    "\n",
    "# After creating zone_system, add:\n",
    "print(f\"DEBUG: Created {len(zone_system.hex_grid)} zones\")\n",
    "print(f\"DEBUG: Mapped {len(zone_system.stop_zone_mapping)} stops to zones\")\n",
    "print(f\"DEBUG: Route cache has {len(zone_system.route_stops_cache)} routes\")\n",
    "\n",
    "# Sample some mappings:\n",
    "sample_stops = list(zone_system.stop_zone_mapping.items())[:5]\n",
    "print(f\"DEBUG: Sample stop-zone mappings: {sample_stops}\")\n",
    "\n",
    "# 2. RUN PYMOO OPTIMIZATION  \n",
    "print(\"\\n=== STEP 2: PYMOO PSO SPATIAL EQUITY OPTIMIZATION ===\")\n",
    "\n",
    "# Add debugging before optimization\n",
    "print(\"üîç DEBUGGING OPTIMIZATION DATA:\")\n",
    "\n",
    "# Check for None values in critical data\n",
    "route_ids = optimization_data['route_ids']\n",
    "round_trip_times = optimization_data['round_trip_times']\n",
    "\n",
    "print(f\"Route IDs: {len(route_ids)} routes\")\n",
    "print(f\"Round trip times: {len(round_trip_times)} values\")\n",
    "\n",
    "# Check for None/NaN in round trip times\n",
    "none_count = sum(1 for x in round_trip_times if x is None)\n",
    "nan_count = sum(1 for x in round_trip_times if pd.isna(x))\n",
    "print(f\"None round trip times: {none_count}\")\n",
    "print(f\"NaN round trip times: {nan_count}\")\n",
    "\n",
    "# Check route cache\n",
    "missing_routes = [rid for rid in route_ids if rid not in zone_system.route_stops_cache]\n",
    "print(f\"Missing routes in cache: {len(missing_routes)}\")\n",
    "if missing_routes:\n",
    "    print(f\"First few missing: {missing_routes[:5]}\")\n",
    "\n",
    "# Check stop mappings\n",
    "print(f\"Stop-zone mappings: {len(zone_system.stop_zone_mapping)}\")\n",
    "\n",
    "# Run PyMOO optimization\n",
    "pymoo_result = run_pymoo_optimization(\n",
    "    optimization_data, \n",
    "    zone_system, \n",
    "    min_fleet_factor=0.8\n",
    ")\n",
    "\n",
    "# Plot convergence\n",
    "plot_pymoo_convergence(pymoo_result['pymoo_result'])\n",
    "\n",
    "# Use PyMOO result for reconstruction\n",
    "pso_result = pymoo_result  # Compatible format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING CELL: Find the problematic data\n",
    "print(\"üîç DETAILED DEBUGGING:\")\n",
    "\n",
    "route_ids = optimization_data['route_ids']\n",
    "round_trip_times = optimization_data['round_trip_times']\n",
    "\n",
    "print(f\"Data types:\")\n",
    "print(f\"  round_trip_times type: {type(round_trip_times)}\")\n",
    "print(f\"  First 5 values: {round_trip_times[:5]}\")\n",
    "print(f\"  Value types: {[type(x) for x in round_trip_times[:5]]}\")\n",
    "\n",
    "# Check for extreme values\n",
    "print(f\"\\nRound trip time statistics:\")\n",
    "print(f\"  Min: {np.min(round_trip_times)}\")\n",
    "print(f\"  Max: {np.max(round_trip_times)}\")\n",
    "print(f\"  Mean: {np.mean(round_trip_times)}\")\n",
    "\n",
    "# Look for problematic values\n",
    "extreme_values = [(i, rt) for i, rt in enumerate(round_trip_times) if rt > 200 or rt < 5]\n",
    "if extreme_values:\n",
    "    print(f\"Extreme round trip times: {extreme_values[:10]}\")\n",
    "\n",
    "# Test a single vehicle calculation\n",
    "test_headway = 15.0\n",
    "test_round_trip = round_trip_times[0]\n",
    "test_vehicles = test_round_trip / test_headway\n",
    "print(f\"\\nTest calculation:\")\n",
    "print(f\"  Round trip: {test_round_trip} (type: {type(test_round_trip)})\")\n",
    "print(f\"  Headway: {test_headway}\")\n",
    "print(f\"  Vehicles needed: {test_vehicles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46eaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Find problematic routes\n",
    "print(\"\\nüîç ANALYZING EXTREME ROUND-TRIP TIMES:\")\n",
    "\n",
    "extreme_indices = [i for i, rt in enumerate(round_trip_times) if rt > 200]\n",
    "print(f\"Found {len(extreme_indices)} routes with >200min round-trips\")\n",
    "\n",
    "for i in extreme_indices[:10]:  # Show first 10\n",
    "    service_id = route_ids[i]\n",
    "    rt_time = round_trip_times[i]\n",
    "    \n",
    "    # Get sample trip for this service\n",
    "    service_trips = optimization_data['gtfs_feed'].trips[\n",
    "        optimization_data['gtfs_feed'].trips['service_id'] == service_id\n",
    "    ]\n",
    "    \n",
    "    if len(service_trips) > 0:\n",
    "        sample_trip = service_trips.iloc[0]['trip_id']\n",
    "        trip_stops = optimization_data['gtfs_feed'].stop_times[\n",
    "            optimization_data['gtfs_feed'].stop_times['trip_id'] == sample_trip\n",
    "        ].sort_values('stop_sequence')\n",
    "        \n",
    "        if len(trip_stops) >= 2:\n",
    "            start_time = trip_stops.iloc[0]['departure_time']\n",
    "            end_time = trip_stops.iloc[-1]['arrival_time']\n",
    "            print(f\"  Route {service_id}: {rt_time:.1f}min ({start_time} ‚Üí {end_time})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transit_opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
