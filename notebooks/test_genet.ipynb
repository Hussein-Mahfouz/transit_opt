{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genet  \n",
    "from genet import read_gtfs\n",
    "from genet import read_matsim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383803be",
   "metadata": {},
   "source": [
    "# Read in the GTFS feed using genet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d6bc6",
   "metadata": {},
   "source": [
    "Genet expects specific columns such as `route_color` to be present in the GTFS feed. We add this column as it does not exist in the original GTFS feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cebff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/external/study_area_gtfs_bus.zip to ./gtfs_extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 15:17:40,043 - Reading GTFS from ./gtfs_extracted\n",
      "2025-07-30 15:17:40,044 - Reading the calendar for GTFS\n",
      "2025-07-30 15:17:40,045 - Reading GTFS data into usable format\n",
      "2025-07-30 15:17:40,045 - Reading stops\n",
      "2025-07-30 15:17:40,057 - Reading stop times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10 files\n",
      "\n",
      "Original routes.txt:\n",
      "  Columns: ['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']\n",
      "  Number of routes: 187\n",
      "Found 24 agencies: ['OP134', 'OP192', 'OP2350', 'OP318', 'OP5050', 'OP5051', 'OP564', 'OP658', 'OP662', 'OP664', 'OP665', 'OP666', 'OP671', 'OP672', 'OP6801', 'OP8944', 'OP8945', 'OP929', 'OP930', 'OP931', 'OP932', 'OP933', 'OP937', 'OP938']\n",
      "  Agency 1: OP134 -> #0078D4\n",
      "  Agency 2: OP192 -> #FF6B35\n",
      "  Agency 3: OP2350 -> #10B981\n",
      "  Agency 4: OP318 -> #EF4444\n",
      "  Agency 5: OP5050 -> #8B5CF6\n",
      "  Agency 6: OP5051 -> #F59E0B\n",
      "  Agency 7: OP564 -> #EC4899\n",
      "  Agency 8: OP658 -> #00BCF2\n",
      "  Agency 9: OP662 -> #8B5A2B\n",
      "  Agency 10: OP664 -> #6B7280\n",
      "  Agency 11: OP665 -> #0078D4\n",
      "  Agency 12: OP666 -> #FF6B35\n",
      "  Agency 13: OP671 -> #10B981\n",
      "  Agency 14: OP672 -> #EF4444\n",
      "  Agency 15: OP6801 -> #8B5CF6\n",
      "  Agency 16: OP8944 -> #F59E0B\n",
      "  Agency 17: OP8945 -> #EC4899\n",
      "  Agency 18: OP929 -> #00BCF2\n",
      "  Agency 19: OP930 -> #8B5A2B\n",
      "  Agency 20: OP931 -> #6B7280\n",
      "  Agency 21: OP932 -> #0078D4\n",
      "  Agency 22: OP933 -> #FF6B35\n",
      "  Agency 23: OP937 -> #10B981\n",
      "  Agency 24: OP938 -> #EF4444\n",
      "\n",
      "Updated routes.txt saved with route_color column\n",
      "\n",
      "Sample of updated routes:\n",
      " route_id agency_id route_short_name route_color\n",
      "    50627    OP6801               A1      8B5CF6\n",
      "    50628    OP6801               A2      8B5CF6\n",
      "    50629    OP6801               A3      8B5CF6\n",
      "    58940     OP671              PH5      10B981\n",
      "    22577     OP318               60      EF4444\n",
      "    29092     OP671              PH3      10B981\n",
      "    20991     OP662               A2      8B5A2B\n",
      "    12826     OP664                7      6B7280\n",
      "    50625     OP662               A3      8B5A2B\n",
      "    25842     OP931                5      6B7280\n",
      "\n",
      "GTFS data prepared successfully in: ./gtfs_extracted\n",
      "\n",
      "Loading GTFS with genet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 15:17:40,986 - Reading routes\n",
      "2025-07-30 15:17:40,989 - Reading trips\n",
      "2025-07-30 15:17:44,150 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450012625']\n",
      "2025-07-30 15:17:44,207 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:44,251 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014725']\n",
      "2025-07-30 15:17:44,304 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:44,406 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:44,443 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:44,566 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:44,597 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:44,683 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:44,728 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:44,842 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:44,931 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:44,941 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:44,995 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:45,110 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:45,201 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:45,205 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:45,219 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010461']\n",
      "2025-07-30 15:17:45,274 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:45,604 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:45,628 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:45,792 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:45,968 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:46,002 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:46,029 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:46,127 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:46,155 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:46,251 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:46,282 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:46,393 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:46,620 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010495']\n",
      "2025-07-30 15:17:46,675 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:46,680 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:46,684 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:17:46,800 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:46,937 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:46,957 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:46,961 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:47,065 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:47,072 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:47,143 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:47,175 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:47,201 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:47,217 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450011382']\n",
      "2025-07-30 15:17:47,221 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:47,313 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:47,486 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:47,518 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:47,579 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:17:47,801 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:47,807 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:47,871 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:47,878 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:47,950 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:47,974 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014725']\n",
      "2025-07-30 15:17:48,039 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:48,111 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:48,162 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:17:48,209 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:48,273 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:48,303 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:48,375 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:48,389 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:48,486 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:48,583 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:48,589 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014463']\n",
      "2025-07-30 15:17:48,632 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:48,717 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:48,722 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:48,734 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:48,923 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:48,949 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:49,028 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:49,060 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:49,065 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:49,101 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:49,134 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:49,378 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:49,636 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:49,727 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450011751']\n",
      "2025-07-30 15:17:49,873 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:49,947 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:49,981 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:50,002 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:50,179 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:50,183 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:50,197 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:50,255 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014763']\n",
      "2025-07-30 15:17:50,559 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:50,569 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:50,586 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:50,805 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:50,893 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:51,111 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:51,175 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:51,245 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:51,320 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:51,434 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:51,543 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:51,585 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:51,666 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:51,681 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:51,697 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:51,763 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:51,801 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:51,886 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:51,891 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:51,977 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:52,148 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:52,184 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:52,224 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025301']\n",
      "2025-07-30 15:17:52,287 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:52,388 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:52,420 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:52,588 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:52,652 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:52,690 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:52,693 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:52,731 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:52,782 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:52,821 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:52,911 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:52,959 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:53,033 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:53,037 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:53,044 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:53,054 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:53,102 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:53,109 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:53,120 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:53,167 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025301']\n",
      "2025-07-30 15:17:53,266 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:53,354 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:53,381 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:53,606 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:53,614 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:53,711 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:53,725 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:53,843 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:17:53,911 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:54,008 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025307', '450011382']\n",
      "2025-07-30 15:17:54,012 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:54,059 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:54,238 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:54,253 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:54,298 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:54,446 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:54,463 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:54,494 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:54,578 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:54,645 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:54,685 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:54,834 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:54,984 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:54,988 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:55,217 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,228 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,295 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:55,330 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,379 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:55,449 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:55,454 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:55,514 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,645 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:55,675 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:55,696 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,735 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:55,771 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:55,867 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:55,943 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:56,121 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:56,256 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:56,531 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:56,546 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:56,625 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:56,672 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:56,695 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:17:56,715 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:56,730 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:56,812 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:56,866 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:56,939 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:57,006 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:57,164 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:57,196 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:57,221 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:57,242 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:57,320 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:57,434 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:57,506 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:57,525 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014725']\n",
      "2025-07-30 15:17:57,778 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:57,884 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:57,893 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:57,906 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:58,044 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:17:58,091 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:58,145 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014485']\n",
      "2025-07-30 15:17:58,224 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025301']\n",
      "2025-07-30 15:17:58,395 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:58,499 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:58,544 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:58,612 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:58,648 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:17:58,662 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:58,762 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:17:58,766 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:58,862 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:58,887 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:58,944 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013292']\n",
      "2025-07-30 15:17:58,973 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025301']\n",
      "2025-07-30 15:17:59,328 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:17:59,382 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:59,414 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:59,441 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:17:59,672 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:17:59,815 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:17:59,848 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025307', '450011382']\n",
      "2025-07-30 15:17:59,871 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:00,049 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:18:00,082 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:18:00,104 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:00,136 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:18:00,145 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:18:00,230 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:00,314 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:00,409 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:18:00,593 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:00,609 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:18:00,649 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014725']\n",
      "2025-07-30 15:18:00,689 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:00,693 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:00,718 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:00,724 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:18:00,737 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:00,763 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014482']\n",
      "2025-07-30 15:18:00,803 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025307', '450011382']\n",
      "2025-07-30 15:18:00,845 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:18:00,873 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:00,939 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:00,957 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:00,973 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:18:01,031 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:01,105 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:01,130 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:18:01,213 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450013280']\n",
      "2025-07-30 15:18:01,265 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010624']\n",
      "2025-07-30 15:18:01,392 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:18:01,411 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:01,429 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:01,531 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:01,651 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450010758']\n",
      "2025-07-30 15:18:01,703 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:01,715 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025301']\n",
      "2025-07-30 15:18:01,731 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:18:01,805 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450026240']\n",
      "2025-07-30 15:18:01,855 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024987']\n",
      "2025-07-30 15:18:01,989 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025305']\n",
      "2025-07-30 15:18:01,995 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014729']\n",
      "2025-07-30 15:18:02,249 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450014703']\n",
      "2025-07-30 15:18:02,372 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n",
      "2025-07-30 15:18:02,431 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450025306', '450011382']\n",
      "2025-07-30 15:18:02,570 - Your GTFS has (a) looooop edge(s)! A zero link between a node and itself, edge affected \n",
      "This edge will not be considered for computation, the stop will be deleted and the schedule will be changed. Affected stops: ['450024069']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GTFS loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def assign_colors_by_agency_number(routes_df):\n",
    "    \"\"\"\n",
    "    Assign unique colors to routes based on agency_id using sequential numbering.\n",
    "    Only adds route_color (not route_text_color).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Color palette - 6-digit hex codes (no # symbol for GTFS)\n",
    "    color_palette = [\n",
    "        '0078D4',  # Blue\n",
    "        'FF6B35',  # Orange  \n",
    "        '10B981',  # Green\n",
    "        'EF4444',  # Red\n",
    "        '8B5CF6',  # Purple\n",
    "        'F59E0B',  # Amber\n",
    "        'EC4899',  # Pink\n",
    "        '00BCF2',  # Light Blue\n",
    "        '8B5A2B',  # Brown\n",
    "        '6B7280',  # Gray\n",
    "    ]\n",
    "    \n",
    "    # Get unique agencies and sort them\n",
    "    unique_agencies = sorted(routes_df['agency_id'].unique())\n",
    "    print(f\"Found {len(unique_agencies)} agencies: {unique_agencies}\")\n",
    "    \n",
    "    # Create agency to color mapping\n",
    "    agency_color_map = {}\n",
    "    \n",
    "    for i, agency in enumerate(unique_agencies):\n",
    "        agency_number = i + 1\n",
    "        color_index = i % len(color_palette)\n",
    "        route_color = color_palette[color_index]\n",
    "        agency_color_map[agency] = route_color\n",
    "        print(f\"  Agency {agency_number}: {agency} -> #{route_color}\")\n",
    "    \n",
    "    # Apply colors to routes\n",
    "    routes_df['route_color'] = routes_df['agency_id'].map(agency_color_map)\n",
    "    \n",
    "    return routes_df\n",
    "\n",
    "def prepare_gtfs_with_auto_colors(zip_path, extract_dir='./gtfs_extracted'):\n",
    "    \"\"\"\n",
    "    Extract GTFS zip file and automatically assign route_color to agencies by number.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean up and create extraction directory\n",
    "    if os.path.exists(extract_dir):\n",
    "        shutil.rmtree(extract_dir)\n",
    "    os.makedirs(extract_dir)\n",
    "    \n",
    "    # Extract zip file\n",
    "    print(f\"Extracting {zip_path} to {extract_dir}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(f\"Extracted {len(zip_ref.namelist())} files\")\n",
    "    \n",
    "    # Fix routes.txt - add route_color based on agency numbering\n",
    "    routes_file = os.path.join(extract_dir, 'routes.txt')\n",
    "    if os.path.exists(routes_file):\n",
    "        routes_df = pd.read_csv(routes_file)\n",
    "        \n",
    "        print(f\"\\nOriginal routes.txt:\")\n",
    "        print(f\"  Columns: {routes_df.columns.tolist()}\")\n",
    "        print(f\"  Number of routes: {len(routes_df)}\")\n",
    "        \n",
    "        # Add colors based on automatic agency numbering\n",
    "        routes_df = assign_colors_by_agency_number(routes_df)\n",
    "        \n",
    "        # Save the updated file\n",
    "        routes_df.to_csv(routes_file, index=False)\n",
    "        print(f\"\\nUpdated routes.txt saved with route_color column\")\n",
    "        \n",
    "        # Show a sample of the updated data\n",
    "        print(\"\\nSample of updated routes:\")\n",
    "        sample_cols = ['route_id', 'agency_id', 'route_short_name', 'route_color']\n",
    "        print(routes_df[sample_cols].head(10).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nGTFS data prepared successfully in: {extract_dir}\")\n",
    "    return extract_dir\n",
    "\n",
    "# COMPLETE WORKFLOW: Extract, fix, and load GTFS\n",
    "zip_path = '../data/external/study_area_gtfs_bus.zip'\n",
    "\n",
    "# Step 1: Prepare the GTFS data (extract and add colors)\n",
    "gtfs_dir = prepare_gtfs_with_auto_colors(zip_path)\n",
    "\n",
    "# Step 2: Load with genet\n",
    "print(\"\\nLoading GTFS with genet...\")\n",
    "feed = genet.read_gtfs(gtfs_dir, '20230814')\n",
    "print(\" GTFS loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d673b",
   "metadata": {},
   "source": [
    "# Prepare data for optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75f8362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE ===\n",
      "=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\n",
      "1. Extracting GTFS data...\n",
      "Extracting GTFS data with 3-hour intervals...\n",
      "Found 358 routes with headway data\n",
      "  Failed to calculate round-trip time for 11855: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11855: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12120: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12120: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12351: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12351: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12352: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12352: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 124: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 124: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12493: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12516: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12522: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12522: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12576: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12589: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12590: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12590: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12594: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12594: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12597: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12597: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12632: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12632: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12639: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12639: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12645: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12645: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12654: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12654: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12657: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12657: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12687: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12687: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12721: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12762: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12762: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12763: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12763: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12768: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12768: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12806: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12806: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12815: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12815: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19882: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19882: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19899: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19899: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20020: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20020: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 22577: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 22577: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24134: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24134: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 25842: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 25842: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30527: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30527: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30531: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30531: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30532: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30532: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30535: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30535: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30536: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30536: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30537: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30537: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32474: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32474: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32869: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32869: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 33496: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35412: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35412: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35416: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35416: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37393: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37393: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 39395: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42279: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42279: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42378: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42378: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 49670: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 49670: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 51684: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 51684: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58953: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63367: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63367: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 64692: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 64692: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66346: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66346: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 70327: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72090: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72090: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72342: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72342: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73303: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73303: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73304: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73304: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73807: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75064: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75064: 'trip_end_time'\n",
      " Successfully extracted 358 routes\n",
      "2. Setting up optimization constraints...\n",
      "3. Creating route configurations...\n",
      "4. Initializing vehicle constraint calculator...\n",
      " Successfully initialized optimization data for 358 routes\n",
      "   Baseline fleet size: 1249.9 vehicles\n",
      "\n",
      "Core route summary:\n",
      "  service_id route_name agency  avg_headway  round_trip_time\n",
      "0      11855        425  OP665         17.2             60.0\n",
      "1      11855        425  OP665         17.2             60.0\n",
      "2      11878        163  OP665         12.4             60.0\n",
      "3      11878        163  OP665         12.4             60.0\n",
      "4      11878        163  OP665         12.4             60.0\n",
      "5      11878        163  OP665         12.4             60.0\n",
      "6      11878        163  OP665         12.4             60.0\n",
      "7      11896        168  OP665         29.9             60.0\n",
      "8      11896        168  OP665         29.9             60.0\n",
      "9      11896        168  OP665         29.9             60.0\n",
      "\n",
      "Optimization setup:\n",
      "  Total decision variables: 2864 (358 routes  8 intervals)\n",
      "  Time intervals: ['00-03h', '03-06h', '06-09h', '09-12h', '12-15h', '15-18h', '18-21h', '21-24h']\n",
      "  Service periods: 2082/2864 (72.7%)\n",
      "  User constraints: 5.0 - 120.0 minutes\n",
      "  Baseline fleet size: 1249.9 vehicles\n",
      "\n",
      "Core optimization interface test:\n",
      "  Optimization vector length: 2864\n",
      "  Bounds vector length: 2864\n",
      "  Sample headways: [9.999e+03 1.500e+01 9.600e+00 1.540e+01 1.550e+01 8.300e+00 2.630e+01\n",
      " 3.000e+01 9.999e+03 1.500e+01 9.600e+00 1.540e+01]\n",
      "  Sample bounds: [5.0, 60.0]\n",
      "\n",
      "Vehicle constraint test:\n",
      "  Current vehicles by interval: [  16.6  569.1 1172.3 1249.9 1214.5 1191.7  812.4  467.7]\n",
      "  Peak vehicles needed: 1249.9\n",
      "  20% increase constraint: 250.0\n",
      "  Total fleet constraint (100 vehicles): -1149.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# =============================================================================\n",
    "# CORE DATA STRUCTURES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class RouteConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration for a single transit route/service.\n",
    "    \n",
    "    This class represents a single transit route with time-varying headways\n",
    "    across different periods of the day. Each route is divided into time\n",
    "    intervals (e.g., 3-hour windows) with potentially different headway values.\n",
    "    \n",
    "    Attributes:\n",
    "        service_id (str): Unique GTFS service identifier\n",
    "        route_name (str): Human-readable route name for display\n",
    "        agency_id (str): Transit agency that operates this route\n",
    "        headways_by_interval (np.ndarray): Headway in minutes for each time interval\n",
    "                                         (np.nan indicates no service in that interval)\n",
    "        min_headway (float): Minimum operationally feasible headway (minutes)\n",
    "        max_headway (float): Maximum operationally reasonable headway (minutes)\n",
    "        operating_hours (Tuple[int, int]): Typical service hours (start_hour, end_hour)\n",
    "        route_color (str): Hex color code for visualization (without #)\n",
    "        interval_hours (int): Duration of each time interval in hours\n",
    "        round_trip_time (float): Complete round-trip time in minutes (for vehicle calculations)\n",
    "    \n",
    "    Example:\n",
    "        A route with 3-hour intervals might have:\n",
    "        headways_by_interval = [30, 15, 15, 20, 30, 45, np.nan, np.nan]\n",
    "        This means: 30min headway 00-03h, 15min 03-06h, ..., no service 18-24h\n",
    "    \"\"\"\n",
    "    service_id: str\n",
    "    route_name: str\n",
    "    agency_id: str\n",
    "    headways_by_interval: np.ndarray\n",
    "    min_headway: float\n",
    "    max_headway: float\n",
    "    operating_hours: Tuple[int, int]\n",
    "    route_color: str\n",
    "    interval_hours: int\n",
    "    round_trip_time: float\n",
    "\n",
    "# =============================================================================\n",
    "# GTFS DATA EXTRACTION LAYER\n",
    "# =============================================================================\n",
    "\n",
    "class GTFSDataExtractor:\n",
    "    \"\"\"\n",
    "    Handles extraction and processing of transit data from GTFS feeds via Genet.\n",
    "    \n",
    "    This class is responsible for:\n",
    "    1. Extracting headway statistics from GTFS data\n",
    "    2. Calculating time-varying headways across different time periods\n",
    "    3. Computing route metadata (names, agencies, colors)\n",
    "    4. Estimating round-trip times from trip data\n",
    "    5. Handling fallback scenarios when data is incomplete\n",
    "    \n",
    "    The extraction process works as follows:\n",
    "    1. Use genet's headway_stats() to get basic route information\n",
    "    2. For each route, analyze trips_to_dataframe() to calculate time-varying headways\n",
    "    3. Split the day into intervals (e.g., 3-hour windows)\n",
    "    4. Calculate average headway within each interval based on actual trip departures\n",
    "    5. Handle edge cases (no trips, single trip, data errors)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 genet_feed,\n",
    "                 gtfs_day: str = \"20230814\",\n",
    "                 interval_hours: int = 3,\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"\n",
    "        Initialize the GTFS data extractor.\n",
    "        \n",
    "        Args:\n",
    "            genet_feed: Genet feed object containing GTFS data\n",
    "            gtfs_day: Date for analysis in YYYYMMDD format\n",
    "            interval_hours: Duration of each time interval (must divide 24 evenly)\n",
    "            fallback_headway: Default headway when calculation fails\n",
    "            default_round_trip_time: Default round-trip time when calculation fails\n",
    "        \"\"\"\n",
    "        if 24 % interval_hours != 0:\n",
    "            raise ValueError(f\"interval_hours ({interval_hours}) must divide 24 evenly\")\n",
    "            \n",
    "        self.feed = genet_feed\n",
    "        self.gtfs_day = gtfs_day\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.fallback_headway = fallback_headway\n",
    "        self.default_round_trip_time = default_round_trip_time\n",
    "    \n",
    "    def extract_all_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract headway and metadata for all routes in the GTFS feed.\n",
    "        \n",
    "        This is the main entry point for data extraction. It:\n",
    "        1. Gets basic headway statistics from genet\n",
    "        2. Filters to valid routes (those with meaningful headway data)\n",
    "        3. For each route, calculates detailed time-varying headways\n",
    "        4. Extracts metadata (names, agencies, colors)\n",
    "        5. Estimates round-trip times for vehicle calculations\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of dictionaries containing route data\n",
    "                       Each dict has keys: service_id, route_id, avg_headway,\n",
    "                       headways_by_interval, route_name, agency_id, route_color,\n",
    "                       round_trip_time\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If extraction fails completely, falls back to simple uniform headways\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Extracting GTFS data with {self.interval_hours}-hour intervals...\")\n",
    "            \n",
    "            # Step 1: Get basic headway statistics from genet\n",
    "            headway_df = self._get_basic_headway_stats()\n",
    "            \n",
    "            # Step 2: Process each route to get detailed time-varying data\n",
    "            route_data_list = []\n",
    "            for _, row in headway_df.iterrows():\n",
    "                route_data = self._process_single_route(row)\n",
    "                if route_data:  # Only add if processing succeeded\n",
    "                    route_data_list.append(route_data)\n",
    "            \n",
    "            print(f\" Successfully extracted {len(route_data_list)} routes\")\n",
    "            return route_data_list\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" GTFS extraction failed: {e}\")\n",
    "            print(\"Using fallback uniform headways...\")\n",
    "            return self._create_fallback_routes()\n",
    "    \n",
    "    def _get_basic_headway_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get basic headway statistics from the genet feed.\n",
    "        \n",
    "        Uses genet's built-in headway_stats() method to get daily average\n",
    "        headways for all routes. Filters out routes without valid headway data.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Routes with columns including service_id, route_id, \n",
    "                         mean_headway_mins, trip_count\n",
    "        \"\"\"\n",
    "        headway_df = self.feed.headway_stats(gtfs_day=self.gtfs_day)\n",
    "        \n",
    "        # Include ALL routes with non-null headways (no arbitrary filtering)\n",
    "        valid_routes = headway_df[headway_df['mean_headway_mins'].notna()].copy()\n",
    "        \n",
    "        print(f\"Found {len(valid_routes)} routes with headway data\")\n",
    "        return valid_routes\n",
    "    \n",
    "    def _process_single_route(self, row: pd.Series) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Process a single route to extract detailed time-varying headway data.\n",
    "        \n",
    "        For each route, this method:\n",
    "        1. Calculates time-varying headways by analyzing trip departure times\n",
    "        2. Extracts route metadata (name, agency, color)\n",
    "        3. Estimates round-trip time from trip durations\n",
    "        4. Packages everything into a dictionary for later processing\n",
    "        \n",
    "        Args:\n",
    "            row: Pandas Series containing basic route info from headway_stats\n",
    "            \n",
    "        Returns:\n",
    "            Dict or None: Route data dictionary, or None if processing failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            service_id = row['service_id']\n",
    "            route_id = row.get('route_id', service_id)\n",
    "            avg_headway = row['mean_headway_mins']\n",
    "            \n",
    "            # Calculate time-varying headways (core functionality)\n",
    "            headways_by_interval = self._calculate_time_varying_headways(service_id, avg_headway)\n",
    "            \n",
    "            # Extract metadata\n",
    "            route_name, agency_id, route_color = self._extract_route_metadata(route_id)\n",
    "            \n",
    "            # Calculate round-trip time for vehicle planning\n",
    "            round_trip_time = self._calculate_round_trip_time(service_id)\n",
    "            \n",
    "            return {\n",
    "                'service_id': service_id,\n",
    "                'route_id': route_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'headways_by_interval': headways_by_interval,\n",
    "                'route_name': route_name,\n",
    "                'agency_id': agency_id,\n",
    "                'route_color': route_color,\n",
    "                'round_trip_time': round_trip_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to process route {row.get('service_id', 'unknown')}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _calculate_time_varying_headways(self, service_id: str, avg_headway: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate headway values for each time interval throughout the day.\n",
    "        \n",
    "        This is the core algorithm for time-varying headway calculation:\n",
    "        \n",
    "        1. Get all trips for this service from GTFS data\n",
    "        2. Extract departure hour from each trip\n",
    "        3. For each time interval (e.g., 0-3h, 3-6h, etc.):\n",
    "           a. Find all trips departing in that interval\n",
    "           b. Sort trips by departure time\n",
    "           c. Calculate time differences between consecutive trips\n",
    "           d. Average these intervals to get headway for that period\n",
    "        4. Handle special cases:\n",
    "           - No trips  np.nan (no service)\n",
    "           - One trip  interval duration (infrequent service)\n",
    "           - Multiple trips  calculated average interval\n",
    "        \n",
    "        Args:\n",
    "            service_id: GTFS service identifier\n",
    "            avg_headway: Daily average headway as fallback\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Headway values for each time interval (np.nan = no service)\n",
    "            \n",
    "        Example:\n",
    "            For 3-hour intervals, returns array of length 8:\n",
    "            [headway_00-03h, headway_03-06h, ..., headway_21-24h]\n",
    "        \"\"\"\n",
    "        headways = np.full(self.n_intervals, np.nan)\n",
    "        \n",
    "        try:\n",
    "            # Get trip data for this service\n",
    "            trips_df = self.feed.trips_to_dataframe(gtfs_day=self.gtfs_day)\n",
    "            service_trips = trips_df[trips_df['service_id'] == service_id].copy()\n",
    "            \n",
    "            # Handle edge cases\n",
    "            if len(service_trips) == 0:\n",
    "                return headways  # All np.nan - no service\n",
    "            elif len(service_trips) == 1:\n",
    "                # Single trip - assume it repeats every interval\n",
    "                headways.fill(self.interval_hours * 60)  # Convert hours to minutes\n",
    "                return headways\n",
    "            \n",
    "            # Extract hour component for interval assignment\n",
    "            service_trips['departure_hour'] = service_trips['trip_departure_time'].dt.hour\n",
    "            \n",
    "            # Calculate headway for each time interval\n",
    "            for interval in range(self.n_intervals):\n",
    "                start_hour = interval * self.interval_hours\n",
    "                end_hour = (interval + 1) * self.interval_hours\n",
    "                \n",
    "                # Find trips in this time window\n",
    "                interval_trips = service_trips[\n",
    "                    (service_trips['departure_hour'] >= start_hour) &\n",
    "                    (service_trips['departure_hour'] < end_hour)\n",
    "                ].copy()\n",
    "                \n",
    "                # Calculate headway for this specific interval\n",
    "                headways[interval] = self._calculate_interval_headway(interval_trips, avg_headway)\n",
    "            \n",
    "            return headways\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to calculate time-varying headways for {service_id}: {e}\")\n",
    "            # Fallback: uniform headway across all intervals\n",
    "            headways.fill(avg_headway)\n",
    "            return headways\n",
    "    \n",
    "    def _calculate_interval_headway(self, interval_trips: pd.DataFrame, avg_headway: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate headway for a specific time interval based on trip departures.\n",
    "        \n",
    "        This method handles the actual headway calculation for a single time period:\n",
    "        \n",
    "        For multiple trips:\n",
    "        1. Sort trips by departure time\n",
    "        2. Calculate time difference to next trip for each trip\n",
    "        3. Filter out invalid intervals (0, outliers)\n",
    "        4. Return average of valid intervals\n",
    "        \n",
    "        For single trip:\n",
    "        - Return interval duration (assumes infrequent service)\n",
    "        \n",
    "        For no trips:\n",
    "        - Return np.nan (no service)\n",
    "        \n",
    "        Args:\n",
    "            interval_trips: DataFrame of trips in this time interval\n",
    "            avg_headway: Fallback headway if calculation fails\n",
    "            \n",
    "        Returns:\n",
    "            float: Calculated headway in minutes, or np.nan for no service\n",
    "        \"\"\"\n",
    "        if len(interval_trips) >= 2:\n",
    "            # Multiple trips - calculate actual intervals\n",
    "            interval_trips = interval_trips.sort_values('trip_departure_time')\n",
    "            \n",
    "            # Calculate time to next departure for each trip\n",
    "            interval_trips['next_departure'] = interval_trips['trip_departure_time'].shift(-1)\n",
    "            interval_trips['interval_mins'] = (\n",
    "                interval_trips['next_departure'] - interval_trips['trip_departure_time']\n",
    "            ).dt.total_seconds() / 60\n",
    "            \n",
    "            # Filter valid intervals (positive, non-zero)\n",
    "            valid_intervals = interval_trips['interval_mins'].dropna()\n",
    "            valid_intervals = valid_intervals[valid_intervals > 0]\n",
    "            \n",
    "            if len(valid_intervals) > 0:\n",
    "                return valid_intervals.mean()\n",
    "            else:\n",
    "                return avg_headway  # Fallback if no valid intervals\n",
    "                \n",
    "        elif len(interval_trips) == 1:\n",
    "            # Single trip - assume it represents infrequent service\n",
    "            return self.interval_hours * 60  # Convert hours to minutes\n",
    "        else:\n",
    "            # No trips - no service in this interval\n",
    "            return np.nan\n",
    "    \n",
    "    def _extract_route_metadata(self, route_id: str) -> Tuple[str, str, str]:\n",
    "        \"\"\"\n",
    "        Extract route metadata from the GTFS feed.\n",
    "        \n",
    "        Attempts to get route name, agency, and color from the genet route object.\n",
    "        Provides sensible defaults if data is missing.\n",
    "        \n",
    "        Args:\n",
    "            route_id: GTFS route identifier\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[str, str, str]: (route_name, agency_id, route_color)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            route = self.feed.route(route_id)\n",
    "            route_name = getattr(route, 'route_short_name', str(route_id))\n",
    "            agency_id = getattr(route, 'agency_id', 'Unknown')\n",
    "            route_color = getattr(route, 'route_color', '000000')\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not extract metadata for route {route_id}: {e}\")\n",
    "            route_name = str(route_id)\n",
    "            agency_id = 'Unknown'\n",
    "            route_color = '000000'\n",
    "            \n",
    "        return route_name, agency_id, route_color\n",
    "    \n",
    "    def _calculate_round_trip_time(self, service_id: str) -> float:\n",
    "        \"\"\"\n",
    "        Estimate round-trip time by analyzing trip durations.\n",
    "        \n",
    "        This calculation is important for vehicle scheduling:\n",
    "        vehicles_needed = round_trip_time / headway\n",
    "        \n",
    "        Process:\n",
    "        1. Get all trips for this service\n",
    "        2. Calculate duration of each trip (end_time - start_time)\n",
    "        3. Take median duration as representative one-way time\n",
    "        4. Estimate round-trip as 2  one-way + 10% buffer for turnaround\n",
    "        \n",
    "        Args:\n",
    "            service_id: GTFS service identifier\n",
    "            \n",
    "        Returns:\n",
    "            float: Estimated round-trip time in minutes\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trips_df = self.feed.trips_to_dataframe(gtfs_day=self.gtfs_day)\n",
    "            service_trips = trips_df[trips_df['service_id'] == service_id].copy()\n",
    "            \n",
    "            if len(service_trips) == 0:\n",
    "                return self.default_round_trip_time\n",
    "            \n",
    "            # Calculate individual trip durations\n",
    "            service_trips['trip_duration'] = (\n",
    "                service_trips['trip_end_time'] - service_trips['trip_departure_time']\n",
    "            ).dt.total_seconds() / 60  # Convert to minutes\n",
    "            \n",
    "            # Filter to valid durations\n",
    "            valid_durations = service_trips['trip_duration'].dropna()\n",
    "            valid_durations = valid_durations[valid_durations > 0]\n",
    "            \n",
    "            if len(valid_durations) > 0:\n",
    "                # Use median one-way time (robust to outliers)\n",
    "                one_way_time = valid_durations.median()\n",
    "                # Round-trip = 2  one-way + 10% buffer for turnaround time\n",
    "                round_trip_time = one_way_time * 2 * 1.1\n",
    "                return round_trip_time\n",
    "            else:\n",
    "                return self.default_round_trip_time\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to calculate round-trip time for {service_id}: {e}\")\n",
    "            return self.default_round_trip_time\n",
    "    \n",
    "    def _create_fallback_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Create simple uniform headway routes when extraction fails.\n",
    "        \n",
    "        This ensures the system can still operate even if detailed GTFS\n",
    "        analysis fails. Creates routes with uniform headways across all intervals.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: Simple route data with uniform headways\n",
    "        \"\"\"\n",
    "        services_list = list(self.feed.services())\n",
    "        fallback_routes = []\n",
    "        \n",
    "        for service in services_list:\n",
    "            headways = np.full(self.n_intervals, self.fallback_headway)\n",
    "            \n",
    "            route_data = {\n",
    "                'service_id': service.id,\n",
    "                'route_id': service.id,\n",
    "                'avg_headway': self.fallback_headway,\n",
    "                'headways_by_interval': headways,\n",
    "                'route_name': getattr(service, 'route_short_name', service.id),\n",
    "                'agency_id': getattr(service, 'agency_id', 'Unknown'),\n",
    "                'route_color': getattr(service, 'route_color', '000000'),\n",
    "                'round_trip_time': self.default_round_trip_time\n",
    "            }\n",
    "            \n",
    "            fallback_routes.append(route_data)\n",
    "        \n",
    "        return fallback_routes\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIMIZATION CONSTRAINT MANAGER\n",
    "# =============================================================================\n",
    "\n",
    "class OptimizationConstraints:\n",
    "    \"\"\"\n",
    "    Manages optimization bounds and constraints for headway variables.\n",
    "    \n",
    "    This class handles:\n",
    "    1. Setting bounds for individual route headway variables\n",
    "    2. Enforcing user-specified global constraints (min/max headways)\n",
    "    3. Calculating data-driven bounds based on existing service patterns\n",
    "    4. Converting between different headway representations (np.nan  large values)\n",
    "    \n",
    "    The constraint system works as follows:\n",
    "    - Each route has per-interval headway variables\n",
    "    - User can set global min/max headway limits\n",
    "    - Bounds can also be calculated from existing data (e.g., 50%-200% of current)\n",
    "    - No-service periods (np.nan) are converted to large values for optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 no_service_headway_value: float = 9999.0):\n",
    "        \"\"\"\n",
    "        Initialize constraint manager with user preferences.\n",
    "        \n",
    "        Args:\n",
    "            user_min_headway: Absolute minimum headway (minutes)\n",
    "            user_max_headway: Absolute maximum headway (minutes)\n",
    "            min_headway_multiplier: Factor for data-driven lower bounds\n",
    "            max_headway_multiplier: Factor for data-driven upper bounds\n",
    "            no_service_headway_value: Large value representing no service\n",
    "        \"\"\"\n",
    "        self.user_min_headway = user_min_headway\n",
    "        self.user_max_headway = user_max_headway\n",
    "        self.min_headway_multiplier = min_headway_multiplier\n",
    "        self.max_headway_multiplier = max_headway_multiplier\n",
    "        self.no_service_headway_value = no_service_headway_value\n",
    "    \n",
    "    def calculate_route_bounds(self, headways_by_interval: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calculate optimization bounds for a single route.\n",
    "        \n",
    "        Combines user-specified constraints with data-driven bounds:\n",
    "        1. Calculate data-driven bounds from existing headways\n",
    "        2. Enforce user-specified global limits\n",
    "        3. Ensure min  max\n",
    "        \n",
    "        Args:\n",
    "            headways_by_interval: Current headway values for the route\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[float, float]: (min_headway, max_headway) for this route\n",
    "        \"\"\"\n",
    "        valid_headways = headways_by_interval[~np.isnan(headways_by_interval)]\n",
    "        \n",
    "        if len(valid_headways) > 0:\n",
    "            # Calculate bounds based on existing data\n",
    "            data_min = np.min(valid_headways) * self.min_headway_multiplier\n",
    "            data_max = np.max(valid_headways) * self.max_headway_multiplier\n",
    "            \n",
    "            # Combine with user constraints (most restrictive wins)\n",
    "            min_headway = max(self.user_min_headway, data_min)\n",
    "            max_headway = max(min_headway, min(self.user_max_headway, data_max))\n",
    "        else:\n",
    "            # No existing service - use user bounds\n",
    "            min_headway = self.user_min_headway\n",
    "            max_headway = self.user_max_headway\n",
    "            \n",
    "        return min_headway, max_headway\n",
    "    \n",
    "    def create_optimization_bounds(self, routes: List[RouteConfig]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Create bounds arrays for all optimization variables.\n",
    "        \n",
    "        The optimization vector is structured as:\n",
    "        [route1_interval1, route1_interval2, ..., route1_intervalN,\n",
    "         route2_interval1, route2_interval2, ..., route2_intervalN, ...]\n",
    "        \n",
    "        This method creates corresponding min/max bound arrays.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (min_bounds, max_bounds) arrays\n",
    "        \"\"\"\n",
    "        min_bounds = []\n",
    "        max_bounds = []\n",
    "        \n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                # All intervals use the same route-level bounds\n",
    "                # (optimization can decide whether to provide service)\n",
    "                min_bounds.append(route.min_headway)\n",
    "                max_bounds.append(route.max_headway)\n",
    "        \n",
    "        return np.array(min_bounds), np.array(max_bounds)\n",
    "    \n",
    "    def convert_to_optimization_vector(self, routes: List[RouteConfig]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert route headways to flat optimization vector.\n",
    "        \n",
    "        Handles the np.nan  large value conversion needed for optimization.\n",
    "        Most optimization algorithms can't handle NaN values, so we convert\n",
    "        no-service periods to a large headway value.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Flattened headway vector for optimization\n",
    "        \"\"\"\n",
    "        all_headways = []\n",
    "        for route in routes:\n",
    "            for headway in route.headways_by_interval:\n",
    "                if np.isnan(headway):\n",
    "                    all_headways.append(self.no_service_headway_value)\n",
    "                else:\n",
    "                    all_headways.append(headway)\n",
    "        return np.array(all_headways)\n",
    "    \n",
    "    def convert_from_optimization_vector(self, headway_vector: np.ndarray, \n",
    "                                       routes: List[RouteConfig]) -> None:\n",
    "        \"\"\"\n",
    "        Update route configurations from optimization vector.\n",
    "        \n",
    "        Converts large headway values back to np.nan and updates the\n",
    "        route configurations in-place.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimized headway values\n",
    "            routes: List of route configurations to update\n",
    "        \"\"\"\n",
    "        expected_length = sum(len(route.headways_by_interval) for route in routes)\n",
    "        if len(headway_vector) != expected_length:\n",
    "            raise ValueError(f\"Vector length mismatch: {len(headway_vector)} vs {expected_length}\")\n",
    "        \n",
    "        idx = 0\n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                new_headway = headway_vector[idx]\n",
    "                \n",
    "                # Convert large values back to no service\n",
    "                if new_headway >= self.no_service_headway_value * 0.9:\n",
    "                    route.headways_by_interval[interval] = np.nan\n",
    "                else:\n",
    "                    route.headways_by_interval[interval] = new_headway\n",
    "                    \n",
    "                idx += 1\n",
    "\n",
    "# =============================================================================\n",
    "# VEHICLE CONSTRAINT CALCULATOR\n",
    "# =============================================================================\n",
    "\n",
    "class VehicleConstraintCalculator:\n",
    "    \"\"\"\n",
    "    Calculates vehicle requirements and enforces fleet constraints.\n",
    "    \n",
    "    This class handles the relationship between headways and vehicle needs:\n",
    "    vehicles_needed = round_trip_time / headway\n",
    "    \n",
    "    Key constraints supported:\n",
    "    1. Total fleet size limits\n",
    "    2. Percentage increase limits (vs baseline)\n",
    "    3. Per-agency fleet limits\n",
    "    4. Time-interval specific limits\n",
    "    \n",
    "    The calculation works as follows:\n",
    "    1. For each route and time interval, calculate vehicles needed\n",
    "    2. Sum across routes to get total vehicles by interval\n",
    "    3. Peak interval determines total fleet size needed\n",
    "    4. Check against various constraint types\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, routes: List[RouteConfig], no_service_threshold: float = 9999.0):\n",
    "        \"\"\"\n",
    "        Initialize vehicle calculator with route data.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            no_service_threshold: Threshold above which headway = no service\n",
    "        \"\"\"\n",
    "        self.routes = routes\n",
    "        self.no_service_threshold = no_service_threshold\n",
    "        self.n_intervals = len(routes[0].headways_by_interval) if routes else 0\n",
    "        \n",
    "        # Calculate baseline vehicle requirements\n",
    "        self.baseline_vehicles_by_interval = self._calculate_baseline_vehicles()\n",
    "        self.baseline_total_vehicles = np.max(self.baseline_vehicles_by_interval)\n",
    "    \n",
    "    def _calculate_baseline_vehicles(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate current vehicle requirements from existing headways.\n",
    "        \n",
    "        This establishes the baseline for percentage-based constraints.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Vehicles needed for each time interval (current schedule)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = route.headways_by_interval[interval]\n",
    "                if not np.isnan(headway) and headway > 0:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate vehicle requirements for each time interval.\n",
    "        \n",
    "        This is the core vehicle calculation:\n",
    "        For each route and interval:\n",
    "        - If service operates: vehicles = round_trip_time / headway\n",
    "        - If no service: vehicles = 0\n",
    "        Sum across all routes for each interval.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Flattened optimization vector\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Total vehicles needed for each time interval\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                # Only count vehicles for active service\n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def constraint_total_fleet_size(self, headway_vector: np.ndarray, \n",
    "                                  max_fleet_size: float) -> float:\n",
    "        \"\"\"\n",
    "        Constraint: total fleet size  max_fleet_size.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            max_fleet_size: Maximum allowed total vehicles\n",
    "            \n",
    "        Returns:\n",
    "            float: Constraint value ( 0 for feasible solutions)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        return max_fleet_size - peak_vehicles\n",
    "    \n",
    "    def constraint_percentage_increase(self, headway_vector: np.ndarray, \n",
    "                                     max_increase_percent: float) -> float:\n",
    "        \"\"\"\n",
    "        Constraint: fleet size increase  max_increase_percent.\n",
    "        \n",
    "        Useful for budget-constrained optimization where you want to limit\n",
    "        the increase in vehicle requirements relative to current operations.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            max_increase_percent: Maximum allowed increase (e.g., 20.0 for 20%)\n",
    "            \n",
    "        Returns:\n",
    "            float: Constraint value ( 0 for feasible solutions)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        \n",
    "        max_allowed = self.baseline_total_vehicles * (1 + max_increase_percent / 100)\n",
    "        return max_allowed - peak_vehicles\n",
    "    \n",
    "    def constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                 agency_limits: Dict[str, float]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Constraint: per-agency fleet limits.\n",
    "        \n",
    "        Useful when different agencies have different vehicle budgets\n",
    "        or operational constraints.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            agency_limits: Maximum vehicles per agency {agency_id: limit}\n",
    "            \n",
    "        Returns:\n",
    "            List[float]: Constraint values for each agency ( 0 for feasible)\n",
    "        \"\"\"\n",
    "        # Calculate vehicles by agency and interval\n",
    "        agency_vehicles = {}\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            agency_id = route.agency_id\n",
    "            if agency_id not in agency_vehicles:\n",
    "                agency_vehicles[agency_id] = np.zeros(self.n_intervals)\n",
    "            \n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    agency_vehicles[agency_id][interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        # Check constraints for each agency\n",
    "        constraints = []\n",
    "        for agency_id, limit in agency_limits.items():\n",
    "            if agency_id in agency_vehicles:\n",
    "                peak_vehicles = np.max(agency_vehicles[agency_id])\n",
    "                constraints.append(limit - peak_vehicles)\n",
    "            else:\n",
    "                constraints.append(limit)  # No vehicles used = always feasible\n",
    "        \n",
    "        return constraints\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN OPTIMIZATION DATA STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "class HeadwayOptimizationData:\n",
    "    \"\"\"\n",
    "    Main class that coordinates all components for headway optimization.\n",
    "    \n",
    "    This class brings together:\n",
    "    - GTFS data extraction (GTFSDataExtractor)\n",
    "    - Route configuration management (RouteConfig)\n",
    "    - Optimization constraints (OptimizationConstraints)\n",
    "    - Vehicle calculations (VehicleConstraintCalculator)\n",
    "    \n",
    "    Responsibilities:\n",
    "    1. Initialize and coordinate all sub-components\n",
    "    2. Provide a clean interface for optimization algorithms\n",
    "    3. Handle data conversion between different representations\n",
    "    4. Generate summary reports and diagnostics\n",
    "    \n",
    "    Usage:\n",
    "        opt_data = HeadwayOptimizationData(feed, gtfs_day=\"20230814\")\n",
    "        \n",
    "        # Get data for optimization\n",
    "        x = opt_data.get_optimization_vector()\n",
    "        bounds = opt_data.get_bounds()\n",
    "        \n",
    "        # Use with optimization algorithm\n",
    "        result = optimizer.minimize(objective, x, bounds=bounds)\n",
    "        \n",
    "        # Update with results\n",
    "        opt_data.set_headways(result.x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 genet_feed, \n",
    "                 gtfs_day: str = \"20230814\", \n",
    "                 interval_hours: int = 3,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 default_operating_hours: Tuple[int, int] = (6, 22),\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 no_service_headway_value: float = 9999.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"\n",
    "        Initialize the complete optimization data structure.\n",
    "        \n",
    "        This constructor coordinates the initialization of all sub-components\n",
    "        and builds the complete data structure needed for optimization.\n",
    "        \n",
    "        Args:\n",
    "            genet_feed: Genet feed object containing GTFS data\n",
    "            gtfs_day: Analysis date in YYYYMMDD format\n",
    "            interval_hours: Duration of each time interval (must divide 24 evenly)\n",
    "            user_min_headway: Absolute minimum headway constraint (minutes)\n",
    "            user_max_headway: Absolute maximum headway constraint (minutes)\n",
    "            min_headway_multiplier: Factor for data-driven lower bounds\n",
    "            max_headway_multiplier: Factor for data-driven upper bounds\n",
    "            default_operating_hours: Default service hours (start, end)\n",
    "            fallback_headway: Default headway when calculation fails\n",
    "            no_service_headway_value: Large value representing no service\n",
    "            default_round_trip_time: Default round-trip time (minutes)\n",
    "        \"\"\"\n",
    "        # Store configuration\n",
    "        self.gtfs_day = gtfs_day\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.default_operating_hours = default_operating_hours\n",
    "        \n",
    "        # Initialize sub-components\n",
    "        print(\"=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\")\n",
    "        \n",
    "        # 1. GTFS Data Extraction\n",
    "        print(\"1. Extracting GTFS data...\")\n",
    "        self.extractor = GTFSDataExtractor(\n",
    "            genet_feed=genet_feed,\n",
    "            gtfs_day=gtfs_day,\n",
    "            interval_hours=interval_hours,\n",
    "            fallback_headway=fallback_headway,\n",
    "            default_round_trip_time=default_round_trip_time\n",
    "        )\n",
    "        \n",
    "        # 2. Extract route data\n",
    "        route_data_list = self.extractor.extract_all_routes()\n",
    "        \n",
    "        # 3. Constraint Management\n",
    "        print(\"2. Setting up optimization constraints...\")\n",
    "        self.constraints = OptimizationConstraints(\n",
    "            user_min_headway=user_min_headway,\n",
    "            user_max_headway=user_max_headway,\n",
    "            min_headway_multiplier=min_headway_multiplier,\n",
    "            max_headway_multiplier=max_headway_multiplier,\n",
    "            no_service_headway_value=no_service_headway_value\n",
    "        )\n",
    "        \n",
    "        # 4. Create RouteConfig objects\n",
    "        print(\"3. Creating route configurations...\")\n",
    "        self.routes = []\n",
    "        for route_data in route_data_list:\n",
    "            min_headway, max_headway = self.constraints.calculate_route_bounds(\n",
    "                route_data['headways_by_interval']\n",
    "            )\n",
    "            \n",
    "            route_config = RouteConfig(\n",
    "                service_id=route_data['service_id'],\n",
    "                route_name=route_data['route_name'],\n",
    "                agency_id=route_data['agency_id'],\n",
    "                headways_by_interval=route_data['headways_by_interval'],\n",
    "                min_headway=min_headway,\n",
    "                max_headway=max_headway,\n",
    "                operating_hours=default_operating_hours,\n",
    "                route_color=route_data['route_color'],\n",
    "                interval_hours=interval_hours,\n",
    "                round_trip_time=route_data['round_trip_time']\n",
    "            )\n",
    "            \n",
    "            self.routes.append(route_config)\n",
    "        \n",
    "        # 5. Vehicle Constraint Calculator\n",
    "        print(\"4. Initializing vehicle constraint calculator...\")\n",
    "        self.vehicle_calculator = VehicleConstraintCalculator(\n",
    "            routes=self.routes,\n",
    "            no_service_threshold=no_service_headway_value\n",
    "        )\n",
    "        \n",
    "        print(f\" Successfully initialized optimization data for {len(self.routes)} routes\")\n",
    "        print(f\"   Baseline fleet size: {self.vehicle_calculator.baseline_total_vehicles:.1f} vehicles\")\n",
    "        print()\n",
    "    \n",
    "    # =============================================================================\n",
    "    # CORE OPTIMIZATION INTERFACE\n",
    "    # =============================================================================\n",
    "    \n",
    "    def get_optimization_vector(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get current headways as a flattened optimization vector.\n",
    "        \n",
    "        This is the main interface for optimization algorithms.\n",
    "        Converts np.nan values to large numbers that optimizers can handle.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Flattened headway vector for optimization\n",
    "        \"\"\"\n",
    "        return self.constraints.convert_to_optimization_vector(self.routes)\n",
    "    \n",
    "    def get_bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get optimization bounds for all headway variables.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (lower_bounds, upper_bounds)\n",
    "        \"\"\"\n",
    "        return self.constraints.create_optimization_bounds(self.routes)\n",
    "    \n",
    "    def set_headways(self, headway_vector: np.ndarray):\n",
    "        \"\"\"\n",
    "        Update route headways from optimization results.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimized headway values\n",
    "        \"\"\"\n",
    "        self.constraints.convert_from_optimization_vector(headway_vector, self.routes)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # VEHICLE CONSTRAINT INTERFACE\n",
    "    # =============================================================================\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate vehicle requirements for each time interval.\"\"\"\n",
    "        return self.vehicle_calculator.calculate_vehicles_needed(headway_vector)\n",
    "    \n",
    "    def vehicle_constraint_total(self, headway_vector: np.ndarray, max_fleet_size: float) -> float:\n",
    "        \"\"\"Vehicle constraint: total fleet size  max_fleet_size.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_total_fleet_size(headway_vector, max_fleet_size)\n",
    "    \n",
    "    def vehicle_constraint_percent_increase(self, headway_vector: np.ndarray, \n",
    "                                          max_increase_percent: float) -> float:\n",
    "        \"\"\"Vehicle constraint: fleet size increase  max_increase_percent.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_percentage_increase(headway_vector, max_increase_percent)\n",
    "    \n",
    "    def vehicle_constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                         agency_limits: Dict[str, float]) -> List[float]:\n",
    "        \"\"\"Vehicle constraint: per-agency fleet limits.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_agency_specific(headway_vector, agency_limits)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # SUMMARY AND REPORTING\n",
    "    # =============================================================================\n",
    "    \n",
    "    def get_route_summary(self, include_interval_details: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate summary table of all routes with their configurations.\n",
    "        \n",
    "        Args:\n",
    "            include_interval_details: Whether to include individual interval columns\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Route summary with headway and constraint information\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for route in self.routes:\n",
    "            active_headways = route.headways_by_interval[~np.isnan(route.headways_by_interval)]\n",
    "            avg_headway = np.mean(active_headways) if len(active_headways) > 0 else np.nan\n",
    "            \n",
    "            row_data = {\n",
    "                'service_id': route.service_id,\n",
    "                'route_name': route.route_name,\n",
    "                'agency': route.agency_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'min_headway': route.min_headway,\n",
    "                'max_headway': route.max_headway,\n",
    "                'intervals_with_service': np.sum(~np.isnan(route.headways_by_interval)),\n",
    "                'route_color': route.route_color,\n",
    "                'round_trip_time': route.round_trip_time\n",
    "            }\n",
    "            \n",
    "            if include_interval_details:\n",
    "                for i in range(self.n_intervals):\n",
    "                    start_hour = i * self.interval_hours\n",
    "                    end_hour = (i + 1) * self.interval_hours\n",
    "                    headway_val = route.headways_by_interval[i]\n",
    "                    row_data[f'headway_{start_hour:02d}-{end_hour:02d}h'] = headway_val\n",
    "            \n",
    "            data.append(row_data)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_interval_labels(self) -> List[str]:\n",
    "        \"\"\"Get human-readable labels for time intervals.\"\"\"\n",
    "        labels = []\n",
    "        for i in range(self.n_intervals):\n",
    "            start_hour = i * self.interval_hours\n",
    "            end_hour = (i + 1) * self.interval_hours\n",
    "            labels.append(f\"{start_hour:02d}-{end_hour:02d}h\")\n",
    "        return labels\n",
    "    \n",
    "    def get_optimization_info(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get comprehensive information about the optimization setup.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Detailed optimization configuration and statistics\n",
    "        \"\"\"\n",
    "        current_vector = self.get_optimization_vector()\n",
    "        valid_headways = current_vector[current_vector < self.constraints.no_service_headway_value * 0.9]\n",
    "        no_service_count = len(current_vector) - len(valid_headways)\n",
    "        \n",
    "        return {\n",
    "            'n_routes': len(self.routes),\n",
    "            'n_intervals': self.n_intervals,\n",
    "            'interval_hours': self.interval_hours,\n",
    "            'total_variables': len(current_vector),\n",
    "            'service_periods': len(valid_headways),\n",
    "            'no_service_periods': no_service_count,\n",
    "            'service_coverage_pct': 100 * len(valid_headways) / len(current_vector) if len(current_vector) > 0 else 0,\n",
    "            'mean_headway': valid_headways.mean() if len(valid_headways) > 0 else np.nan,\n",
    "            'min_headway': valid_headways.min() if len(valid_headways) > 0 else np.nan,\n",
    "            'max_headway': valid_headways.max() if len(valid_headways) > 0 else np.nan,\n",
    "            'std_headway': valid_headways.std() if len(valid_headways) > 0 else np.nan,\n",
    "            'interval_labels': self.get_interval_labels(),\n",
    "            'user_min_headway': self.constraints.user_min_headway,\n",
    "            'user_max_headway': self.constraints.user_max_headway,\n",
    "            'baseline_total_vehicles': self.vehicle_calculator.baseline_total_vehicles,\n",
    "            'baseline_vehicles_by_interval': self.vehicle_calculator.baseline_vehicles_by_interval\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "# Create the optimization data structure\n",
    "print(\"=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE ===\")\n",
    "\n",
    "opt_data = HeadwayOptimizationData(\n",
    "    genet_feed=feed,\n",
    "    gtfs_day=\"20230814\",\n",
    "    interval_hours=3,\n",
    "    user_min_headway=5.0,\n",
    "    user_max_headway=120.0,\n",
    "    min_headway_multiplier=0.5,\n",
    "    max_headway_multiplier=2.0,\n",
    "    default_operating_hours=(6, 22),\n",
    "    fallback_headway=30.0,\n",
    "    no_service_headway_value=9999.0,\n",
    "    default_round_trip_time=60.0\n",
    ")\n",
    "\n",
    "# Show core route summary\n",
    "summary_df = opt_data.get_route_summary(include_interval_details=False)\n",
    "print(\"Core route summary:\")\n",
    "print(summary_df[['service_id', 'route_name', 'agency', 'avg_headway', 'round_trip_time']].round(1).head(10))\n",
    "print()\n",
    "\n",
    "# Show optimization setup information\n",
    "opt_info = opt_data.get_optimization_info()\n",
    "print(\"Optimization setup:\")\n",
    "print(f\"  Total decision variables: {opt_info['total_variables']} ({opt_info['n_routes']} routes  {opt_info['n_intervals']} intervals)\")\n",
    "print(f\"  Time intervals: {opt_info['interval_labels']}\")\n",
    "print(f\"  Service periods: {opt_info['service_periods']}/{opt_info['total_variables']} ({opt_info['service_coverage_pct']:.1f}%)\")\n",
    "print(f\"  User constraints: {opt_info['user_min_headway']:.1f} - {opt_info['user_max_headway']:.1f} minutes\")\n",
    "print(f\"  Baseline fleet size: {opt_info['baseline_total_vehicles']:.1f} vehicles\")\n",
    "print()\n",
    "\n",
    "# Test the core optimization interface\n",
    "current_vector = opt_data.get_optimization_vector()\n",
    "min_bounds, max_bounds = opt_data.get_bounds()\n",
    "\n",
    "print(\"Core optimization interface test:\")\n",
    "print(f\"  Optimization vector length: {len(current_vector)}\")\n",
    "print(f\"  Bounds vector length: {len(min_bounds)}\")\n",
    "print(f\"  Sample headways: {current_vector[:12].round(1)}\")\n",
    "print(f\"  Sample bounds: [{min_bounds[0]:.1f}, {max_bounds[0]:.1f}]\")\n",
    "print()\n",
    "\n",
    "# Test vehicle constraint functions\n",
    "vehicles_needed = opt_data.calculate_vehicles_needed(current_vector)\n",
    "print(\"Vehicle constraint test:\")\n",
    "print(f\"  Current vehicles by interval: {vehicles_needed.round(1)}\")\n",
    "print(f\"  Peak vehicles needed: {np.max(vehicles_needed):.1f}\")\n",
    "print(f\"  20% increase constraint: {opt_data.vehicle_constraint_percent_increase(current_vector, 20.0):.1f}\")\n",
    "print(f\"  Total fleet constraint (100 vehicles): {opt_data.vehicle_constraint_total(current_vector, 100.0):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b517f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE ===\n",
      "=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\n",
      "1. Extracting GTFS data...\n",
      "Extracting GTFS data with 3-hour intervals...\n",
      "Found 358 routes with headway data\n",
      "  Failed to calculate round-trip time for 11855: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11855: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11878: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11896: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11929: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11934: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11963: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11986: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 11989: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12120: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12120: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12255: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12316: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12351: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12351: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12352: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12352: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 124: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 124: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12490: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12492: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12493: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12516: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12522: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12522: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12544: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12550: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12562: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12565: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12576: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12589: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12590: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12590: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12592: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12594: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12594: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12597: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12597: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12614: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12631: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12632: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12632: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12633: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12639: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12639: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12645: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12645: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12654: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12654: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12655: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12657: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12657: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12687: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12687: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12693: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12696: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12701: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12721: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12762: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12762: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12763: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12763: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12768: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12768: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12806: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12806: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12815: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12815: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 12826: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 18680: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19840: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19882: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19882: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19899: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 19899: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20020: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20020: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20990: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 20991: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 22577: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 22577: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24133: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24134: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 24134: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 25842: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 25842: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30526: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30527: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30527: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30528: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30529: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30530: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30531: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30531: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30532: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30532: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30533: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30534: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30535: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30535: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30536: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30536: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30537: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30537: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30539: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30541: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 30542: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32473: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32474: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32474: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32869: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 32869: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 33496: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35412: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35412: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35416: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 35416: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37393: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37393: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 37599: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 38189: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 39395: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42279: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42279: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42378: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 42378: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 47558: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 49670: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 49670: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50407: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50625: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50627: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50628: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 50629: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 51684: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 51684: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 52014: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58949: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 58953: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63360: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63367: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63367: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 63868: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 64692: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 64692: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66346: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66346: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66540: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66897: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 66898: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 70327: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72084: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72090: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72090: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72342: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 72342: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73303: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73303: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73304: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73304: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 73807: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 74362: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75063: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75064: 'trip_end_time'\n",
      "  Failed to calculate round-trip time for 75064: 'trip_end_time'\n",
      " Successfully extracted 358 routes\n",
      "2. Setting up optimization constraints...\n",
      "3. Creating route configurations...\n",
      "4. Initializing vehicle constraint calculator...\n",
      " Successfully initialized optimization data for 358 routes\n",
      "   Baseline fleet size: 1249.9 vehicles\n",
      "\n",
      "Core route summary:\n",
      "  service_id route_name agency  avg_headway  round_trip_time\n",
      "0      11855        425  OP665         17.2             60.0\n",
      "1      11855        425  OP665         17.2             60.0\n",
      "2      11878        163  OP665         12.4             60.0\n",
      "3      11878        163  OP665         12.4             60.0\n",
      "4      11878        163  OP665         12.4             60.0\n",
      "5      11878        163  OP665         12.4             60.0\n",
      "6      11878        163  OP665         12.4             60.0\n",
      "7      11896        168  OP665         29.9             60.0\n",
      "8      11896        168  OP665         29.9             60.0\n",
      "9      11896        168  OP665         29.9             60.0\n",
      "\n",
      "Optimization setup:\n",
      "  Total decision variables: 2864 (358 routes  8 intervals)\n",
      "  Time intervals: ['00-03h', '03-06h', '06-09h', '09-12h', '12-15h', '15-18h', '18-21h', '21-24h']\n",
      "  Service periods: 2082/2864 (72.7%)\n",
      "  User constraints: 5.0 - 120.0 minutes\n",
      "  Baseline fleet size: 1249.9 vehicles\n",
      "\n",
      "Core optimization interface test:\n",
      "  Optimization vector length: 2864\n",
      "  Bounds vector length: 2864\n",
      "  Sample headways: [9.999e+03 1.500e+01 9.600e+00 1.540e+01 1.550e+01 8.300e+00 2.630e+01\n",
      " 3.000e+01 9.999e+03 1.500e+01 9.600e+00 1.540e+01]\n",
      "  Sample bounds: [5.0, 60.0]\n",
      "\n",
      "Vehicle constraint test:\n",
      "  Current vehicles by interval: [  16.6  569.1 1172.3 1249.9 1214.5 1191.7  812.4  467.7]\n",
      "  Peak vehicles needed: 1249.9\n",
      "  20% increase constraint: 250.0\n",
      "  Total fleet constraint (100 vehicles): -1149.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# =============================================================================\n",
    "# CORE DATA STRUCTURES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class RouteConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration for a single transit route/service.\n",
    "    \n",
    "    This class represents a single transit route with time-varying headways\n",
    "    across different periods of the day. Each route is divided into time\n",
    "    intervals (e.g., 3-hour windows) with potentially different headway values.\n",
    "    \n",
    "    Attributes:\n",
    "        service_id (str): Unique GTFS service identifier\n",
    "        route_name (str): Human-readable route name for display\n",
    "        agency_id (str): Transit agency that operates this route\n",
    "        headways_by_interval (np.ndarray): Headway in minutes for each time interval\n",
    "                                         (np.nan indicates no service in that interval)\n",
    "        min_headway (float): Minimum operationally feasible headway (minutes)\n",
    "        max_headway (float): Maximum operationally reasonable headway (minutes)\n",
    "        operating_hours (Tuple[int, int]): Typical service hours (start_hour, end_hour)\n",
    "        route_color (str): Hex color code for visualization (without #)\n",
    "        interval_hours (int): Duration of each time interval in hours\n",
    "        round_trip_time (float): Complete round-trip time in minutes (for vehicle calculations)\n",
    "    \n",
    "    Example:\n",
    "        A route with 3-hour intervals might have:\n",
    "        headways_by_interval = [30, 15, 15, 20, 30, 45, np.nan, np.nan]\n",
    "        This means: 30min headway 00-03h, 15min 03-06h, ..., no service 18-24h\n",
    "    \"\"\"\n",
    "    service_id: str\n",
    "    route_name: str\n",
    "    agency_id: str\n",
    "    headways_by_interval: np.ndarray\n",
    "    min_headway: float\n",
    "    max_headway: float\n",
    "    operating_hours: Tuple[int, int]\n",
    "    route_color: str\n",
    "    interval_hours: int\n",
    "    round_trip_time: float\n",
    "\n",
    "# =============================================================================\n",
    "# GTFS DATA EXTRACTION LAYER\n",
    "# =============================================================================\n",
    "\n",
    "class GTFSDataExtractor:\n",
    "    \"\"\"\n",
    "    Handles extraction and processing of transit data from GTFS feeds via Genet.\n",
    "    \n",
    "    This class is responsible for:\n",
    "    1. Extracting headway statistics from GTFS data\n",
    "    2. Calculating time-varying headways across different time periods\n",
    "    3. Computing route metadata (names, agencies, colors)\n",
    "    4. Estimating round-trip times from trip data\n",
    "    5. Handling fallback scenarios when data is incomplete\n",
    "    \n",
    "    The extraction process works as follows:\n",
    "    1. Use genet's headway_stats() to get basic route information\n",
    "    2. For each route, analyze trips_to_dataframe() to calculate time-varying headways\n",
    "    3. Split the day into intervals (e.g., 3-hour windows)\n",
    "    4. Calculate average headway within each interval based on actual trip departures\n",
    "    5. Handle edge cases (no trips, single trip, data errors)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 genet_feed,\n",
    "                 gtfs_day: str = \"20230814\",\n",
    "                 interval_hours: int = 3,\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"\n",
    "        Initialize the GTFS data extractor.\n",
    "        \n",
    "        Args:\n",
    "            genet_feed: Genet feed object containing GTFS data\n",
    "            gtfs_day: Date for analysis in YYYYMMDD format\n",
    "            interval_hours: Duration of each time interval (must divide 24 evenly)\n",
    "            fallback_headway: Default headway when calculation fails\n",
    "            default_round_trip_time: Default round-trip time when calculation fails\n",
    "        \"\"\"\n",
    "        if 24 % interval_hours != 0:\n",
    "            raise ValueError(f\"interval_hours ({interval_hours}) must divide 24 evenly\")\n",
    "            \n",
    "        self.feed = genet_feed\n",
    "        self.gtfs_day = gtfs_day\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.fallback_headway = fallback_headway\n",
    "        self.default_round_trip_time = default_round_trip_time\n",
    "    \n",
    "    def extract_all_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract headway and metadata for all routes in the GTFS feed.\n",
    "        \n",
    "        This is the main entry point for data extraction. It:\n",
    "        1. Gets basic headway statistics from genet\n",
    "        2. Filters to valid routes (those with meaningful headway data)\n",
    "        3. For each route, calculates detailed time-varying headways\n",
    "        4. Extracts metadata (names, agencies, colors)\n",
    "        5. Estimates round-trip times for vehicle calculations\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of dictionaries containing route data\n",
    "                       Each dict has keys: service_id, route_id, avg_headway,\n",
    "                       headways_by_interval, route_name, agency_id, route_color,\n",
    "                       round_trip_time\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If extraction fails completely, falls back to simple uniform headways\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Extracting GTFS data with {self.interval_hours}-hour intervals...\")\n",
    "            \n",
    "            # Step 1: Get basic headway statistics from genet\n",
    "            headway_df = self._get_basic_headway_stats()\n",
    "            \n",
    "            # Step 2: Process each route to get detailed time-varying data\n",
    "            route_data_list = []\n",
    "            for _, row in headway_df.iterrows():\n",
    "                route_data = self._process_single_route(row)\n",
    "                if route_data:  # Only add if processing succeeded\n",
    "                    route_data_list.append(route_data)\n",
    "            \n",
    "            print(f\" Successfully extracted {len(route_data_list)} routes\")\n",
    "            return route_data_list\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" GTFS extraction failed: {e}\")\n",
    "            print(\"Using fallback uniform headways...\")\n",
    "            return self._create_fallback_routes()\n",
    "    \n",
    "    def _get_basic_headway_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get basic headway statistics from the genet feed.\n",
    "        \n",
    "        Uses genet's built-in headway_stats() method to get daily average\n",
    "        headways for all routes. Filters out routes without valid headway data.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Routes with columns including service_id, route_id, \n",
    "                         mean_headway_mins, trip_count\n",
    "        \"\"\"\n",
    "        headway_df = self.feed.headway_stats(gtfs_day=self.gtfs_day)\n",
    "        \n",
    "        # Include ALL routes with non-null headways (no arbitrary filtering)\n",
    "        valid_routes = headway_df[headway_df['mean_headway_mins'].notna()].copy()\n",
    "        \n",
    "        print(f\"Found {len(valid_routes)} routes with headway data\")\n",
    "        return valid_routes\n",
    "    \n",
    "    def _process_single_route(self, row: pd.Series) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Process a single route to extract detailed time-varying headway data.\n",
    "        \n",
    "        For each route, this method:\n",
    "        1. Calculates time-varying headways by analyzing trip departure times\n",
    "        2. Extracts route metadata (name, agency, color)\n",
    "        3. Estimates round-trip time from trip durations\n",
    "        4. Packages everything into a dictionary for later processing\n",
    "        \n",
    "        Args:\n",
    "            row: Pandas Series containing basic route info from headway_stats\n",
    "            \n",
    "        Returns:\n",
    "            Dict or None: Route data dictionary, or None if processing failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            service_id = row['service_id']\n",
    "            route_id = row.get('route_id', service_id)\n",
    "            avg_headway = row['mean_headway_mins']\n",
    "            \n",
    "            # Calculate time-varying headways (core functionality)\n",
    "            headways_by_interval = self._calculate_time_varying_headways(service_id, avg_headway)\n",
    "            \n",
    "            # Extract metadata\n",
    "            route_name, agency_id, route_color = self._extract_route_metadata(route_id)\n",
    "            \n",
    "            # Calculate round-trip time for vehicle planning\n",
    "            round_trip_time = self._calculate_round_trip_time(service_id)\n",
    "            \n",
    "            return {\n",
    "                'service_id': service_id,\n",
    "                'route_id': route_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'headways_by_interval': headways_by_interval,\n",
    "                'route_name': route_name,\n",
    "                'agency_id': agency_id,\n",
    "                'route_color': route_color,\n",
    "                'round_trip_time': round_trip_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to process route {row.get('service_id', 'unknown')}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _calculate_time_varying_headways(self, service_id: str, avg_headway: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate headway values for each time interval throughout the day.\n",
    "        \n",
    "        This is the core algorithm for time-varying headway calculation:\n",
    "        \n",
    "        1. Get all trips for this service from GTFS data\n",
    "        2. Extract departure hour from each trip\n",
    "        3. For each time interval (e.g., 0-3h, 3-6h, etc.):\n",
    "           a. Find all trips departing in that interval\n",
    "           b. Sort trips by departure time\n",
    "           c. Calculate time differences between consecutive trips\n",
    "           d. Average these intervals to get headway for that period\n",
    "        4. Handle special cases:\n",
    "           - No trips  np.nan (no service)\n",
    "           - One trip  interval duration (infrequent service)\n",
    "           - Multiple trips  calculated average interval\n",
    "        \n",
    "        Args:\n",
    "            service_id: GTFS service identifier\n",
    "            avg_headway: Daily average headway as fallback\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Headway values for each time interval (np.nan = no service)\n",
    "            \n",
    "        Example:\n",
    "            For 3-hour intervals, returns array of length 8:\n",
    "            [headway_00-03h, headway_03-06h, ..., headway_21-24h]\n",
    "        \"\"\"\n",
    "        headways = np.full(self.n_intervals, np.nan)\n",
    "        \n",
    "        try:\n",
    "            # Get trip data for this service\n",
    "            trips_df = self.feed.trips_to_dataframe(gtfs_day=self.gtfs_day)\n",
    "            service_trips = trips_df[trips_df['service_id'] == service_id].copy()\n",
    "            \n",
    "            # Handle edge cases\n",
    "            if len(service_trips) == 0:\n",
    "                return headways  # All np.nan - no service\n",
    "            elif len(service_trips) == 1:\n",
    "                # Single trip - assume it repeats every interval\n",
    "                headways.fill(self.interval_hours * 60)  # Convert hours to minutes\n",
    "                return headways\n",
    "            \n",
    "            # Extract hour component for interval assignment\n",
    "            service_trips['departure_hour'] = service_trips['trip_departure_time'].dt.hour\n",
    "            \n",
    "            # Calculate headway for each time interval\n",
    "            for interval in range(self.n_intervals):\n",
    "                start_hour = interval * self.interval_hours\n",
    "                end_hour = (interval + 1) * self.interval_hours\n",
    "                \n",
    "                # Find trips in this time window\n",
    "                interval_trips = service_trips[\n",
    "                    (service_trips['departure_hour'] >= start_hour) &\n",
    "                    (service_trips['departure_hour'] < end_hour)\n",
    "                ].copy()\n",
    "                \n",
    "                # Calculate headway for this specific interval\n",
    "                headways[interval] = self._calculate_interval_headway(interval_trips, avg_headway)\n",
    "            \n",
    "            return headways\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to calculate time-varying headways for {service_id}: {e}\")\n",
    "            # Fallback: uniform headway across all intervals\n",
    "            headways.fill(avg_headway)\n",
    "            return headways\n",
    "    \n",
    "    def _calculate_interval_headway(self, interval_trips: pd.DataFrame, avg_headway: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate headway for a specific time interval based on trip departures.\n",
    "        \n",
    "        This method handles the actual headway calculation for a single time period:\n",
    "        \n",
    "        For multiple trips:\n",
    "        1. Sort trips by departure time\n",
    "        2. Calculate time difference to next trip for each trip\n",
    "        3. Filter out invalid intervals (0, outliers)\n",
    "        4. Return average of valid intervals\n",
    "        \n",
    "        For single trip:\n",
    "        - Return interval duration (assumes infrequent service)\n",
    "        \n",
    "        For no trips:\n",
    "        - Return np.nan (no service)\n",
    "        \n",
    "        Args:\n",
    "            interval_trips: DataFrame of trips in this time interval\n",
    "            avg_headway: Fallback headway if calculation fails\n",
    "            \n",
    "        Returns:\n",
    "            float: Calculated headway in minutes, or np.nan for no service\n",
    "        \"\"\"\n",
    "        if len(interval_trips) >= 2:\n",
    "            # Multiple trips - calculate actual intervals\n",
    "            interval_trips = interval_trips.sort_values('trip_departure_time')\n",
    "            \n",
    "            # Calculate time to next departure for each trip\n",
    "            interval_trips['next_departure'] = interval_trips['trip_departure_time'].shift(-1)\n",
    "            interval_trips['interval_mins'] = (\n",
    "                interval_trips['next_departure'] - interval_trips['trip_departure_time']\n",
    "            ).dt.total_seconds() / 60\n",
    "            \n",
    "            # Filter valid intervals (positive, non-zero)\n",
    "            valid_intervals = interval_trips['interval_mins'].dropna()\n",
    "            valid_intervals = valid_intervals[valid_intervals > 0]\n",
    "            \n",
    "            if len(valid_intervals) > 0:\n",
    "                return valid_intervals.mean()\n",
    "            else:\n",
    "                return avg_headway  # Fallback if no valid intervals\n",
    "                \n",
    "        elif len(interval_trips) == 1:\n",
    "            # Single trip - assume it represents infrequent service\n",
    "            return self.interval_hours * 60  # Convert hours to minutes\n",
    "        else:\n",
    "            # No trips - no service in this interval\n",
    "            return np.nan\n",
    "    \n",
    "    def _extract_route_metadata(self, route_id: str) -> Tuple[str, str, str]:\n",
    "        \"\"\"\n",
    "        Extract route metadata from the GTFS feed.\n",
    "        \n",
    "        Attempts to get route name, agency, and color from the genet route object.\n",
    "        Provides sensible defaults if data is missing.\n",
    "        \n",
    "        Args:\n",
    "            route_id: GTFS route identifier\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[str, str, str]: (route_name, agency_id, route_color)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            route = self.feed.route(route_id)\n",
    "            route_name = getattr(route, 'route_short_name', str(route_id))\n",
    "            agency_id = getattr(route, 'agency_id', 'Unknown')\n",
    "            route_color = getattr(route, 'route_color', '000000')\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not extract metadata for route {route_id}: {e}\")\n",
    "            route_name = str(route_id)\n",
    "            agency_id = 'Unknown'\n",
    "            route_color = '000000'\n",
    "            \n",
    "        return route_name, agency_id, route_color\n",
    "    \n",
    "    def _calculate_round_trip_time(self, service_id: str) -> float:\n",
    "        \"\"\"\n",
    "        Estimate round-trip time by analyzing trip durations.\n",
    "        \n",
    "        This calculation is important for vehicle scheduling:\n",
    "        vehicles_needed = round_trip_time / headway\n",
    "        \n",
    "        Process:\n",
    "        1. Get all trips for this service\n",
    "        2. Calculate duration of each trip (end_time - start_time)\n",
    "        3. Take median duration as representative one-way time\n",
    "        4. Estimate round-trip as 2  one-way + 10% buffer for turnaround\n",
    "        \n",
    "        Args:\n",
    "            service_id: GTFS service identifier\n",
    "            \n",
    "        Returns:\n",
    "            float: Estimated round-trip time in minutes\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trips_df = self.feed.trips_to_dataframe(gtfs_day=self.gtfs_day)\n",
    "            service_trips = trips_df[trips_df['service_id'] == service_id].copy()\n",
    "            \n",
    "            if len(service_trips) == 0:\n",
    "                return self.default_round_trip_time\n",
    "            \n",
    "            # Calculate individual trip durations\n",
    "            service_trips['trip_duration'] = (\n",
    "                service_trips['trip_end_time'] - service_trips['trip_departure_time']\n",
    "            ).dt.total_seconds() / 60  # Convert to minutes\n",
    "            \n",
    "            # Filter to valid durations\n",
    "            valid_durations = service_trips['trip_duration'].dropna()\n",
    "            valid_durations = valid_durations[valid_durations > 0]\n",
    "            \n",
    "            if len(valid_durations) > 0:\n",
    "                # Use median one-way time (robust to outliers)\n",
    "                one_way_time = valid_durations.median()\n",
    "                # Round-trip = 2  one-way + 10% buffer for turnaround time\n",
    "                round_trip_time = one_way_time * 2 * 1.1\n",
    "                return round_trip_time\n",
    "            else:\n",
    "                return self.default_round_trip_time\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to calculate round-trip time for {service_id}: {e}\")\n",
    "            return self.default_round_trip_time\n",
    "    \n",
    "    def _create_fallback_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Create simple uniform headway routes when extraction fails.\n",
    "        \n",
    "        This ensures the system can still operate even if detailed GTFS\n",
    "        analysis fails. Creates routes with uniform headways across all intervals.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: Simple route data with uniform headways\n",
    "        \"\"\"\n",
    "        services_list = list(self.feed.services())\n",
    "        fallback_routes = []\n",
    "        \n",
    "        for service in services_list:\n",
    "            headways = np.full(self.n_intervals, self.fallback_headway)\n",
    "            \n",
    "            route_data = {\n",
    "                'service_id': service.id,\n",
    "                'route_id': service.id,\n",
    "                'avg_headway': self.fallback_headway,\n",
    "                'headways_by_interval': headways,\n",
    "                'route_name': getattr(service, 'route_short_name', service.id),\n",
    "                'agency_id': getattr(service, 'agency_id', 'Unknown'),\n",
    "                'route_color': getattr(service, 'route_color', '000000'),\n",
    "                'round_trip_time': self.default_round_trip_time\n",
    "            }\n",
    "            \n",
    "            fallback_routes.append(route_data)\n",
    "        \n",
    "        return fallback_routes\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIMIZATION CONSTRAINT MANAGER\n",
    "# =============================================================================\n",
    "\n",
    "class OptimizationConstraints:\n",
    "    \"\"\"\n",
    "    Manages optimization bounds and constraints for headway variables.\n",
    "    \n",
    "    This class handles:\n",
    "    1. Setting bounds for individual route headway variables\n",
    "    2. Enforcing user-specified global constraints (min/max headways)\n",
    "    3. Calculating data-driven bounds based on existing service patterns\n",
    "    4. Converting between different headway representations (np.nan  large values)\n",
    "    \n",
    "    The constraint system works as follows:\n",
    "    - Each route has per-interval headway variables\n",
    "    - User can set global min/max headway limits\n",
    "    - Bounds can also be calculated from existing data (e.g., 50%-200% of current)\n",
    "    - No-service periods (np.nan) are converted to large values for optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 no_service_headway_value: float = 9999.0):\n",
    "        \"\"\"\n",
    "        Initialize constraint manager with user preferences.\n",
    "        \n",
    "        Args:\n",
    "            user_min_headway: Absolute minimum headway (minutes)\n",
    "            user_max_headway: Absolute maximum headway (minutes)\n",
    "            min_headway_multiplier: Factor for data-driven lower bounds\n",
    "            max_headway_multiplier: Factor for data-driven upper bounds\n",
    "            no_service_headway_value: Large value representing no service\n",
    "        \"\"\"\n",
    "        self.user_min_headway = user_min_headway\n",
    "        self.user_max_headway = user_max_headway\n",
    "        self.min_headway_multiplier = min_headway_multiplier\n",
    "        self.max_headway_multiplier = max_headway_multiplier\n",
    "        self.no_service_headway_value = no_service_headway_value\n",
    "    \n",
    "    def calculate_route_bounds(self, headways_by_interval: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calculate optimization bounds for a single route.\n",
    "        \n",
    "        Combines user-specified constraints with data-driven bounds:\n",
    "        1. Calculate data-driven bounds from existing headways\n",
    "        2. Enforce user-specified global limits\n",
    "        3. Ensure min  max\n",
    "        \n",
    "        Args:\n",
    "            headways_by_interval: Current headway values for the route\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[float, float]: (min_headway, max_headway) for this route\n",
    "        \"\"\"\n",
    "        valid_headways = headways_by_interval[~np.isnan(headways_by_interval)]\n",
    "        \n",
    "        if len(valid_headways) > 0:\n",
    "            # Calculate bounds based on existing data\n",
    "            data_min = np.min(valid_headways) * self.min_headway_multiplier\n",
    "            data_max = np.max(valid_headways) * self.max_headway_multiplier\n",
    "            \n",
    "            # Combine with user constraints (most restrictive wins)\n",
    "            min_headway = max(self.user_min_headway, data_min)\n",
    "            max_headway = max(min_headway, min(self.user_max_headway, data_max))\n",
    "        else:\n",
    "            # No existing service - use user bounds\n",
    "            min_headway = self.user_min_headway\n",
    "            max_headway = self.user_max_headway\n",
    "            \n",
    "        return min_headway, max_headway\n",
    "    \n",
    "    def create_optimization_bounds(self, routes: List[RouteConfig]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Create bounds arrays for all optimization variables.\n",
    "        \n",
    "        The optimization vector is structured as:\n",
    "        [route1_interval1, route1_interval2, ..., route1_intervalN,\n",
    "         route2_interval1, route2_interval2, ..., route2_intervalN, ...]\n",
    "        \n",
    "        This method creates corresponding min/max bound arrays.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (min_bounds, max_bounds) arrays\n",
    "        \"\"\"\n",
    "        min_bounds = []\n",
    "        max_bounds = []\n",
    "        \n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                # All intervals use the same route-level bounds\n",
    "                # (optimization can decide whether to provide service)\n",
    "                min_bounds.append(route.min_headway)\n",
    "                max_bounds.append(route.max_headway)\n",
    "        \n",
    "        return np.array(min_bounds), np.array(max_bounds)\n",
    "    \n",
    "    def convert_to_optimization_vector(self, routes: List[RouteConfig]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert route headways to flat optimization vector.\n",
    "        \n",
    "        Handles the np.nan  large value conversion needed for optimization.\n",
    "        Most optimization algorithms can't handle NaN values, so we convert\n",
    "        no-service periods to a large headway value.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Flattened headway vector for optimization\n",
    "        \"\"\"\n",
    "        all_headways = []\n",
    "        for route in routes:\n",
    "            for headway in route.headways_by_interval:\n",
    "                if np.isnan(headway):\n",
    "                    all_headways.append(self.no_service_headway_value)\n",
    "                else:\n",
    "                    all_headways.append(headway)\n",
    "        return np.array(all_headways)\n",
    "    \n",
    "    def convert_from_optimization_vector(self, headway_vector: np.ndarray, \n",
    "                                       routes: List[RouteConfig]) -> None:\n",
    "        \"\"\"\n",
    "        Update route configurations from optimization vector.\n",
    "        \n",
    "        Converts large headway values back to np.nan and updates the\n",
    "        route configurations in-place.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimized headway values\n",
    "            routes: List of route configurations to update\n",
    "        \"\"\"\n",
    "        expected_length = sum(len(route.headways_by_interval) for route in routes)\n",
    "        if len(headway_vector) != expected_length:\n",
    "            raise ValueError(f\"Vector length mismatch: {len(headway_vector)} vs {expected_length}\")\n",
    "        \n",
    "        idx = 0\n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                new_headway = headway_vector[idx]\n",
    "                \n",
    "                # Convert large values back to no service\n",
    "                if new_headway >= self.no_service_headway_value * 0.9:\n",
    "                    route.headways_by_interval[interval] = np.nan\n",
    "                else:\n",
    "                    route.headways_by_interval[interval] = new_headway\n",
    "                    \n",
    "                idx += 1\n",
    "\n",
    "# =============================================================================\n",
    "# VEHICLE CONSTRAINT CALCULATOR\n",
    "# =============================================================================\n",
    "\n",
    "class VehicleConstraintCalculator:\n",
    "    \"\"\"\n",
    "    Calculates vehicle requirements and enforces fleet constraints.\n",
    "    \n",
    "    This class handles the relationship between headways and vehicle needs:\n",
    "    vehicles_needed = round_trip_time / headway\n",
    "    \n",
    "    Key constraints supported:\n",
    "    1. Total fleet size limits\n",
    "    2. Percentage increase limits (vs baseline)\n",
    "    3. Per-agency fleet limits\n",
    "    4. Time-interval specific limits\n",
    "    \n",
    "    The calculation works as follows:\n",
    "    1. For each route and time interval, calculate vehicles needed\n",
    "    2. Sum across routes to get total vehicles by interval\n",
    "    3. Peak interval determines total fleet size needed\n",
    "    4. Check against various constraint types\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, routes: List[RouteConfig], no_service_threshold: float = 9999.0):\n",
    "        \"\"\"\n",
    "        Initialize vehicle calculator with route data.\n",
    "        \n",
    "        Args:\n",
    "            routes: List of route configurations\n",
    "            no_service_threshold: Threshold above which headway = no service\n",
    "        \"\"\"\n",
    "        self.routes = routes\n",
    "        self.no_service_threshold = no_service_threshold\n",
    "        self.n_intervals = len(routes[0].headways_by_interval) if routes else 0\n",
    "        \n",
    "        # Calculate baseline vehicle requirements\n",
    "        self.baseline_vehicles_by_interval = self._calculate_baseline_vehicles()\n",
    "        self.baseline_total_vehicles = np.max(self.baseline_vehicles_by_interval)\n",
    "    \n",
    "    def _calculate_baseline_vehicles(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate current vehicle requirements from existing headways.\n",
    "        \n",
    "        This establishes the baseline for percentage-based constraints.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Vehicles needed for each time interval (current schedule)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = route.headways_by_interval[interval]\n",
    "                if not np.isnan(headway) and headway > 0:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate vehicle requirements for each time interval.\n",
    "        \n",
    "        This is the core vehicle calculation:\n",
    "        For each route and interval:\n",
    "        - If service operates: vehicles = round_trip_time / headway\n",
    "        - If no service: vehicles = 0\n",
    "        Sum across all routes for each interval.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Flattened optimization vector\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Total vehicles needed for each time interval\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                # Only count vehicles for active service\n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def constraint_total_fleet_size(self, headway_vector: np.ndarray, \n",
    "                                  max_fleet_size: float) -> float:\n",
    "        \"\"\"\n",
    "        Constraint: total fleet size  max_fleet_size.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            max_fleet_size: Maximum allowed total vehicles\n",
    "            \n",
    "        Returns:\n",
    "            float: Constraint value ( 0 for feasible solutions)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        return max_fleet_size - peak_vehicles\n",
    "    \n",
    "    def constraint_percentage_increase(self, headway_vector: np.ndarray, \n",
    "                                     max_increase_percent: float) -> float:\n",
    "        \"\"\"\n",
    "        Constraint: fleet size increase  max_increase_percent.\n",
    "        \n",
    "        Useful for budget-constrained optimization where you want to limit\n",
    "        the increase in vehicle requirements relative to current operations.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            max_increase_percent: Maximum allowed increase (e.g., 20.0 for 20%)\n",
    "            \n",
    "        Returns:\n",
    "            float: Constraint value ( 0 for feasible solutions)\n",
    "        \"\"\"\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        \n",
    "        max_allowed = self.baseline_total_vehicles * (1 + max_increase_percent / 100)\n",
    "        return max_allowed - peak_vehicles\n",
    "    \n",
    "    def constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                 agency_limits: Dict[str, float]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Constraint: per-agency fleet limits.\n",
    "        \n",
    "        Useful when different agencies have different vehicle budgets\n",
    "        or operational constraints.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimization vector\n",
    "            agency_limits: Maximum vehicles per agency {agency_id: limit}\n",
    "            \n",
    "        Returns:\n",
    "            List[float]: Constraint values for each agency ( 0 for feasible)\n",
    "        \"\"\"\n",
    "        # Calculate vehicles by agency and interval\n",
    "        agency_vehicles = {}\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            agency_id = route.agency_id\n",
    "            if agency_id not in agency_vehicles:\n",
    "                agency_vehicles[agency_id] = np.zeros(self.n_intervals)\n",
    "            \n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    agency_vehicles[agency_id][interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        # Check constraints for each agency\n",
    "        constraints = []\n",
    "        for agency_id, limit in agency_limits.items():\n",
    "            if agency_id in agency_vehicles:\n",
    "                peak_vehicles = np.max(agency_vehicles[agency_id])\n",
    "                constraints.append(limit - peak_vehicles)\n",
    "            else:\n",
    "                constraints.append(limit)  # No vehicles used = always feasible\n",
    "        \n",
    "        return constraints\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN OPTIMIZATION DATA STRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "class HeadwayOptimizationData:\n",
    "    \"\"\"\n",
    "    Main class that coordinates all components for headway optimization.\n",
    "    \n",
    "    This class brings together:\n",
    "    - GTFS data extraction (GTFSDataExtractor)\n",
    "    - Route configuration management (RouteConfig)\n",
    "    - Optimization constraints (OptimizationConstraints)\n",
    "    - Vehicle calculations (VehicleConstraintCalculator)\n",
    "    \n",
    "    Responsibilities:\n",
    "    1. Initialize and coordinate all sub-components\n",
    "    2. Provide a clean interface for optimization algorithms\n",
    "    3. Handle data conversion between different representations\n",
    "    4. Generate summary reports and diagnostics\n",
    "    \n",
    "    Usage:\n",
    "        opt_data = HeadwayOptimizationData(feed, gtfs_day=\"20230814\")\n",
    "        \n",
    "        # Get data for optimization\n",
    "        x = opt_data.get_optimization_vector()\n",
    "        bounds = opt_data.get_bounds()\n",
    "        \n",
    "        # Use with optimization algorithm\n",
    "        result = optimizer.minimize(objective, x, bounds=bounds)\n",
    "        \n",
    "        # Update with results\n",
    "        opt_data.set_headways(result.x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 genet_feed, \n",
    "                 gtfs_day: str = \"20230814\", \n",
    "                 interval_hours: int = 3,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 default_operating_hours: Tuple[int, int] = (6, 22),\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 no_service_headway_value: float = 9999.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"\n",
    "        Initialize the complete optimization data structure.\n",
    "        \n",
    "        This constructor coordinates the initialization of all sub-components\n",
    "        and builds the complete data structure needed for optimization.\n",
    "        \n",
    "        Args:\n",
    "            genet_feed: Genet feed object containing GTFS data\n",
    "            gtfs_day: Analysis date in YYYYMMDD format\n",
    "            interval_hours: Duration of each time interval (must divide 24 evenly)\n",
    "            user_min_headway: Absolute minimum headway constraint (minutes)\n",
    "            user_max_headway: Absolute maximum headway constraint (minutes)\n",
    "            min_headway_multiplier: Factor for data-driven lower bounds\n",
    "            max_headway_multiplier: Factor for data-driven upper bounds\n",
    "            default_operating_hours: Default service hours (start, end)\n",
    "            fallback_headway: Default headway when calculation fails\n",
    "            no_service_headway_value: Large value representing no service\n",
    "            default_round_trip_time: Default round-trip time (minutes)\n",
    "        \"\"\"\n",
    "        # Store configuration\n",
    "        self.gtfs_day = gtfs_day\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.default_operating_hours = default_operating_hours\n",
    "        \n",
    "        # Initialize sub-components\n",
    "        print(\"=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\")\n",
    "        \n",
    "        # 1. GTFS Data Extraction\n",
    "        print(\"1. Extracting GTFS data...\")\n",
    "        self.extractor = GTFSDataExtractor(\n",
    "            genet_feed=genet_feed,\n",
    "            gtfs_day=gtfs_day,\n",
    "            interval_hours=interval_hours,\n",
    "            fallback_headway=fallback_headway,\n",
    "            default_round_trip_time=default_round_trip_time\n",
    "        )\n",
    "        \n",
    "        # 2. Extract route data\n",
    "        route_data_list = self.extractor.extract_all_routes()\n",
    "        \n",
    "        # 3. Constraint Management\n",
    "        print(\"2. Setting up optimization constraints...\")\n",
    "        self.constraints = OptimizationConstraints(\n",
    "            user_min_headway=user_min_headway,\n",
    "            user_max_headway=user_max_headway,\n",
    "            min_headway_multiplier=min_headway_multiplier,\n",
    "            max_headway_multiplier=max_headway_multiplier,\n",
    "            no_service_headway_value=no_service_headway_value\n",
    "        )\n",
    "        \n",
    "        # 4. Create RouteConfig objects\n",
    "        print(\"3. Creating route configurations...\")\n",
    "        self.routes = []\n",
    "        for route_data in route_data_list:\n",
    "            min_headway, max_headway = self.constraints.calculate_route_bounds(\n",
    "                route_data['headways_by_interval']\n",
    "            )\n",
    "            \n",
    "            route_config = RouteConfig(\n",
    "                service_id=route_data['service_id'],\n",
    "                route_name=route_data['route_name'],\n",
    "                agency_id=route_data['agency_id'],\n",
    "                headways_by_interval=route_data['headways_by_interval'],\n",
    "                min_headway=min_headway,\n",
    "                max_headway=max_headway,\n",
    "                operating_hours=default_operating_hours,\n",
    "                route_color=route_data['route_color'],\n",
    "                interval_hours=interval_hours,\n",
    "                round_trip_time=route_data['round_trip_time']\n",
    "            )\n",
    "            \n",
    "            self.routes.append(route_config)\n",
    "        \n",
    "        # 5. Vehicle Constraint Calculator\n",
    "        print(\"4. Initializing vehicle constraint calculator...\")\n",
    "        self.vehicle_calculator = VehicleConstraintCalculator(\n",
    "            routes=self.routes,\n",
    "            no_service_threshold=no_service_headway_value\n",
    "        )\n",
    "        \n",
    "        print(f\" Successfully initialized optimization data for {len(self.routes)} routes\")\n",
    "        print(f\"   Baseline fleet size: {self.vehicle_calculator.baseline_total_vehicles:.1f} vehicles\")\n",
    "        print()\n",
    "    \n",
    "    # =============================================================================\n",
    "    # CORE OPTIMIZATION INTERFACE\n",
    "    # =============================================================================\n",
    "    \n",
    "    def get_optimization_vector(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get current headways as a flattened optimization vector.\n",
    "        \n",
    "        This is the main interface for optimization algorithms.\n",
    "        Converts np.nan values to large numbers that optimizers can handle.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Flattened headway vector for optimization\n",
    "        \"\"\"\n",
    "        return self.constraints.convert_to_optimization_vector(self.routes)\n",
    "    \n",
    "    def get_bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get optimization bounds for all headway variables.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: (lower_bounds, upper_bounds)\n",
    "        \"\"\"\n",
    "        return self.constraints.create_optimization_bounds(self.routes)\n",
    "    \n",
    "    def set_headways(self, headway_vector: np.ndarray):\n",
    "        \"\"\"\n",
    "        Update route headways from optimization results.\n",
    "        \n",
    "        Args:\n",
    "            headway_vector: Optimized headway values\n",
    "        \"\"\"\n",
    "        self.constraints.convert_from_optimization_vector(headway_vector, self.routes)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # VEHICLE CONSTRAINT INTERFACE\n",
    "    # =============================================================================\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate vehicle requirements for each time interval.\"\"\"\n",
    "        return self.vehicle_calculator.calculate_vehicles_needed(headway_vector)\n",
    "    \n",
    "    def vehicle_constraint_total(self, headway_vector: np.ndarray, max_fleet_size: float) -> float:\n",
    "        \"\"\"Vehicle constraint: total fleet size  max_fleet_size.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_total_fleet_size(headway_vector, max_fleet_size)\n",
    "    \n",
    "    def vehicle_constraint_percent_increase(self, headway_vector: np.ndarray, \n",
    "                                          max_increase_percent: float) -> float:\n",
    "        \"\"\"Vehicle constraint: fleet size increase  max_increase_percent.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_percentage_increase(headway_vector, max_increase_percent)\n",
    "    \n",
    "    def vehicle_constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                         agency_limits: Dict[str, float]) -> List[float]:\n",
    "        \"\"\"Vehicle constraint: per-agency fleet limits.\"\"\"\n",
    "        return self.vehicle_calculator.constraint_agency_specific(headway_vector, agency_limits)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # SUMMARY AND REPORTING\n",
    "    # =============================================================================\n",
    "    \n",
    "    def get_route_summary(self, include_interval_details: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate summary table of all routes with their configurations.\n",
    "        \n",
    "        Args:\n",
    "            include_interval_details: Whether to include individual interval columns\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Route summary with headway and constraint information\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for route in self.routes:\n",
    "            active_headways = route.headways_by_interval[~np.isnan(route.headways_by_interval)]\n",
    "            avg_headway = np.mean(active_headways) if len(active_headways) > 0 else np.nan\n",
    "            \n",
    "            row_data = {\n",
    "                'service_id': route.service_id,\n",
    "                'route_name': route.route_name,\n",
    "                'agency': route.agency_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'min_headway': route.min_headway,\n",
    "                'max_headway': route.max_headway,\n",
    "                'intervals_with_service': np.sum(~np.isnan(route.headways_by_interval)),\n",
    "                'route_color': route.route_color,\n",
    "                'round_trip_time': route.round_trip_time\n",
    "            }\n",
    "            \n",
    "            if include_interval_details:\n",
    "                for i in range(self.n_intervals):\n",
    "                    start_hour = i * self.interval_hours\n",
    "                    end_hour = (i + 1) * self.interval_hours\n",
    "                    headway_val = route.headways_by_interval[i]\n",
    "                    row_data[f'headway_{start_hour:02d}-{end_hour:02d}h'] = headway_val\n",
    "            \n",
    "            data.append(row_data)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_interval_labels(self) -> List[str]:\n",
    "        \"\"\"Get human-readable labels for time intervals.\"\"\"\n",
    "        labels = []\n",
    "        for i in range(self.n_intervals):\n",
    "            start_hour = i * self.interval_hours\n",
    "            end_hour = (i + 1) * self.interval_hours\n",
    "            labels.append(f\"{start_hour:02d}-{end_hour:02d}h\")\n",
    "        return labels\n",
    "    \n",
    "    def get_optimization_info(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get comprehensive information about the optimization setup.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Detailed optimization configuration and statistics\n",
    "        \"\"\"\n",
    "        current_vector = self.get_optimization_vector()\n",
    "        valid_headways = current_vector[current_vector < self.constraints.no_service_headway_value * 0.9]\n",
    "        no_service_count = len(current_vector) - len(valid_headways)\n",
    "        \n",
    "        return {\n",
    "            'n_routes': len(self.routes),\n",
    "            'n_intervals': self.n_intervals,\n",
    "            'interval_hours': self.interval_hours,\n",
    "            'total_variables': len(current_vector),\n",
    "            'service_periods': len(valid_headways),\n",
    "            'no_service_periods': no_service_count,\n",
    "            'service_coverage_pct': 100 * len(valid_headways) / len(current_vector) if len(current_vector) > 0 else 0,\n",
    "            'mean_headway': valid_headways.mean() if len(valid_headways) > 0 else np.nan,\n",
    "            'min_headway': valid_headways.min() if len(valid_headways) > 0 else np.nan,\n",
    "            'max_headway': valid_headways.max() if len(valid_headways) > 0 else np.nan,\n",
    "            'std_headway': valid_headways.std() if len(valid_headways) > 0 else np.nan,\n",
    "            'interval_labels': self.get_interval_labels(),\n",
    "            'user_min_headway': self.constraints.user_min_headway,\n",
    "            'user_max_headway': self.constraints.user_max_headway,\n",
    "            'baseline_total_vehicles': self.vehicle_calculator.baseline_total_vehicles,\n",
    "            'baseline_vehicles_by_interval': self.vehicle_calculator.baseline_vehicles_by_interval\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "# Create the optimization data structure\n",
    "print(\"=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE ===\")\n",
    "\n",
    "opt_data = HeadwayOptimizationData(\n",
    "    genet_feed=feed,\n",
    "    gtfs_day=\"20230814\",\n",
    "    interval_hours=3,\n",
    "    user_min_headway=5.0,\n",
    "    user_max_headway=120.0,\n",
    "    min_headway_multiplier=0.5,\n",
    "    max_headway_multiplier=2.0,\n",
    "    default_operating_hours=(6, 22),\n",
    "    fallback_headway=30.0,\n",
    "    no_service_headway_value=9999.0,\n",
    "    default_round_trip_time=60.0\n",
    ")\n",
    "\n",
    "# Show core route summary\n",
    "summary_df = opt_data.get_route_summary(include_interval_details=False)\n",
    "print(\"Core route summary:\")\n",
    "print(summary_df[['service_id', 'route_name', 'agency', 'avg_headway', 'round_trip_time']].round(1).head(10))\n",
    "print()\n",
    "\n",
    "# Show optimization setup information\n",
    "opt_info = opt_data.get_optimization_info()\n",
    "print(\"Optimization setup:\")\n",
    "print(f\"  Total decision variables: {opt_info['total_variables']} ({opt_info['n_routes']} routes  {opt_info['n_intervals']} intervals)\")\n",
    "print(f\"  Time intervals: {opt_info['interval_labels']}\")\n",
    "print(f\"  Service periods: {opt_info['service_periods']}/{opt_info['total_variables']} ({opt_info['service_coverage_pct']:.1f}%)\")\n",
    "print(f\"  User constraints: {opt_info['user_min_headway']:.1f} - {opt_info['user_max_headway']:.1f} minutes\")\n",
    "print(f\"  Baseline fleet size: {opt_info['baseline_total_vehicles']:.1f} vehicles\")\n",
    "print()\n",
    "\n",
    "# Test the core optimization interface\n",
    "current_vector = opt_data.get_optimization_vector()\n",
    "min_bounds, max_bounds = opt_data.get_bounds()\n",
    "\n",
    "print(\"Core optimization interface test:\")\n",
    "print(f\"  Optimization vector length: {len(current_vector)}\")\n",
    "print(f\"  Bounds vector length: {len(min_bounds)}\")\n",
    "print(f\"  Sample headways: {current_vector[:12].round(1)}\")\n",
    "print(f\"  Sample bounds: [{min_bounds[0]:.1f}, {max_bounds[0]:.1f}]\")\n",
    "print()\n",
    "\n",
    "# Test vehicle constraint functions\n",
    "vehicles_needed = opt_data.calculate_vehicles_needed(current_vector)\n",
    "print(\"Vehicle constraint test:\")\n",
    "print(f\"  Current vehicles by interval: {vehicles_needed.round(1)}\")\n",
    "print(f\"  Peak vehicles needed: {np.max(vehicles_needed):.1f}\")\n",
    "print(f\"  20% increase constraint: {opt_data.vehicle_constraint_percent_increase(current_vector, 20.0):.1f}\")\n",
    "print(f\"  Total fleet constraint (100 vehicles): {opt_data.vehicle_constraint_total(current_vector, 100.0):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64b12183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the improved round-trip calculation method...\n",
      "=== TESTING ROUND-TRIP TIME CALCULATION ===\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: nan minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Found 82 trips for service 11855\n",
      "Analyzing stop times for each trip...\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0c500e46af16ae241e984cf66e755390d079bbde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0ea68314b6135a0907a563ac9bfdb0005b8a3f23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ11b2c347b3f5a9fda3943b2e32be4377099d5fac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2689ffde2e01e5181fdb5b802efa736cf37a19fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4830908304f9f688f1fa0a1aeeedc6e8374c6cf6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f359654ad5933f3ebc9b830062c4cb77434059f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ57103ed29d58fbfe987264a368cde946c1df5476: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5d20ebae138bb1f86777a66fcf88fc89e4879ada: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5eaf720bfd50af13d5505baa815d0623169c6cad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6560f3e552dc6e87a5422eb22cb2dd8920bdb913: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ69990daa285cf28ee45f9bef97827b3437eccc7a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6a16bca9a521301b1edc7a32dc59364e79a26efd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b94d3cc811ab71c94de47b3c93fdc715d75cbcf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ713626a03e63bad3b43cd0a9a4b521806a8c4c2f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7166dcefff4ea9de5137e1764a5464d157002344: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7265faac22279a2cd9fefd57d19d8284c3988e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7a799c54378c878a3f77dc08c2b889ccb66ece2e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8c3da21fa78e558372b4d13428d8e477142231fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9a6b3fcaabf6941b58bd698cc293ac5b4ef38eac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ec2d43fc26d75ee95f7c3b17210394d4bfb63ad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ee8177b1c89ea98009ac785d42937d52e400250: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9f86f862880e40146dccff90b145240bd39c5450: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa2c8ab198db458a7d95a6b29293bff613ca4ba1d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa6962a719a8edb55a081b38a9fd0c69fe4a6544d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJab25f1b3d46aee09ba18f81ac160a9e2a6761d61: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb63e5f73407d404a47c28ab02254b5789ac94cde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc0f3ec66741bae14e4f7f794ec37e4a2c88a551c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc377b88377d7f7dcfcc9ff1bea6cecbac2b0ffaf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd0f7e0a8bf898b0e846f812a40e2fd12ce4f7f4a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd5e9b05f35ce7420736d81318b40f37023984f79: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd6aaa5fd80365ddd400ad1b950c2156163047786: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd77bee49855237d564adb35e53a148bce55f7b51: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJdbdb4f680aaee768fd8f6b94864adc50332b01e1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe56a6f51c89a146c741ea2d299155cd895db7dbb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe5ff62d557722f32d3cc4d497222a8aa8b7ab7d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJec0dac8749dd4aa87cadfd11586db0b12e50d9c8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf583825f1dfbf16049ff836f5d30eff5ebad21c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJfa75f45777ad3ff9b69c4e76ce300a6721a3a685: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb24978919a3f987166a7ba5955edbe207329f5: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb7969275a6a0cdf4055febc51408af3163c1da1f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb92d110e4bc0f791cf3deede03bca21809905398: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ013bd906c94f6c8157e14d13aa5b76d9fb1f3e75: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ080e0094880e0384d33aa831920700dd8d7afb5f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ08e9ad8e2744f0581e0158258a09cf388d1a08ec: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0a91b2e33e3dc4eb0e4b007a1a8ffe5e73f0496f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1ae65af23e133301a3f4944d29829b1b62d75c9f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1d1249ee308924096d7e4899d225902aaadb405b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1e009f70e9413120433000b12991749b8dbd7d29: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ216bc78250f8c0804f0b2f390b2aa1e2d2f4261e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ27b73220eba97b55688a0db38eccddf7fdfa05c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2bfd7626da25a537fd8675182b457c8036ae11eb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2fa557f1f28cf86e0c95f0f7b2c5efa991d17aa6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ397efc09aa89d9fa4657ea9cd411d25edc1b36ce: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4268591cb30462b6861175a035ac592d23e8dcb8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f1e2a6f0917d88179b0171fda8e57d6586bd711: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f991607ad9a6b2f90ce4d7616475e3c2a6cb89b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ54f1245b382b24a48726354bb703fad130fb6945: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ59162cebb86dd595631866b9f5e1c845a422d6cd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ64700374f8558f687b68aace011bbc62fe044ed4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ68bd613d00c74dd0adbad1bf3243cbf0a096cb5c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b8515668ae4d92ec13d5615901142774bab7d07: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6d1382b8c0574adeb5f3bbbacbc4baeac852b186: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ79ce9463fda4dc483623160643977fc10b2c4895: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7db7604be2c21069f126cc3b0a57c992f768546e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7debe11afa2542a22bf9c6961e1dbe267763c9c2: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7fc2d69d95ff6d55a162e4a3c61a966747b6f319: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8b762be9fdcba57311ce1c17cb05d4a4113ff4d4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8e3452702e726da5ac1129566f6152999e3e973d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9794e7458d6f374ca9bf38358762afb7ac96b133: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9c72fc02c72e466ce24e47661615ab6e9d810410: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9df96d32c61211e6b636b30381dd8af2779fc5b7: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa386ca4238e0f8e43517193ab2efc71d0b3b81d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb3eddf03abb88945732f9e926002ccc493e3ee72: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJbef4792789ef6e6087c254e959fe9feefcfb95fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJcc14f5f146f16e5ebf0590d4bf37e8846813814a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe1ab903f09721f113ffe431c3c1c9238e636d2ab: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe6544d3fbbaf076d9ecbba00ae8334683ee29e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf271a92e37b15596e7500ccc5a32b20c7cd17196: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb04c84e885e4d4f4ebda5a5f7c1861114f8a23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "Successfully processed 0 trips with valid stop times\n",
      " No valid trip durations found - using default\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: 25.5 minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Found 82 trips for service 11855\n",
      "Analyzing stop times for each trip...\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0c500e46af16ae241e984cf66e755390d079bbde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0ea68314b6135a0907a563ac9bfdb0005b8a3f23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ11b2c347b3f5a9fda3943b2e32be4377099d5fac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2689ffde2e01e5181fdb5b802efa736cf37a19fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4830908304f9f688f1fa0a1aeeedc6e8374c6cf6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f359654ad5933f3ebc9b830062c4cb77434059f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ57103ed29d58fbfe987264a368cde946c1df5476: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5d20ebae138bb1f86777a66fcf88fc89e4879ada: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5eaf720bfd50af13d5505baa815d0623169c6cad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6560f3e552dc6e87a5422eb22cb2dd8920bdb913: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ69990daa285cf28ee45f9bef97827b3437eccc7a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6a16bca9a521301b1edc7a32dc59364e79a26efd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b94d3cc811ab71c94de47b3c93fdc715d75cbcf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ713626a03e63bad3b43cd0a9a4b521806a8c4c2f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7166dcefff4ea9de5137e1764a5464d157002344: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7265faac22279a2cd9fefd57d19d8284c3988e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7a799c54378c878a3f77dc08c2b889ccb66ece2e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8c3da21fa78e558372b4d13428d8e477142231fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9a6b3fcaabf6941b58bd698cc293ac5b4ef38eac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ec2d43fc26d75ee95f7c3b17210394d4bfb63ad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ee8177b1c89ea98009ac785d42937d52e400250: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9f86f862880e40146dccff90b145240bd39c5450: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa2c8ab198db458a7d95a6b29293bff613ca4ba1d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa6962a719a8edb55a081b38a9fd0c69fe4a6544d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJab25f1b3d46aee09ba18f81ac160a9e2a6761d61: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb63e5f73407d404a47c28ab02254b5789ac94cde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc0f3ec66741bae14e4f7f794ec37e4a2c88a551c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc377b88377d7f7dcfcc9ff1bea6cecbac2b0ffaf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd0f7e0a8bf898b0e846f812a40e2fd12ce4f7f4a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd5e9b05f35ce7420736d81318b40f37023984f79: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd6aaa5fd80365ddd400ad1b950c2156163047786: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd77bee49855237d564adb35e53a148bce55f7b51: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJdbdb4f680aaee768fd8f6b94864adc50332b01e1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe56a6f51c89a146c741ea2d299155cd895db7dbb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe5ff62d557722f32d3cc4d497222a8aa8b7ab7d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJec0dac8749dd4aa87cadfd11586db0b12e50d9c8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf583825f1dfbf16049ff836f5d30eff5ebad21c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJfa75f45777ad3ff9b69c4e76ce300a6721a3a685: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb24978919a3f987166a7ba5955edbe207329f5: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb7969275a6a0cdf4055febc51408af3163c1da1f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb92d110e4bc0f791cf3deede03bca21809905398: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ013bd906c94f6c8157e14d13aa5b76d9fb1f3e75: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ080e0094880e0384d33aa831920700dd8d7afb5f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ08e9ad8e2744f0581e0158258a09cf388d1a08ec: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0a91b2e33e3dc4eb0e4b007a1a8ffe5e73f0496f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1ae65af23e133301a3f4944d29829b1b62d75c9f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1d1249ee308924096d7e4899d225902aaadb405b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1e009f70e9413120433000b12991749b8dbd7d29: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ216bc78250f8c0804f0b2f390b2aa1e2d2f4261e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ27b73220eba97b55688a0db38eccddf7fdfa05c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2bfd7626da25a537fd8675182b457c8036ae11eb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2fa557f1f28cf86e0c95f0f7b2c5efa991d17aa6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ397efc09aa89d9fa4657ea9cd411d25edc1b36ce: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4268591cb30462b6861175a035ac592d23e8dcb8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f1e2a6f0917d88179b0171fda8e57d6586bd711: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f991607ad9a6b2f90ce4d7616475e3c2a6cb89b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ54f1245b382b24a48726354bb703fad130fb6945: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ59162cebb86dd595631866b9f5e1c845a422d6cd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ64700374f8558f687b68aace011bbc62fe044ed4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ68bd613d00c74dd0adbad1bf3243cbf0a096cb5c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b8515668ae4d92ec13d5615901142774bab7d07: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6d1382b8c0574adeb5f3bbbacbc4baeac852b186: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ79ce9463fda4dc483623160643977fc10b2c4895: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7db7604be2c21069f126cc3b0a57c992f768546e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7debe11afa2542a22bf9c6961e1dbe267763c9c2: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7fc2d69d95ff6d55a162e4a3c61a966747b6f319: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8b762be9fdcba57311ce1c17cb05d4a4113ff4d4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8e3452702e726da5ac1129566f6152999e3e973d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9794e7458d6f374ca9bf38358762afb7ac96b133: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9c72fc02c72e466ce24e47661615ab6e9d810410: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9df96d32c61211e6b636b30381dd8af2779fc5b7: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa386ca4238e0f8e43517193ab2efc71d0b3b81d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb3eddf03abb88945732f9e926002ccc493e3ee72: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJbef4792789ef6e6087c254e959fe9feefcfb95fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJcc14f5f146f16e5ebf0590d4bf37e8846813814a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe1ab903f09721f113ffe431c3c1c9238e636d2ab: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe6544d3fbbaf076d9ecbba00ae8334683ee29e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf271a92e37b15596e7500ccc5a32b20c7cd17196: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb04c84e885e4d4f4ebda5a5f7c1861114f8a23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "Successfully processed 0 trips with valid stop times\n",
      " No valid trip durations found - using default\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: nan minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Found 82 trips for service 11855\n",
      "Analyzing stop times for each trip...\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0c500e46af16ae241e984cf66e755390d079bbde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0ea68314b6135a0907a563ac9bfdb0005b8a3f23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ11b2c347b3f5a9fda3943b2e32be4377099d5fac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2689ffde2e01e5181fdb5b802efa736cf37a19fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4830908304f9f688f1fa0a1aeeedc6e8374c6cf6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f359654ad5933f3ebc9b830062c4cb77434059f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ57103ed29d58fbfe987264a368cde946c1df5476: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5d20ebae138bb1f86777a66fcf88fc89e4879ada: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5eaf720bfd50af13d5505baa815d0623169c6cad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6560f3e552dc6e87a5422eb22cb2dd8920bdb913: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ69990daa285cf28ee45f9bef97827b3437eccc7a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6a16bca9a521301b1edc7a32dc59364e79a26efd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b94d3cc811ab71c94de47b3c93fdc715d75cbcf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ713626a03e63bad3b43cd0a9a4b521806a8c4c2f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7166dcefff4ea9de5137e1764a5464d157002344: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7265faac22279a2cd9fefd57d19d8284c3988e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7a799c54378c878a3f77dc08c2b889ccb66ece2e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8c3da21fa78e558372b4d13428d8e477142231fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9a6b3fcaabf6941b58bd698cc293ac5b4ef38eac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ec2d43fc26d75ee95f7c3b17210394d4bfb63ad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ee8177b1c89ea98009ac785d42937d52e400250: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9f86f862880e40146dccff90b145240bd39c5450: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa2c8ab198db458a7d95a6b29293bff613ca4ba1d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa6962a719a8edb55a081b38a9fd0c69fe4a6544d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJab25f1b3d46aee09ba18f81ac160a9e2a6761d61: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb63e5f73407d404a47c28ab02254b5789ac94cde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc0f3ec66741bae14e4f7f794ec37e4a2c88a551c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc377b88377d7f7dcfcc9ff1bea6cecbac2b0ffaf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd0f7e0a8bf898b0e846f812a40e2fd12ce4f7f4a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd5e9b05f35ce7420736d81318b40f37023984f79: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd6aaa5fd80365ddd400ad1b950c2156163047786: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd77bee49855237d564adb35e53a148bce55f7b51: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJdbdb4f680aaee768fd8f6b94864adc50332b01e1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe56a6f51c89a146c741ea2d299155cd895db7dbb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe5ff62d557722f32d3cc4d497222a8aa8b7ab7d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJec0dac8749dd4aa87cadfd11586db0b12e50d9c8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf583825f1dfbf16049ff836f5d30eff5ebad21c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJfa75f45777ad3ff9b69c4e76ce300a6721a3a685: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb24978919a3f987166a7ba5955edbe207329f5: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb7969275a6a0cdf4055febc51408af3163c1da1f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb92d110e4bc0f791cf3deede03bca21809905398: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ013bd906c94f6c8157e14d13aa5b76d9fb1f3e75: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ080e0094880e0384d33aa831920700dd8d7afb5f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ08e9ad8e2744f0581e0158258a09cf388d1a08ec: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0a91b2e33e3dc4eb0e4b007a1a8ffe5e73f0496f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1ae65af23e133301a3f4944d29829b1b62d75c9f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1d1249ee308924096d7e4899d225902aaadb405b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1e009f70e9413120433000b12991749b8dbd7d29: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ216bc78250f8c0804f0b2f390b2aa1e2d2f4261e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ27b73220eba97b55688a0db38eccddf7fdfa05c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2bfd7626da25a537fd8675182b457c8036ae11eb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2fa557f1f28cf86e0c95f0f7b2c5efa991d17aa6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ397efc09aa89d9fa4657ea9cd411d25edc1b36ce: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4268591cb30462b6861175a035ac592d23e8dcb8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f1e2a6f0917d88179b0171fda8e57d6586bd711: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f991607ad9a6b2f90ce4d7616475e3c2a6cb89b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ54f1245b382b24a48726354bb703fad130fb6945: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ59162cebb86dd595631866b9f5e1c845a422d6cd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ64700374f8558f687b68aace011bbc62fe044ed4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ68bd613d00c74dd0adbad1bf3243cbf0a096cb5c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b8515668ae4d92ec13d5615901142774bab7d07: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6d1382b8c0574adeb5f3bbbacbc4baeac852b186: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ79ce9463fda4dc483623160643977fc10b2c4895: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7db7604be2c21069f126cc3b0a57c992f768546e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7debe11afa2542a22bf9c6961e1dbe267763c9c2: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7fc2d69d95ff6d55a162e4a3c61a966747b6f319: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8b762be9fdcba57311ce1c17cb05d4a4113ff4d4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8e3452702e726da5ac1129566f6152999e3e973d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9794e7458d6f374ca9bf38358762afb7ac96b133: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9c72fc02c72e466ce24e47661615ab6e9d810410: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9df96d32c61211e6b636b30381dd8af2779fc5b7: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa386ca4238e0f8e43517193ab2efc71d0b3b81d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb3eddf03abb88945732f9e926002ccc493e3ee72: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJbef4792789ef6e6087c254e959fe9feefcfb95fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJcc14f5f146f16e5ebf0590d4bf37e8846813814a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe1ab903f09721f113ffe431c3c1c9238e636d2ab: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe6544d3fbbaf076d9ecbba00ae8334683ee29e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf271a92e37b15596e7500ccc5a32b20c7cd17196: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb04c84e885e4d4f4ebda5a5f7c1861114f8a23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "Successfully processed 0 trips with valid stop times\n",
      " No valid trip durations found - using default\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: nan minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Found 82 trips for service 11855\n",
      "Analyzing stop times for each trip...\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0c500e46af16ae241e984cf66e755390d079bbde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0ea68314b6135a0907a563ac9bfdb0005b8a3f23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ11b2c347b3f5a9fda3943b2e32be4377099d5fac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2689ffde2e01e5181fdb5b802efa736cf37a19fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4830908304f9f688f1fa0a1aeeedc6e8374c6cf6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f359654ad5933f3ebc9b830062c4cb77434059f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ57103ed29d58fbfe987264a368cde946c1df5476: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5d20ebae138bb1f86777a66fcf88fc89e4879ada: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5eaf720bfd50af13d5505baa815d0623169c6cad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6560f3e552dc6e87a5422eb22cb2dd8920bdb913: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ69990daa285cf28ee45f9bef97827b3437eccc7a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6a16bca9a521301b1edc7a32dc59364e79a26efd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b94d3cc811ab71c94de47b3c93fdc715d75cbcf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ713626a03e63bad3b43cd0a9a4b521806a8c4c2f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7166dcefff4ea9de5137e1764a5464d157002344: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7265faac22279a2cd9fefd57d19d8284c3988e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7a799c54378c878a3f77dc08c2b889ccb66ece2e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8c3da21fa78e558372b4d13428d8e477142231fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9a6b3fcaabf6941b58bd698cc293ac5b4ef38eac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ec2d43fc26d75ee95f7c3b17210394d4bfb63ad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ee8177b1c89ea98009ac785d42937d52e400250: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9f86f862880e40146dccff90b145240bd39c5450: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa2c8ab198db458a7d95a6b29293bff613ca4ba1d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa6962a719a8edb55a081b38a9fd0c69fe4a6544d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJab25f1b3d46aee09ba18f81ac160a9e2a6761d61: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb63e5f73407d404a47c28ab02254b5789ac94cde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc0f3ec66741bae14e4f7f794ec37e4a2c88a551c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc377b88377d7f7dcfcc9ff1bea6cecbac2b0ffaf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd0f7e0a8bf898b0e846f812a40e2fd12ce4f7f4a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd5e9b05f35ce7420736d81318b40f37023984f79: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd6aaa5fd80365ddd400ad1b950c2156163047786: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd77bee49855237d564adb35e53a148bce55f7b51: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJdbdb4f680aaee768fd8f6b94864adc50332b01e1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe56a6f51c89a146c741ea2d299155cd895db7dbb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe5ff62d557722f32d3cc4d497222a8aa8b7ab7d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJec0dac8749dd4aa87cadfd11586db0b12e50d9c8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf583825f1dfbf16049ff836f5d30eff5ebad21c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJfa75f45777ad3ff9b69c4e76ce300a6721a3a685: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb24978919a3f987166a7ba5955edbe207329f5: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb7969275a6a0cdf4055febc51408af3163c1da1f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb92d110e4bc0f791cf3deede03bca21809905398: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ013bd906c94f6c8157e14d13aa5b76d9fb1f3e75: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ080e0094880e0384d33aa831920700dd8d7afb5f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ08e9ad8e2744f0581e0158258a09cf388d1a08ec: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0a91b2e33e3dc4eb0e4b007a1a8ffe5e73f0496f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1ae65af23e133301a3f4944d29829b1b62d75c9f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1d1249ee308924096d7e4899d225902aaadb405b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1e009f70e9413120433000b12991749b8dbd7d29: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ216bc78250f8c0804f0b2f390b2aa1e2d2f4261e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ27b73220eba97b55688a0db38eccddf7fdfa05c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2bfd7626da25a537fd8675182b457c8036ae11eb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2fa557f1f28cf86e0c95f0f7b2c5efa991d17aa6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ397efc09aa89d9fa4657ea9cd411d25edc1b36ce: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4268591cb30462b6861175a035ac592d23e8dcb8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f1e2a6f0917d88179b0171fda8e57d6586bd711: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f991607ad9a6b2f90ce4d7616475e3c2a6cb89b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ54f1245b382b24a48726354bb703fad130fb6945: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ59162cebb86dd595631866b9f5e1c845a422d6cd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ64700374f8558f687b68aace011bbc62fe044ed4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ68bd613d00c74dd0adbad1bf3243cbf0a096cb5c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b8515668ae4d92ec13d5615901142774bab7d07: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6d1382b8c0574adeb5f3bbbacbc4baeac852b186: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ79ce9463fda4dc483623160643977fc10b2c4895: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7db7604be2c21069f126cc3b0a57c992f768546e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7debe11afa2542a22bf9c6961e1dbe267763c9c2: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7fc2d69d95ff6d55a162e4a3c61a966747b6f319: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8b762be9fdcba57311ce1c17cb05d4a4113ff4d4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8e3452702e726da5ac1129566f6152999e3e973d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9794e7458d6f374ca9bf38358762afb7ac96b133: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9c72fc02c72e466ce24e47661615ab6e9d810410: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9df96d32c61211e6b636b30381dd8af2779fc5b7: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa386ca4238e0f8e43517193ab2efc71d0b3b81d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb3eddf03abb88945732f9e926002ccc493e3ee72: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJbef4792789ef6e6087c254e959fe9feefcfb95fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJcc14f5f146f16e5ebf0590d4bf37e8846813814a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe1ab903f09721f113ffe431c3c1c9238e636d2ab: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe6544d3fbbaf076d9ecbba00ae8334683ee29e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf271a92e37b15596e7500ccc5a32b20c7cd17196: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb04c84e885e4d4f4ebda5a5f7c1861114f8a23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "Successfully processed 0 trips with valid stop times\n",
      " No valid trip durations found - using default\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: 27.4 minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Found 82 trips for service 11855\n",
      "Analyzing stop times for each trip...\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0c500e46af16ae241e984cf66e755390d079bbde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0ea68314b6135a0907a563ac9bfdb0005b8a3f23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ11b2c347b3f5a9fda3943b2e32be4377099d5fac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2689ffde2e01e5181fdb5b802efa736cf37a19fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4830908304f9f688f1fa0a1aeeedc6e8374c6cf6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f359654ad5933f3ebc9b830062c4cb77434059f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ57103ed29d58fbfe987264a368cde946c1df5476: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5d20ebae138bb1f86777a66fcf88fc89e4879ada: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ5eaf720bfd50af13d5505baa815d0623169c6cad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6560f3e552dc6e87a5422eb22cb2dd8920bdb913: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ69990daa285cf28ee45f9bef97827b3437eccc7a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6a16bca9a521301b1edc7a32dc59364e79a26efd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b94d3cc811ab71c94de47b3c93fdc715d75cbcf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ713626a03e63bad3b43cd0a9a4b521806a8c4c2f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7166dcefff4ea9de5137e1764a5464d157002344: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7265faac22279a2cd9fefd57d19d8284c3988e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7a799c54378c878a3f77dc08c2b889ccb66ece2e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8c3da21fa78e558372b4d13428d8e477142231fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9a6b3fcaabf6941b58bd698cc293ac5b4ef38eac: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ec2d43fc26d75ee95f7c3b17210394d4bfb63ad: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9ee8177b1c89ea98009ac785d42937d52e400250: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9f86f862880e40146dccff90b145240bd39c5450: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa2c8ab198db458a7d95a6b29293bff613ca4ba1d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa6962a719a8edb55a081b38a9fd0c69fe4a6544d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJab25f1b3d46aee09ba18f81ac160a9e2a6761d61: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb63e5f73407d404a47c28ab02254b5789ac94cde: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc0f3ec66741bae14e4f7f794ec37e4a2c88a551c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJc377b88377d7f7dcfcc9ff1bea6cecbac2b0ffaf: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd0f7e0a8bf898b0e846f812a40e2fd12ce4f7f4a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd5e9b05f35ce7420736d81318b40f37023984f79: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd6aaa5fd80365ddd400ad1b950c2156163047786: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJd77bee49855237d564adb35e53a148bce55f7b51: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJdbdb4f680aaee768fd8f6b94864adc50332b01e1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe56a6f51c89a146c741ea2d299155cd895db7dbb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe5ff62d557722f32d3cc4d497222a8aa8b7ab7d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJec0dac8749dd4aa87cadfd11586db0b12e50d9c8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf583825f1dfbf16049ff836f5d30eff5ebad21c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJfa75f45777ad3ff9b69c4e76ce300a6721a3a685: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb24978919a3f987166a7ba5955edbe207329f5: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb7969275a6a0cdf4055febc51408af3163c1da1f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb92d110e4bc0f791cf3deede03bca21809905398: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ013bd906c94f6c8157e14d13aa5b76d9fb1f3e75: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ080e0094880e0384d33aa831920700dd8d7afb5f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ08e9ad8e2744f0581e0158258a09cf388d1a08ec: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ0a91b2e33e3dc4eb0e4b007a1a8ffe5e73f0496f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1ae65af23e133301a3f4944d29829b1b62d75c9f: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1d1249ee308924096d7e4899d225902aaadb405b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ1e009f70e9413120433000b12991749b8dbd7d29: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ216bc78250f8c0804f0b2f390b2aa1e2d2f4261e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ27b73220eba97b55688a0db38eccddf7fdfa05c1: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2bfd7626da25a537fd8675182b457c8036ae11eb: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ2fa557f1f28cf86e0c95f0f7b2c5efa991d17aa6: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ397efc09aa89d9fa4657ea9cd411d25edc1b36ce: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4268591cb30462b6861175a035ac592d23e8dcb8: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f1e2a6f0917d88179b0171fda8e57d6586bd711: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ4f991607ad9a6b2f90ce4d7616475e3c2a6cb89b: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ54f1245b382b24a48726354bb703fad130fb6945: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ59162cebb86dd595631866b9f5e1c845a422d6cd: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ64700374f8558f687b68aace011bbc62fe044ed4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ68bd613d00c74dd0adbad1bf3243cbf0a096cb5c: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6b8515668ae4d92ec13d5615901142774bab7d07: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ6d1382b8c0574adeb5f3bbbacbc4baeac852b186: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ79ce9463fda4dc483623160643977fc10b2c4895: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7db7604be2c21069f126cc3b0a57c992f768546e: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7debe11afa2542a22bf9c6961e1dbe267763c9c2: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ7fc2d69d95ff6d55a162e4a3c61a966747b6f319: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8b762be9fdcba57311ce1c17cb05d4a4113ff4d4: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ8e3452702e726da5ac1129566f6152999e3e973d: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9794e7458d6f374ca9bf38358762afb7ac96b133: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9c72fc02c72e466ce24e47661615ab6e9d810410: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJ9df96d32c61211e6b636b30381dd8af2779fc5b7: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJa386ca4238e0f8e43517193ab2efc71d0b3b81d0: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJb3eddf03abb88945732f9e926002ccc493e3ee72: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJbef4792789ef6e6087c254e959fe9feefcfb95fa: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJcc14f5f146f16e5ebf0590d4bf37e8846813814a: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe1ab903f09721f113ffe431c3c1c9238e636d2ab: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJe6544d3fbbaf076d9ecbba00ae8334683ee29e63: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJf271a92e37b15596e7500ccc5a32b20c7cd17196: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "  Trip VJffb04c84e885e4d4f4ebda5a5f7c1861114f8a23: Error processing stop times - 'Schedule' object has no attribute 'stop_times_to_dataframe'\n",
      "Successfully processed 0 trips with valid stop times\n",
      " No valid trip durations found - using default\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL ROUTES TESTED:\n",
      "service_id  avg_headway  round_trip_time  vehicles_needed  calculation_success  trips_analyzed median_trip_duration\n",
      "     11855          NaN             60.0              NaN                False               0                 None\n",
      "     11855         25.5             60.0              2.4                False               0                 None\n",
      "     11855          NaN             60.0              NaN                False               0                 None\n",
      "     11855          NaN             60.0              NaN                False               0                 None\n",
      "     11855         27.4             60.0              2.2                False               0                 None\n",
      "\n",
      "Calculation success rate: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "def calculate_route_round_trip_time_from_stops(genet_feed, \n",
    "                                             service_id: str, \n",
    "                                             gtfs_day: str = \"20230814\",\n",
    "                                             turnaround_buffer: float = 1.15,\n",
    "                                             default_round_trip_time: float = 60.0,\n",
    "                                             verbose: bool = True) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate round-trip time for a route using actual stop times data.\n",
    "    \n",
    "    This method is much more accurate than using trip-level start/end times because:\n",
    "    1. It uses actual scheduled stop times from stop_times.txt\n",
    "    2. It calculates the full journey time from first to last stop\n",
    "    3. It accounts for real operational patterns, not assumptions\n",
    "    \n",
    "    Args:\n",
    "        genet_feed: Genet feed object\n",
    "        service_id: GTFS service identifier  \n",
    "        gtfs_day: Analysis date\n",
    "        turnaround_buffer: Multiplier for round-trip (e.g., 1.15 = 15% buffer)\n",
    "        default_round_trip_time: Fallback value if calculation fails\n",
    "        verbose: Whether to print diagnostic information\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[float, Dict]: (calculated_round_trip_time, diagnostic_info)\n",
    "    \"\"\"\n",
    "    \n",
    "    diagnostics = {\n",
    "        'service_id': service_id,\n",
    "        'method': 'stop_times_analysis',\n",
    "        'success': False,\n",
    "        'trips_found': 0,\n",
    "        'trips_with_valid_stops': 0,\n",
    "        'valid_durations_count': 0,\n",
    "        'median_trip_duration': None,\n",
    "        'min_trip_duration': None,\n",
    "        'max_trip_duration': None,\n",
    "        'calculated_round_trip': None,\n",
    "        'turnaround_buffer_used': turnaround_buffer,\n",
    "        'fallback_used': False,\n",
    "        'error_message': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if verbose:\n",
    "            print(f\"\\n=== CALCULATING ROUND-TRIP TIME FOR SERVICE {service_id} ===\")\n",
    "        \n",
    "        # Step 1: Get all trips for this service\n",
    "        trips_df = genet_feed.trips_to_dataframe(gtfs_day=gtfs_day)\n",
    "        service_trips = trips_df[trips_df['service_id'] == service_id]\n",
    "        diagnostics['trips_found'] = len(service_trips)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Found {len(service_trips)} trips for service {service_id}\")\n",
    "        \n",
    "        if len(service_trips) == 0:\n",
    "            diagnostics['error_message'] = 'No trips found for service'\n",
    "            if verbose:\n",
    "                print(\" No trips found - using default\")\n",
    "            diagnostics['fallback_used'] = True\n",
    "            return default_round_trip_time, diagnostics\n",
    "        \n",
    "        # Step 2: Get stop times data for all trips\n",
    "        if verbose:\n",
    "            print(\"Analyzing stop times for each trip...\")\n",
    "        \n",
    "        trip_durations = []\n",
    "        trips_processed = 0\n",
    "        \n",
    "        for trip_id in service_trips['trip_id']:\n",
    "            try:\n",
    "                # Get stop times for this specific trip\n",
    "                stop_times_df = genet_feed.stop_times_to_dataframe(trip_ids=[trip_id])\n",
    "                \n",
    "                if len(stop_times_df) < 2:\n",
    "                    if verbose:\n",
    "                        print(f\"  Trip {trip_id}: Only {len(stop_times_df)} stops - skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Sort by stop sequence to ensure correct order\n",
    "                stop_times_df = stop_times_df.sort_values('stop_sequence')\n",
    "                \n",
    "                # Get first and last stop times\n",
    "                first_stop_time = stop_times_df.iloc[0]['departure_time']\n",
    "                last_stop_time = stop_times_df.iloc[-1]['arrival_time']\n",
    "                \n",
    "                # Calculate trip duration in minutes\n",
    "                duration_minutes = (last_stop_time - first_stop_time).total_seconds() / 60\n",
    "                \n",
    "                if duration_minutes > 0:  # Valid duration\n",
    "                    trip_durations.append(duration_minutes)\n",
    "                    trips_processed += 1\n",
    "                    \n",
    "                    if verbose and trips_processed <= 3:  # Show first few for debugging\n",
    "                        print(f\"  Trip {trip_id}: {len(stop_times_df)} stops, \"\n",
    "                              f\"{duration_minutes:.1f} minutes \"\n",
    "                              f\"({first_stop_time.strftime('%H:%M')}  {last_stop_time.strftime('%H:%M')})\")\n",
    "                elif verbose:\n",
    "                    print(f\"  Trip {trip_id}: Invalid duration ({duration_minutes:.1f} min) - skipping\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  Trip {trip_id}: Error processing stop times - {e}\")\n",
    "                continue\n",
    "        \n",
    "        diagnostics['trips_with_valid_stops'] = trips_processed\n",
    "        diagnostics['valid_durations_count'] = len(trip_durations)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Successfully processed {trips_processed} trips with valid stop times\")\n",
    "        \n",
    "        # Step 3: Calculate statistics and round-trip time\n",
    "        if len(trip_durations) == 0:\n",
    "            diagnostics['error_message'] = 'No valid trip durations found'\n",
    "            if verbose:\n",
    "                print(\" No valid trip durations found - using default\")\n",
    "            diagnostics['fallback_used'] = True\n",
    "            return default_round_trip_time, diagnostics\n",
    "        \n",
    "        # Calculate trip duration statistics\n",
    "        trip_durations = np.array(trip_durations)\n",
    "        median_duration = np.median(trip_durations)\n",
    "        min_duration = np.min(trip_durations)\n",
    "        max_duration = np.max(trip_durations)\n",
    "        \n",
    "        # Calculate round-trip time with buffer\n",
    "        round_trip_time = median_duration * 2 * turnaround_buffer\n",
    "        \n",
    "        # Store diagnostics\n",
    "        diagnostics['median_trip_duration'] = float(median_duration)\n",
    "        diagnostics['min_trip_duration'] = float(min_duration)\n",
    "        diagnostics['max_trip_duration'] = float(max_duration)\n",
    "        diagnostics['calculated_round_trip'] = float(round_trip_time)\n",
    "        diagnostics['success'] = True\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n TRIP DURATION ANALYSIS:\")\n",
    "            print(f\"  Valid trips analyzed: {len(trip_durations)}\")\n",
    "            print(f\"  Trip duration range: {min_duration:.1f} - {max_duration:.1f} minutes\")\n",
    "            print(f\"  Median trip duration: {median_duration:.1f} minutes\")\n",
    "            print(f\"  Estimated round-trip: {median_duration:.1f}  2  {turnaround_buffer} = {round_trip_time:.1f} minutes\")\n",
    "            print(f\" Round-trip calculation successful!\")\n",
    "        \n",
    "        return round_trip_time, diagnostics\n",
    "        \n",
    "    except Exception as e:\n",
    "        diagnostics['error_message'] = str(e)\n",
    "        diagnostics['fallback_used'] = True\n",
    "        if verbose:\n",
    "            print(f\" Error in round-trip calculation: {e}\")\n",
    "            print(f\"Using default round-trip time: {default_round_trip_time} minutes\")\n",
    "        return default_round_trip_time, diagnostics\n",
    "\n",
    "\n",
    "def test_round_trip_calculation(genet_feed, gtfs_day: str = \"20230814\", max_routes: int = 5):\n",
    "    \"\"\"\n",
    "    Test the round-trip calculation on multiple routes to see how it works.\n",
    "    \"\"\"\n",
    "    print(\"=== TESTING ROUND-TRIP TIME CALCULATION ===\")\n",
    "    \n",
    "    # Get some routes to test\n",
    "    headway_df = genet_feed.headway_stats(gtfs_day=gtfs_day)\n",
    "    test_routes = headway_df.head(max_routes)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, route_info in test_routes.iterrows():\n",
    "        service_id = route_info['service_id']\n",
    "        avg_headway = route_info['mean_headway_mins']\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TESTING SERVICE: {service_id}\")\n",
    "        print(f\"Average headway: {avg_headway:.1f} minutes\")\n",
    "        \n",
    "        # Calculate round-trip time\n",
    "        round_trip_time, diagnostics = calculate_route_round_trip_time_from_stops(\n",
    "            genet_feed, service_id, gtfs_day, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Calculate vehicles needed\n",
    "        if diagnostics['success']:\n",
    "            vehicles_needed = round_trip_time / avg_headway\n",
    "            print(f\"\\n VEHICLE REQUIREMENT:\")\n",
    "            print(f\"  Vehicles needed: {round_trip_time:.1f}  {avg_headway:.1f} = {vehicles_needed:.1f} vehicles\")\n",
    "        \n",
    "        results.append({\n",
    "            'service_id': service_id,\n",
    "            'avg_headway': avg_headway,\n",
    "            'round_trip_time': round_trip_time,\n",
    "            'vehicles_needed': round_trip_time / avg_headway if avg_headway > 0 else np.nan,\n",
    "            'calculation_success': diagnostics['success'],\n",
    "            'trips_analyzed': diagnostics['valid_durations_count'],\n",
    "            'median_trip_duration': diagnostics['median_trip_duration']\n",
    "        })\n",
    "    \n",
    "    # Summary table\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY OF ALL ROUTES TESTED:\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.round(1).to_string(index=False))\n",
    "    \n",
    "    # Success rate\n",
    "    success_rate = results_df['calculation_success'].mean() * 100\n",
    "    print(f\"\\nCalculation success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# TEST THE NEW CALCULATION\n",
    "print(\"Testing the improved round-trip calculation method...\")\n",
    "results_df = test_round_trip_calculation(feed, gtfs_day=\"20230814\", max_routes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1c5a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the corrected round-trip calculation method...\n",
      "=== TESTING FIXED ROUND-TRIP TIME CALCULATION ===\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: nan minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Retrieved trips_with_stops data: 294071 records\n",
      "Columns available: ['from_stop', 'arrival_time', 'service_name', 'to_stop_name', 'to_stop', 'route_id', 'service_id', 'departure_time', 'mode', 'from_stop_name', 'route_name', 'trip_id', 'vehicle_id']\n",
      "Found 6512 stop records for service 11855\n",
      "Covering 82 unique trips\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: 39 stops, 29.0 minutes (05:33  06:02)\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: 82 stops, 80.0 minutes (16:45  18:05)\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: 82 stops, 80.0 minutes (09:53  11:13)\n",
      "Successfully calculated durations for 82 trips\n",
      "\n",
      " TRIP DURATION ANALYSIS:\n",
      "  Valid trips analyzed: 82\n",
      "  Duration range: 27.0 - 100.0 minutes\n",
      "  Median trip duration: 80.0 minutes\n",
      "  Round-trip calculation: 80.0  2  1.15 = 184.0 minutes\n",
      " Round-trip calculation successful!\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: 25.5 minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Retrieved trips_with_stops data: 294071 records\n",
      "Columns available: ['from_stop', 'arrival_time', 'service_name', 'to_stop_name', 'to_stop', 'route_id', 'service_id', 'departure_time', 'mode', 'from_stop_name', 'route_name', 'trip_id', 'vehicle_id']\n",
      "Found 6512 stop records for service 11855\n",
      "Covering 82 unique trips\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: 39 stops, 29.0 minutes (05:33  06:02)\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: 82 stops, 80.0 minutes (16:45  18:05)\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: 82 stops, 80.0 minutes (09:53  11:13)\n",
      "Successfully calculated durations for 82 trips\n",
      "\n",
      " TRIP DURATION ANALYSIS:\n",
      "  Valid trips analyzed: 82\n",
      "  Duration range: 27.0 - 100.0 minutes\n",
      "  Median trip duration: 80.0 minutes\n",
      "  Round-trip calculation: 80.0  2  1.15 = 184.0 minutes\n",
      " Round-trip calculation successful!\n",
      "\n",
      " VEHICLE REQUIREMENT:\n",
      "  Vehicles needed: 184.0  25.5 = 7.2 vehicles\n",
      "\n",
      "============================================================\n",
      "TESTING SERVICE: 11855\n",
      "Average headway: nan minutes\n",
      "\n",
      "=== CALCULATING ROUND-TRIP TIME FOR SERVICE 11855 ===\n",
      "Retrieved trips_with_stops data: 294071 records\n",
      "Columns available: ['from_stop', 'arrival_time', 'service_name', 'to_stop_name', 'to_stop', 'route_id', 'service_id', 'departure_time', 'mode', 'from_stop_name', 'route_name', 'trip_id', 'vehicle_id']\n",
      "Found 6512 stop records for service 11855\n",
      "Covering 82 unique trips\n",
      "  Trip VJa79a2689eef92ae5e0f24ae32b324b43c8f58ced: 39 stops, 29.0 minutes (05:33  06:02)\n",
      "  Trip VJ039542b7a26132c6c50b77f760fa8aa838b1fafd: 82 stops, 80.0 minutes (16:45  18:05)\n",
      "  Trip VJ06f4e90aa3ce001a40260ef60fa9ad728b9a2020: 82 stops, 80.0 minutes (09:53  11:13)\n",
      "Successfully calculated durations for 82 trips\n",
      "\n",
      " TRIP DURATION ANALYSIS:\n",
      "  Valid trips analyzed: 82\n",
      "  Duration range: 27.0 - 100.0 minutes\n",
      "  Median trip duration: 80.0 minutes\n",
      "  Round-trip calculation: 80.0  2  1.15 = 184.0 minutes\n",
      " Round-trip calculation successful!\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL ROUTES TESTED:\n",
      "service_id  avg_headway  round_trip_time  vehicles_needed  calculation_success  trips_analyzed  median_trip_duration\n",
      "     11855          NaN            184.0              NaN                 True              82                  80.0\n",
      "     11855         25.5            184.0              7.2                 True              82                  80.0\n",
      "     11855          NaN            184.0              NaN                 True              82                  80.0\n",
      "\n",
      "Calculation success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def calculate_route_round_trip_time_fixed(genet_feed, \n",
    "                                        service_id: str, \n",
    "                                        gtfs_day: str = \"20230814\",\n",
    "                                        turnaround_buffer: float = 1.15,\n",
    "                                        default_round_trip_time: float = 60.0,\n",
    "                                        verbose: bool = True) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate round-trip time using genet's trips_with_stops_to_dataframe method.\n",
    "    This method provides stop-level timing data for accurate calculations.\n",
    "    \"\"\"\n",
    "    \n",
    "    diagnostics = {\n",
    "        'service_id': service_id,\n",
    "        'method': 'trips_with_stops_analysis',\n",
    "        'success': False,\n",
    "        'trips_found': 0,\n",
    "        'trips_with_valid_stops': 0,\n",
    "        'valid_durations_count': 0,\n",
    "        'median_trip_duration': None,\n",
    "        'calculated_round_trip': None,\n",
    "        'turnaround_buffer_used': turnaround_buffer,\n",
    "        'fallback_used': False,\n",
    "        'error_message': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if verbose:\n",
    "            print(f\"\\n=== CALCULATING ROUND-TRIP TIME FOR SERVICE {service_id} ===\")\n",
    "        \n",
    "        # Step 1: Get trips with stops data\n",
    "        trips_with_stops_df = genet_feed.trips_with_stops_to_dataframe(gtfs_day=gtfs_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Retrieved trips_with_stops data: {len(trips_with_stops_df)} records\")\n",
    "            if len(trips_with_stops_df) > 0:\n",
    "                print(f\"Columns available: {list(trips_with_stops_df.columns)}\")\n",
    "        \n",
    "        # Step 2: Filter to our service\n",
    "        service_data = trips_with_stops_df[trips_with_stops_df['service_id'] == service_id]\n",
    "        unique_trips = service_data['trip_id'].unique() if len(service_data) > 0 else []\n",
    "        diagnostics['trips_found'] = len(unique_trips)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Found {len(service_data)} stop records for service {service_id}\")\n",
    "            print(f\"Covering {len(unique_trips)} unique trips\")\n",
    "        \n",
    "        if len(service_data) == 0:\n",
    "            diagnostics['error_message'] = 'No stop data found for service'\n",
    "            if verbose:\n",
    "                print(\" No stop data found - using default\")\n",
    "            diagnostics['fallback_used'] = True\n",
    "            return default_round_trip_time, diagnostics\n",
    "        \n",
    "        # Step 3: Calculate trip durations\n",
    "        trip_durations = []\n",
    "        \n",
    "        for trip_id in unique_trips:\n",
    "            trip_stops = service_data[service_data['trip_id'] == trip_id].copy()\n",
    "            \n",
    "            if len(trip_stops) < 2:\n",
    "                if verbose and len(trip_durations) < 3:\n",
    "                    print(f\"  Trip {trip_id}: Only {len(trip_stops)} stops - skipping\")\n",
    "                continue\n",
    "                \n",
    "            # Sort by departure time to get chronological order\n",
    "            trip_stops = trip_stops.sort_values('departure_time')\n",
    "            \n",
    "            # Get first and last stop times\n",
    "            first_stop = trip_stops.iloc[0]\n",
    "            last_stop = trip_stops.iloc[-1]\n",
    "            \n",
    "            # Use departure_time for first stop, arrival_time for last stop\n",
    "            start_time = first_stop['departure_time']\n",
    "            end_time = last_stop['arrival_time']\n",
    "            \n",
    "            # Calculate duration in minutes\n",
    "            duration_minutes = (end_time - start_time).total_seconds() / 60\n",
    "            \n",
    "            if duration_minutes > 0:\n",
    "                trip_durations.append(duration_minutes)\n",
    "                \n",
    "                if verbose and len(trip_durations) <= 3:  # Show first few for debugging\n",
    "                    print(f\"  Trip {trip_id}: {len(trip_stops)} stops, \"\n",
    "                          f\"{duration_minutes:.1f} minutes \"\n",
    "                          f\"({start_time.strftime('%H:%M')}  {end_time.strftime('%H:%M')})\")\n",
    "            elif verbose and len(trip_durations) < 3:\n",
    "                print(f\"  Trip {trip_id}: Invalid duration ({duration_minutes:.1f} min) - skipping\")\n",
    "        \n",
    "        diagnostics['trips_with_valid_stops'] = len(trip_durations)\n",
    "        diagnostics['valid_durations_count'] = len(trip_durations)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Successfully calculated durations for {len(trip_durations)} trips\")\n",
    "        \n",
    "        # Step 4: Calculate round-trip time\n",
    "        if len(trip_durations) == 0:\n",
    "            diagnostics['error_message'] = 'No valid trip durations calculated'\n",
    "            if verbose:\n",
    "                print(\" No valid trip durations - using default\")\n",
    "            diagnostics['fallback_used'] = True\n",
    "            return default_round_trip_time, diagnostics\n",
    "        \n",
    "        # Use median duration (robust to outliers) and apply turnaround buffer\n",
    "        trip_durations_array = np.array(trip_durations)\n",
    "        median_duration = np.median(trip_durations_array)\n",
    "        round_trip_time = median_duration * 2 * turnaround_buffer\n",
    "        \n",
    "        diagnostics['median_trip_duration'] = float(median_duration)\n",
    "        diagnostics['calculated_round_trip'] = float(round_trip_time)\n",
    "        diagnostics['success'] = True\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n TRIP DURATION ANALYSIS:\")\n",
    "            print(f\"  Valid trips analyzed: {len(trip_durations)}\")\n",
    "            print(f\"  Duration range: {np.min(trip_durations_array):.1f} - {np.max(trip_durations_array):.1f} minutes\")\n",
    "            print(f\"  Median trip duration: {median_duration:.1f} minutes\")\n",
    "            print(f\"  Round-trip calculation: {median_duration:.1f}  2  {turnaround_buffer} = {round_trip_time:.1f} minutes\")\n",
    "            print(f\" Round-trip calculation successful!\")\n",
    "        \n",
    "        return round_trip_time, diagnostics\n",
    "        \n",
    "    except Exception as e:\n",
    "        diagnostics['error_message'] = str(e)\n",
    "        diagnostics['fallback_used'] = True\n",
    "        if verbose:\n",
    "            print(f\" Error in round-trip calculation: {e}\")\n",
    "            print(f\"Using default round-trip time: {default_round_trip_time} minutes\")\n",
    "        return default_round_trip_time, diagnostics\n",
    "\n",
    "\n",
    "def test_fixed_round_trip_calculation(genet_feed, gtfs_day: str = \"20230814\", max_routes: int = 5):\n",
    "    \"\"\"\n",
    "    Test the fixed round-trip calculation method.\n",
    "    \"\"\"\n",
    "    print(\"=== TESTING FIXED ROUND-TRIP TIME CALCULATION ===\")\n",
    "    \n",
    "    # Get some routes to test\n",
    "    headway_df = genet_feed.headway_stats(gtfs_day=gtfs_day)\n",
    "    test_routes = headway_df.head(max_routes)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, route_info in test_routes.iterrows():\n",
    "        service_id = route_info['service_id']\n",
    "        avg_headway = route_info['mean_headway_mins']\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TESTING SERVICE: {service_id}\")\n",
    "        print(f\"Average headway: {avg_headway:.1f} minutes\")\n",
    "        \n",
    "        # Calculate round-trip time using the fixed method\n",
    "        round_trip_time, diagnostics = calculate_route_round_trip_time_fixed(\n",
    "            genet_feed, service_id, gtfs_day, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Calculate vehicles needed\n",
    "        if diagnostics['success'] and avg_headway > 0:\n",
    "            vehicles_needed = round_trip_time / avg_headway\n",
    "            print(f\"\\n VEHICLE REQUIREMENT:\")\n",
    "            print(f\"  Vehicles needed: {round_trip_time:.1f}  {avg_headway:.1f} = {vehicles_needed:.1f} vehicles\")\n",
    "        \n",
    "        results.append({\n",
    "            'service_id': service_id,\n",
    "            'avg_headway': avg_headway,\n",
    "            'round_trip_time': round_trip_time,\n",
    "            'vehicles_needed': round_trip_time / avg_headway if avg_headway > 0 else np.nan,\n",
    "            'calculation_success': diagnostics['success'],\n",
    "            'trips_analyzed': diagnostics['valid_durations_count'],\n",
    "            'median_trip_duration': diagnostics['median_trip_duration'],\n",
    "            'error_message': diagnostics['error_message']\n",
    "        })\n",
    "    \n",
    "    # Summary table\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY OF ALL ROUTES TESTED:\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display_columns = ['service_id', 'avg_headway', 'round_trip_time', 'vehicles_needed', \n",
    "                      'calculation_success', 'trips_analyzed', 'median_trip_duration']\n",
    "    print(results_df[display_columns].round(1).to_string(index=False))\n",
    "    \n",
    "    # Show errors if any\n",
    "    failed_routes = results_df[~results_df['calculation_success']]\n",
    "    if len(failed_routes) > 0:\n",
    "        print(f\"\\nFailed routes:\")\n",
    "        for _, row in failed_routes.iterrows():\n",
    "            print(f\"  {row['service_id']}: {row['error_message']}\")\n",
    "    \n",
    "    # Success rate\n",
    "    success_rate = results_df['calculation_success'].mean() * 100\n",
    "    print(f\"\\nCalculation success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "# TEST THE FIXED CALCULATION\n",
    "print(\"Testing the corrected round-trip calculation method...\")\n",
    "results_df = test_fixed_round_trip_calculation(feed, gtfs_day=\"20230814\", max_routes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db65db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE (FIXED VERSION) ===\n",
      "=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\n",
      "1. Creating GTFS data extractor...\n",
      "  Loading GTFS feed from ../data/external/study_area_gtfs_bus.zip...\n",
      " GTFS feed loaded in 3.20 seconds\n",
      "  Pre-loading GTFS tables...\n",
      "    Loaded 13,974 trips\n",
      "    Loaded 703,721 stop times\n",
      "    Loaded 187 routes\n",
      "    Converting departure times...\n",
      "    Departure time column type: string\n",
      "    Sample departure times: ['05:30:00', '05:34:00', '05:35:00']\n",
      "    Converted 703,721/703,721 departure times (100.0%)\n",
      "    Time conversion completed in 1.85 seconds\n",
      " Data pre-loaded in 1.95 seconds\n",
      "    Extractor created in 5.15 seconds\n",
      "2. Extracting route data...\n",
      "  Extracting GTFS data with 3-hour intervals...\n",
      " Found 278 unique services to process\n",
      "    Progress: 50/278 (18.0%) - Elapsed: 9.5s - Success rate: 50/50 (100.0%)\n",
      "    Progress: 100/278 (36.0%) - Elapsed: 12.1s - Success rate: 100/100 (100.0%)\n",
      "    Progress: 150/278 (54.0%) - Elapsed: 13.8s - Success rate: 150/150 (100.0%)\n",
      "    Progress: 200/278 (71.9%) - Elapsed: 15.6s - Success rate: 200/200 (100.0%)\n",
      "    Progress: 250/278 (89.9%) - Elapsed: 18.9s - Success rate: 250/250 (100.0%)\n",
      " Successfully extracted 278 routes in 21.17 seconds\n",
      "    Success rate: 278/278 (100.0%)\n",
      "    Average time per service: 0.076s\n",
      "    Route extraction completed in 21.17 seconds\n",
      "3. Setting up optimization constraints...\n",
      "    Constraints setup in 0.000 seconds\n",
      "4. Creating route configurations...\n",
      "    Route configs created in 0.002 seconds\n",
      "5. Initializing vehicle constraint calculator...\n",
      "    Vehicle calculator initialized in 0.002 seconds\n",
      " Successfully initialized optimization data for 278 routes\n",
      "    Total initialization time: 26.33 seconds\n",
      "    Baseline fleet size: 2193.6 vehicles\n",
      "\n",
      "  TIMING BREAKDOWN:\n",
      "   Extractor creation: 5.15s (19.6%)\n",
      "   Route extraction: 21.17s (80.4%)\n",
      "   Constraints setup: 0.000s (0.0%)\n",
      "   Route configs: 0.002s (0.0%)\n",
      "   Vehicle calculator: 0.002s (0.0%)\n",
      "\n",
      " TOTAL PIPELINE TIME: 26.36 seconds\n",
      " Average time per route: 0.095 seconds\n",
      "\n",
      "Core route summary:\n",
      "  service_id route_name  agency  avg_headway  round_trip_time\n",
      "0       1221         A1  OP6801         52.3             80.5\n",
      "1       1302         A1  OP6801         59.6             98.9\n",
      "2       1303         A1  OP6801         59.0             98.9\n",
      "3       1304         A1  OP6801         47.9             94.3\n",
      "4       1305         A1  OP6801         65.7             80.5\n",
      "5       1306         A1  OP6801         56.1            108.1\n",
      "6       1307         A2  OP6801         27.6            177.1\n",
      "7       1308         A2  OP6801         29.6            165.6\n",
      "8       1309         A2  OP6801         46.0            170.2\n",
      "9       3194        PH5   OP671          8.7             80.5\n",
      "\n",
      "Optimization setup:\n",
      "  Total decision variables: 2224 (278 routes  8 intervals)\n",
      "  Time intervals: ['00-03h', '03-06h', '06-09h', '09-12h', '12-15h', '15-18h', '18-21h', '21-24h']\n",
      "  Service periods: 1465/2224 (65.9%)\n",
      "  User constraints: 5.0 - 120.0 minutes\n",
      "  Baseline fleet size: 2193.6 vehicles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gtfs_kit as gk\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "\n",
    "# GOOD\n",
    "# =============================================================================\n",
    "# CORE DATA STRUCTURES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class RouteConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration for a single transit route/service.\n",
    "    \"\"\"\n",
    "    service_id: str\n",
    "    route_name: str\n",
    "    agency_id: str\n",
    "    headways_by_interval: np.ndarray\n",
    "    min_headway: float\n",
    "    max_headway: float\n",
    "    operating_hours: Tuple[int, int]\n",
    "    route_color: str\n",
    "    interval_hours: int\n",
    "    round_trip_time: float\n",
    "\n",
    "# =============================================================================\n",
    "# GTFS DATA EXTRACTION LAYER - FIXED TIME CONVERSION\n",
    "# =============================================================================\n",
    "\n",
    "class GTFSDataExtractor:\n",
    "    \"\"\"\n",
    "    Handles extraction and processing of transit data from GTFS feeds via gtfs_kit.\n",
    "    \n",
    "    FIXED VERSION with proper time string conversion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 gtfs_path: str,\n",
    "                 date: str = \"20230814\",\n",
    "                 interval_hours: int = 3,\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"\n",
    "        Initialize the GTFS data extractor.\n",
    "        \"\"\"\n",
    "        if 24 % interval_hours != 0:\n",
    "            raise ValueError(f\"interval_hours ({interval_hours}) must divide 24 evenly\")\n",
    "            \n",
    "        self.gtfs_path = gtfs_path\n",
    "        self.date = date\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.fallback_headway = fallback_headway\n",
    "        self.default_round_trip_time = default_round_trip_time\n",
    "        \n",
    "        # Load GTFS feed with timing\n",
    "        print(f\"  Loading GTFS feed from {gtfs_path}...\")\n",
    "        start_time = time.time()\n",
    "        self.feed = gk.read_feed(gtfs_path, dist_units='km')\n",
    "        load_time = time.time() - start_time\n",
    "        print(f\" GTFS feed loaded in {load_time:.2f} seconds\")\n",
    "        \n",
    "        # Pre-load and cache frequently used data\n",
    "        print(\"  Pre-loading GTFS tables...\")\n",
    "        start_time = time.time()\n",
    "        self._preload_data()\n",
    "        preload_time = time.time() - start_time\n",
    "        print(f\" Data pre-loaded in {preload_time:.2f} seconds\")\n",
    "    \n",
    "    def _preload_data(self):\n",
    "        \"\"\"Pre-load and cache GTFS data with FIXED time conversion.\"\"\"\n",
    "        # Cache the main tables we'll use repeatedly\n",
    "        self.trips_df = self.feed.trips.copy()\n",
    "        self.stop_times_df = self.feed.stop_times.copy()\n",
    "        self.routes_df = self.feed.routes.copy()\n",
    "        \n",
    "        print(f\"    Loaded {len(self.trips_df):,} trips\")\n",
    "        print(f\"    Loaded {len(self.stop_times_df):,} stop times\")\n",
    "        print(f\"    Loaded {len(self.routes_df):,} routes\")\n",
    "        \n",
    "        # FIXED: Proper time conversion\n",
    "        print(\"    Converting departure times...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Convert time strings to seconds using gtfs_kit's helper function\n",
    "        print(f\"    Departure time column type: {self.stop_times_df['departure_time'].dtype}\")\n",
    "        print(f\"    Sample departure times: {self.stop_times_df['departure_time'].head(3).tolist()}\")\n",
    "        \n",
    "        # Always convert using gtfs_kit's timestr_to_seconds function\n",
    "        def safe_timestr_to_seconds(time_str):\n",
    "            try:\n",
    "                if pd.isna(time_str):\n",
    "                    return np.nan\n",
    "                if isinstance(time_str, str):\n",
    "                    return gk.helpers.timestr_to_seconds(time_str)\n",
    "                else:\n",
    "                    # If it's already a number, assume it's seconds\n",
    "                    return float(time_str)\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "        \n",
    "        self.stop_times_df['departure_seconds'] = self.stop_times_df['departure_time'].apply(safe_timestr_to_seconds)\n",
    "        self.stop_times_df['arrival_seconds'] = self.stop_times_df['arrival_time'].apply(safe_timestr_to_seconds)\n",
    "        \n",
    "        # Check conversion success\n",
    "        valid_departures = self.stop_times_df['departure_seconds'].notna().sum()\n",
    "        total_departures = len(self.stop_times_df)\n",
    "        print(f\"    Converted {valid_departures:,}/{total_departures:,} departure times ({100*valid_departures/total_departures:.1f}%)\")\n",
    "        \n",
    "        convert_time = time.time() - start_time\n",
    "        print(f\"    Time conversion completed in {convert_time:.2f} seconds\")\n",
    "    \n",
    "    def extract_all_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract headway and metadata for all routes in the GTFS feed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"  Extracting GTFS data with {self.interval_hours}-hour intervals...\")\n",
    "            total_start = time.time()\n",
    "            \n",
    "            # Get all unique services\n",
    "            all_services = self.trips_df['service_id'].unique()\n",
    "            print(f\" Found {len(all_services)} unique services to process\")\n",
    "            \n",
    "            # Process each service with progress tracking\n",
    "            route_data_list = []\n",
    "            successful_extractions = 0\n",
    "            failed_extractions = 0\n",
    "            \n",
    "            for i, service_id in enumerate(all_services):\n",
    "                if i % 50 == 0:  # Progress update every 50 services (less frequent)\n",
    "                    elapsed = time.time() - total_start\n",
    "                    progress_pct = (i / len(all_services)) * 100\n",
    "                    if i > 0:\n",
    "                        print(f\"    Progress: {i}/{len(all_services)} ({progress_pct:.1f}%) - \"\n",
    "                              f\"Elapsed: {elapsed:.1f}s - \"\n",
    "                              f\"Success rate: {successful_extractions}/{i} ({100*successful_extractions/i:.1f}%)\")\n",
    "                \n",
    "                route_data = self._process_single_service(service_id)\n",
    "                \n",
    "                if route_data:  # Only add if processing succeeded\n",
    "                    route_data_list.append(route_data)\n",
    "                    successful_extractions += 1\n",
    "                else:\n",
    "                    failed_extractions += 1\n",
    "            \n",
    "            total_time = time.time() - total_start\n",
    "            print(f\" Successfully extracted {len(route_data_list)} routes in {total_time:.2f} seconds\")\n",
    "            print(f\"    Success rate: {successful_extractions}/{len(all_services)} ({100*successful_extractions/len(all_services):.1f}%)\")\n",
    "            print(f\"    Average time per service: {total_time/len(all_services):.3f}s\")\n",
    "            \n",
    "            if failed_extractions > 0:\n",
    "                print(f\"     {failed_extractions} services failed processing\")\n",
    "            \n",
    "            return route_data_list\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" GTFS extraction failed: {e}\")\n",
    "            print(\"Using fallback uniform headways...\")\n",
    "            return self._create_fallback_routes()\n",
    "    \n",
    "    def _process_single_service(self, service_id: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Process a single service to extract detailed time-varying headway data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get trips for this service\n",
    "            service_trips = self.trips_df[self.trips_df['service_id'] == service_id]\n",
    "            \n",
    "            if len(service_trips) == 0:\n",
    "                return None\n",
    "            \n",
    "            # Calculate average headway and time-varying headways\n",
    "            avg_headway = self._calculate_average_headway(service_id, service_trips)\n",
    "            headways_by_interval = self._calculate_time_varying_headways(service_id, service_trips, avg_headway)\n",
    "            \n",
    "            # Extract metadata from first trip's route\n",
    "            first_trip = service_trips.iloc[0]\n",
    "            route_id = first_trip['route_id']\n",
    "            route_name, agency_id, route_color = self._extract_route_metadata(route_id)\n",
    "            \n",
    "            # Calculate round-trip time\n",
    "            round_trip_time = self._calculate_round_trip_time(service_id, service_trips)\n",
    "            \n",
    "            return {\n",
    "                'service_id': service_id,\n",
    "                'route_id': route_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'headways_by_interval': headways_by_interval,\n",
    "                'route_name': route_name,\n",
    "                'agency_id': agency_id,\n",
    "                'route_color': route_color,\n",
    "                'round_trip_time': round_trip_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Only print errors for first few services to avoid spam\n",
    "            if len([s for s in self.trips_df['service_id'].unique()][:10]) and service_id in self.trips_df['service_id'].unique()[:10]:\n",
    "                print(f\"  Failed to process service {service_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _calculate_average_headway(self, service_id: str, service_trips: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Calculate average headway for a service across the entire day.\n",
    "        FIXED VERSION - handles numeric departure times properly.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(service_trips) <= 1:\n",
    "                return self.fallback_headway\n",
    "            \n",
    "            # Get departure times from pre-loaded stop_times using trip_ids\n",
    "            trip_ids = service_trips['trip_id'].tolist()\n",
    "            \n",
    "            # Use vectorized operations instead of loops\n",
    "            service_stop_times = self.stop_times_df[\n",
    "                self.stop_times_df['trip_id'].isin(trip_ids)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(service_stop_times) == 0:\n",
    "                return self.fallback_headway\n",
    "            \n",
    "            # Get first departure for each trip (minimum stop_sequence)\n",
    "            first_departures = service_stop_times.loc[\n",
    "                service_stop_times.groupby('trip_id')['stop_sequence'].idxmin()\n",
    "            ]\n",
    "            \n",
    "            # Extract departure times in seconds (now properly converted)\n",
    "            departure_times = first_departures['departure_seconds'].dropna().values\n",
    "            \n",
    "            if len(departure_times) <= 1:\n",
    "                return self.fallback_headway\n",
    "            \n",
    "            # Sort and calculate intervals\n",
    "            departure_times = np.sort(departure_times)\n",
    "            intervals = np.diff(departure_times) / 60  # Convert to minutes\n",
    "            \n",
    "            # Filter reasonable intervals (avoid overnight gaps)\n",
    "            reasonable_intervals = intervals[(intervals >= 1) & (intervals <= 180)]\n",
    "            \n",
    "            if len(reasonable_intervals) > 0:\n",
    "                return np.mean(reasonable_intervals)\n",
    "            else:\n",
    "                return self.fallback_headway\n",
    "                \n",
    "        except Exception as e:\n",
    "            return self.fallback_headway\n",
    "    \n",
    "    def _calculate_time_varying_headways(self, service_id: str, service_trips: pd.DataFrame, avg_headway: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate headway values for each time interval throughout the day.\n",
    "        FIXED VERSION - uses properly converted departure times.\n",
    "        \"\"\"\n",
    "        headways = np.full(self.n_intervals, np.nan)\n",
    "        \n",
    "        try:\n",
    "            if len(service_trips) == 0:\n",
    "                return headways\n",
    "            elif len(service_trips) == 1:\n",
    "                headways.fill(self.interval_hours * 60)\n",
    "                return headways\n",
    "            \n",
    "            # Get stop times for all trips in this service\n",
    "            trip_ids = service_trips['trip_id'].tolist()\n",
    "            service_stop_times = self.stop_times_df[\n",
    "                self.stop_times_df['trip_id'].isin(trip_ids)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(service_stop_times) == 0:\n",
    "                return headways\n",
    "            \n",
    "            # Get first departure for each trip\n",
    "            first_departures = service_stop_times.loc[\n",
    "                service_stop_times.groupby('trip_id')['stop_sequence'].idxmin()\n",
    "            ][['trip_id', 'departure_seconds']].copy()\n",
    "            \n",
    "            # Convert departure seconds to hours (now working with numbers)\n",
    "            first_departures['departure_hour'] = (first_departures['departure_seconds'] // 3600) % 24\n",
    "            first_departures = first_departures.dropna()\n",
    "            \n",
    "            if len(first_departures) == 0:\n",
    "                return headways\n",
    "            \n",
    "            # Calculate headways for each time interval using vectorized operations\n",
    "            for interval in range(self.n_intervals):\n",
    "                start_hour = interval * self.interval_hours\n",
    "                end_hour = (interval + 1) * self.interval_hours\n",
    "                \n",
    "                # Find departures in this interval\n",
    "                interval_departures = first_departures[\n",
    "                    (first_departures['departure_hour'] >= start_hour) &\n",
    "                    (first_departures['departure_hour'] < end_hour)\n",
    "                ]['departure_seconds'].values\n",
    "                \n",
    "                headways[interval] = self._calculate_interval_headway_vectorized(interval_departures, avg_headway)\n",
    "            \n",
    "            return headways\n",
    "            \n",
    "        except Exception as e:\n",
    "            headways.fill(avg_headway)\n",
    "            return headways\n",
    "    \n",
    "    def _calculate_interval_headway_vectorized(self, departure_times: np.ndarray, avg_headway: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate headway for a specific time interval using vectorized operations.\n",
    "        \"\"\"\n",
    "        if len(departure_times) >= 2:\n",
    "            # Sort departure times\n",
    "            departure_times = np.sort(departure_times)\n",
    "            \n",
    "            # Calculate intervals between consecutive departures\n",
    "            intervals = np.diff(departure_times) / 60  # Convert to minutes\n",
    "            \n",
    "            # Filter valid intervals\n",
    "            valid_intervals = intervals[intervals > 0]\n",
    "            \n",
    "            if len(valid_intervals) > 0:\n",
    "                return np.mean(valid_intervals)\n",
    "            else:\n",
    "                return avg_headway\n",
    "                \n",
    "        elif len(departure_times) == 1:\n",
    "            # Single trip - assume infrequent service\n",
    "            return self.interval_hours * 60\n",
    "        else:\n",
    "            # No trips - no service\n",
    "            return np.nan\n",
    "    \n",
    "    def _extract_route_metadata(self, route_id: str) -> Tuple[str, str, str]:\n",
    "        \"\"\"\n",
    "        Extract route metadata from the pre-loaded routes data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            route_info = self.routes_df[self.routes_df['route_id'] == route_id]\n",
    "            \n",
    "            if len(route_info) > 0:\n",
    "                route = route_info.iloc[0]\n",
    "                route_name = route.get('route_short_name', str(route_id))\n",
    "                agency_id = route.get('agency_id', 'Unknown')\n",
    "                route_color = route.get('route_color', '000000')\n",
    "                \n",
    "                # Clean up route_color (remove # if present)\n",
    "                if isinstance(route_color, str) and route_color.startswith('#'):\n",
    "                    route_color = route_color[1:]\n",
    "                    \n",
    "                return str(route_name), str(agency_id), str(route_color)\n",
    "            else:\n",
    "                return str(route_id), 'Unknown', '000000'\n",
    "                \n",
    "        except Exception as e:\n",
    "            return str(route_id), 'Unknown', '000000'\n",
    "    \n",
    "    def _calculate_round_trip_time(self, service_id: str, service_trips: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Estimate round-trip time using properly converted departure/arrival times.\n",
    "        FIXED VERSION - works with numeric time values.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(service_trips) == 0:\n",
    "                return self.default_round_trip_time\n",
    "            \n",
    "            # Get trip IDs for this service\n",
    "            trip_ids = service_trips['trip_id'].tolist()\n",
    "            \n",
    "            # Get stop times for all trips in this service\n",
    "            service_stop_times = self.stop_times_df[\n",
    "                self.stop_times_df['trip_id'].isin(trip_ids)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(service_stop_times) == 0:\n",
    "                return self.default_round_trip_time\n",
    "            \n",
    "            # Calculate trip durations using vectorized operations\n",
    "            trip_durations = []\n",
    "            \n",
    "            # Group by trip_id and calculate duration for each trip\n",
    "            for trip_id, trip_stops in service_stop_times.groupby('trip_id'):\n",
    "                if len(trip_stops) >= 2:\n",
    "                    trip_stops = trip_stops.sort_values('stop_sequence')\n",
    "                    \n",
    "                    # Get first departure and last arrival (now numeric)\n",
    "                    first_departure = trip_stops.iloc[0]['departure_seconds']\n",
    "                    last_arrival = trip_stops.iloc[-1]['arrival_seconds']\n",
    "                    \n",
    "                    if pd.notna(first_departure) and pd.notna(last_arrival):\n",
    "                        duration_minutes = (last_arrival - first_departure) / 60\n",
    "                        \n",
    "                        if duration_minutes > 0:\n",
    "                            trip_durations.append(duration_minutes)\n",
    "            \n",
    "            if len(trip_durations) > 0:\n",
    "                # Use median one-way time (robust to outliers)\n",
    "                median_one_way = np.median(trip_durations)\n",
    "                # Round-trip = 2  one-way + 15% buffer for turnaround\n",
    "                round_trip_time = median_one_way * 2 * 1.15\n",
    "                return round_trip_time\n",
    "            else:\n",
    "                return self.default_round_trip_time\n",
    "                \n",
    "        except Exception as e:\n",
    "            return self.default_round_trip_time\n",
    "    \n",
    "    def _create_fallback_routes(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Create simple uniform headway routes when extraction fails.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get unique services from pre-loaded trips\n",
    "            unique_services = self.trips_df['service_id'].unique()\n",
    "            fallback_routes = []\n",
    "            \n",
    "            for service_id in unique_services:\n",
    "                headways = np.full(self.n_intervals, self.fallback_headway)\n",
    "                \n",
    "                # Try to get basic route info\n",
    "                service_trips = self.trips_df[self.trips_df['service_id'] == service_id]\n",
    "                if len(service_trips) > 0:\n",
    "                    route_id = service_trips.iloc[0]['route_id']\n",
    "                    route_name, agency_id, route_color = self._extract_route_metadata(route_id)\n",
    "                else:\n",
    "                    route_id = service_id\n",
    "                    route_name = str(service_id)\n",
    "                    agency_id = 'Unknown'\n",
    "                    route_color = '000000'\n",
    "                \n",
    "                route_data = {\n",
    "                    'service_id': service_id,\n",
    "                    'route_id': route_id,\n",
    "                    'avg_headway': self.fallback_headway,\n",
    "                    'headways_by_interval': headways,\n",
    "                    'route_name': route_name,\n",
    "                    'agency_id': agency_id,\n",
    "                    'route_color': route_color,\n",
    "                    'round_trip_time': self.default_round_trip_time\n",
    "                }\n",
    "                \n",
    "                fallback_routes.append(route_data)\n",
    "            \n",
    "            return fallback_routes\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Even fallback route creation failed: {e}\")\n",
    "            return []\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIMIZATION CONSTRAINT MANAGER (unchanged)\n",
    "# =============================================================================\n",
    "\n",
    "class OptimizationConstraints:\n",
    "    \"\"\"Manages optimization bounds and constraints for headway variables.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 no_service_headway_value: float = 9999.0):\n",
    "        self.user_min_headway = user_min_headway\n",
    "        self.user_max_headway = user_max_headway\n",
    "        self.min_headway_multiplier = min_headway_multiplier\n",
    "        self.max_headway_multiplier = max_headway_multiplier\n",
    "        self.no_service_headway_value = no_service_headway_value\n",
    "    \n",
    "    def calculate_route_bounds(self, headways_by_interval: np.ndarray) -> Tuple[float, float]:\n",
    "        valid_headways = headways_by_interval[~np.isnan(headways_by_interval)]\n",
    "        \n",
    "        if len(valid_headways) > 0:\n",
    "            data_min = np.min(valid_headways) * self.min_headway_multiplier\n",
    "            data_max = np.max(valid_headways) * self.max_headway_multiplier\n",
    "            min_headway = max(self.user_min_headway, data_min)\n",
    "            max_headway = max(min_headway, min(self.user_max_headway, data_max))\n",
    "        else:\n",
    "            min_headway = self.user_min_headway\n",
    "            max_headway = self.user_max_headway\n",
    "            \n",
    "        return min_headway, max_headway\n",
    "    \n",
    "    def create_optimization_bounds(self, routes: List[RouteConfig]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        min_bounds = []\n",
    "        max_bounds = []\n",
    "        \n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                min_bounds.append(route.min_headway)\n",
    "                max_bounds.append(route.max_headway)\n",
    "        \n",
    "        return np.array(min_bounds), np.array(max_bounds)\n",
    "    \n",
    "    def convert_to_optimization_vector(self, routes: List[RouteConfig]) -> np.ndarray:\n",
    "        all_headways = []\n",
    "        for route in routes:\n",
    "            for headway in route.headways_by_interval:\n",
    "                if np.isnan(headway):\n",
    "                    all_headways.append(self.no_service_headway_value)\n",
    "                else:\n",
    "                    all_headways.append(headway)\n",
    "        return np.array(all_headways)\n",
    "    \n",
    "    def convert_from_optimization_vector(self, headway_vector: np.ndarray, \n",
    "                                       routes: List[RouteConfig]) -> None:\n",
    "        expected_length = sum(len(route.headways_by_interval) for route in routes)\n",
    "        if len(headway_vector) != expected_length:\n",
    "            raise ValueError(f\"Vector length mismatch: {len(headway_vector)} vs {expected_length}\")\n",
    "        \n",
    "        idx = 0\n",
    "        for route in routes:\n",
    "            for interval in range(len(route.headways_by_interval)):\n",
    "                new_headway = headway_vector[idx]\n",
    "                \n",
    "                if new_headway >= self.no_service_headway_value * 0.9:\n",
    "                    route.headways_by_interval[interval] = np.nan\n",
    "                else:\n",
    "                    route.headways_by_interval[interval] = new_headway\n",
    "                    \n",
    "                idx += 1\n",
    "\n",
    "# =============================================================================\n",
    "# VEHICLE CONSTRAINT CALCULATOR (unchanged)\n",
    "# =============================================================================\n",
    "\n",
    "class VehicleConstraintCalculator:\n",
    "    \"\"\"Calculates vehicle requirements and enforces fleet constraints.\"\"\"\n",
    "    \n",
    "    def __init__(self, routes: List[RouteConfig], no_service_threshold: float = 9999.0):\n",
    "        self.routes = routes\n",
    "        self.no_service_threshold = no_service_threshold\n",
    "        self.n_intervals = len(routes[0].headways_by_interval) if routes else 0\n",
    "        \n",
    "        # Calculate baseline vehicle requirements\n",
    "        self.baseline_vehicles_by_interval = self._calculate_baseline_vehicles()\n",
    "        self.baseline_total_vehicles = np.max(self.baseline_vehicles_by_interval)\n",
    "    \n",
    "    def _calculate_baseline_vehicles(self) -> np.ndarray:\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = route.headways_by_interval[interval]\n",
    "                if not np.isnan(headway) and headway > 0:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        vehicles_by_interval = np.zeros(self.n_intervals)\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    vehicles_by_interval[interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        return vehicles_by_interval\n",
    "    \n",
    "    def constraint_total_fleet_size(self, headway_vector: np.ndarray, \n",
    "                                  max_fleet_size: float) -> float:\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        return max_fleet_size - peak_vehicles\n",
    "    \n",
    "    def constraint_percentage_increase(self, headway_vector: np.ndarray, \n",
    "                                     max_increase_percent: float) -> float:\n",
    "        vehicles_by_interval = self.calculate_vehicles_needed(headway_vector)\n",
    "        peak_vehicles = np.max(vehicles_by_interval)\n",
    "        \n",
    "        max_allowed = self.baseline_total_vehicles * (1 + max_increase_percent / 100)\n",
    "        return max_allowed - peak_vehicles\n",
    "    \n",
    "    def constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                 agency_limits: Dict[str, float]) -> List[float]:\n",
    "        agency_vehicles = {}\n",
    "        idx = 0\n",
    "        \n",
    "        for route in self.routes:\n",
    "            agency_id = route.agency_id\n",
    "            if agency_id not in agency_vehicles:\n",
    "                agency_vehicles[agency_id] = np.zeros(self.n_intervals)\n",
    "            \n",
    "            for interval in range(self.n_intervals):\n",
    "                headway = headway_vector[idx]\n",
    "                \n",
    "                if headway < self.no_service_threshold * 0.9:\n",
    "                    vehicles_needed = route.round_trip_time / headway\n",
    "                    agency_vehicles[agency_id][interval] += vehicles_needed\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        constraints = []\n",
    "        for agency_id, limit in agency_limits.items():\n",
    "            if agency_id in agency_vehicles:\n",
    "                peak_vehicles = np.max(agency_vehicles[agency_id])\n",
    "                constraints.append(limit - peak_vehicles)\n",
    "            else:\n",
    "                constraints.append(limit)\n",
    "        \n",
    "        return constraints\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN OPTIMIZATION DATA STRUCTURE (simplified initialization)\n",
    "# =============================================================================\n",
    "\n",
    "class HeadwayOptimizationData:\n",
    "    \"\"\"Main class that coordinates all components for headway optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 gtfs_path: str,\n",
    "                 date: str = \"20230814\", \n",
    "                 interval_hours: int = 3,\n",
    "                 user_min_headway: float = 5.0,\n",
    "                 user_max_headway: float = 120.0,\n",
    "                 min_headway_multiplier: float = 0.5,\n",
    "                 max_headway_multiplier: float = 2.0,\n",
    "                 default_operating_hours: Tuple[int, int] = (6, 22),\n",
    "                 fallback_headway: float = 30.0,\n",
    "                 no_service_headway_value: float = 9999.0,\n",
    "                 default_round_trip_time: float = 60.0):\n",
    "        \"\"\"Initialize the complete optimization data structure.\"\"\"\n",
    "        # Store configuration\n",
    "        self.gtfs_path = gtfs_path\n",
    "        self.date = date\n",
    "        self.interval_hours = interval_hours\n",
    "        self.n_intervals = 24 // interval_hours\n",
    "        self.default_operating_hours = default_operating_hours\n",
    "        \n",
    "        # Initialize sub-components with timing\n",
    "        print(\"=== INITIALIZING HEADWAY OPTIMIZATION DATA STRUCTURE ===\")\n",
    "        total_start = time.time()\n",
    "        \n",
    "        # 1. GTFS Data Extraction\n",
    "        print(\"1. Creating GTFS data extractor...\")\n",
    "        extractor_start = time.time()\n",
    "        self.extractor = GTFSDataExtractor(\n",
    "            gtfs_path=gtfs_path,\n",
    "            date=date,\n",
    "            interval_hours=interval_hours,\n",
    "            fallback_headway=fallback_headway,\n",
    "            default_round_trip_time=default_round_trip_time\n",
    "        )\n",
    "        extractor_time = time.time() - extractor_start\n",
    "        print(f\"    Extractor created in {extractor_time:.2f} seconds\")\n",
    "        \n",
    "        # 2. Extract route data\n",
    "        print(\"2. Extracting route data...\")\n",
    "        extraction_start = time.time()\n",
    "        route_data_list = self.extractor.extract_all_routes()\n",
    "        extraction_time = time.time() - extraction_start\n",
    "        print(f\"    Route extraction completed in {extraction_time:.2f} seconds\")\n",
    "        \n",
    "        # 3. Constraint Management\n",
    "        print(\"3. Setting up optimization constraints...\")\n",
    "        constraints_start = time.time()\n",
    "        self.constraints = OptimizationConstraints(\n",
    "            user_min_headway=user_min_headway,\n",
    "            user_max_headway=user_max_headway,\n",
    "            min_headway_multiplier=min_headway_multiplier,\n",
    "            max_headway_multiplier=max_headway_multiplier,\n",
    "            no_service_headway_value=no_service_headway_value\n",
    "        )\n",
    "        constraints_time = time.time() - constraints_start\n",
    "        print(f\"    Constraints setup in {constraints_time:.3f} seconds\")\n",
    "        \n",
    "        # 4. Create RouteConfig objects\n",
    "        print(\"4. Creating route configurations...\")\n",
    "        config_start = time.time()\n",
    "        self.routes = []\n",
    "        for route_data in route_data_list:\n",
    "            min_headway, max_headway = self.constraints.calculate_route_bounds(\n",
    "                route_data['headways_by_interval']\n",
    "            )\n",
    "            \n",
    "            route_config = RouteConfig(\n",
    "                service_id=route_data['service_id'],\n",
    "                route_name=route_data['route_name'],\n",
    "                agency_id=route_data['agency_id'],\n",
    "                headways_by_interval=route_data['headways_by_interval'],\n",
    "                min_headway=min_headway,\n",
    "                max_headway=max_headway,\n",
    "                operating_hours=default_operating_hours,\n",
    "                route_color=route_data['route_color'],\n",
    "                interval_hours=interval_hours,\n",
    "                round_trip_time=route_data['round_trip_time']\n",
    "            )\n",
    "            \n",
    "            self.routes.append(route_config)\n",
    "        config_time = time.time() - config_start\n",
    "        print(f\"    Route configs created in {config_time:.3f} seconds\")\n",
    "        \n",
    "        # 5. Vehicle Constraint Calculator\n",
    "        print(\"5. Initializing vehicle constraint calculator...\")\n",
    "        vehicle_start = time.time()\n",
    "        self.vehicle_calculator = VehicleConstraintCalculator(\n",
    "            routes=self.routes,\n",
    "            no_service_threshold=no_service_headway_value\n",
    "        )\n",
    "        vehicle_time = time.time() - vehicle_start\n",
    "        print(f\"    Vehicle calculator initialized in {vehicle_time:.3f} seconds\")\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        print(f\" Successfully initialized optimization data for {len(self.routes)} routes\")\n",
    "        print(f\"    Total initialization time: {total_time:.2f} seconds\")\n",
    "        print(f\"    Baseline fleet size: {self.vehicle_calculator.baseline_total_vehicles:.1f} vehicles\")\n",
    "        print()\n",
    "        \n",
    "        # Timing breakdown\n",
    "        print(\"  TIMING BREAKDOWN:\")\n",
    "        print(f\"   Extractor creation: {extractor_time:.2f}s ({100*extractor_time/total_time:.1f}%)\")\n",
    "        print(f\"   Route extraction: {extraction_time:.2f}s ({100*extraction_time/total_time:.1f}%)\")\n",
    "        print(f\"   Constraints setup: {constraints_time:.3f}s ({100*constraints_time/total_time:.1f}%)\")\n",
    "        print(f\"   Route configs: {config_time:.3f}s ({100*config_time/total_time:.1f}%)\")\n",
    "        print(f\"   Vehicle calculator: {vehicle_time:.3f}s ({100*vehicle_time/total_time:.1f}%)\")\n",
    "        print()\n",
    "    \n",
    "    # Core optimization interface methods (unchanged)\n",
    "    def get_optimization_vector(self) -> np.ndarray:\n",
    "        return self.constraints.convert_to_optimization_vector(self.routes)\n",
    "    \n",
    "    def get_bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return self.constraints.create_optimization_bounds(self.routes)\n",
    "    \n",
    "    def set_headways(self, headway_vector: np.ndarray):\n",
    "        self.constraints.convert_from_optimization_vector(headway_vector, self.routes)\n",
    "    \n",
    "    def calculate_vehicles_needed(self, headway_vector: np.ndarray) -> np.ndarray:\n",
    "        return self.vehicle_calculator.calculate_vehicles_needed(headway_vector)\n",
    "    \n",
    "    def vehicle_constraint_total(self, headway_vector: np.ndarray, max_fleet_size: float) -> float:\n",
    "        return self.vehicle_calculator.constraint_total_fleet_size(headway_vector, max_fleet_size)\n",
    "    \n",
    "    def vehicle_constraint_percent_increase(self, headway_vector: np.ndarray, \n",
    "                                          max_increase_percent: float) -> float:\n",
    "        return self.vehicle_calculator.constraint_percentage_increase(headway_vector, max_increase_percent)\n",
    "    \n",
    "    def vehicle_constraint_agency_specific(self, headway_vector: np.ndarray, \n",
    "                                         agency_limits: Dict[str, float]) -> List[float]:\n",
    "        return self.vehicle_calculator.constraint_agency_specific(headway_vector, agency_limits)\n",
    "    \n",
    "    def get_route_summary(self, include_interval_details: bool = True) -> pd.DataFrame:\n",
    "        data = []\n",
    "        for route in self.routes:\n",
    "            active_headways = route.headways_by_interval[~np.isnan(route.headways_by_interval)]\n",
    "            avg_headway = np.mean(active_headways) if len(active_headways) > 0 else np.nan\n",
    "            \n",
    "            row_data = {\n",
    "                'service_id': route.service_id,\n",
    "                'route_name': route.route_name,\n",
    "                'agency': route.agency_id,\n",
    "                'avg_headway': avg_headway,\n",
    "                'min_headway': route.min_headway,\n",
    "                'max_headway': route.max_headway,\n",
    "                'intervals_with_service': np.sum(~np.isnan(route.headways_by_interval)),\n",
    "                'route_color': route.route_color,\n",
    "                'round_trip_time': route.round_trip_time\n",
    "            }\n",
    "            \n",
    "            if include_interval_details:\n",
    "                for i in range(self.n_intervals):\n",
    "                    start_hour = i * self.interval_hours\n",
    "                    end_hour = (i + 1) * self.interval_hours\n",
    "                    headway_val = route.headways_by_interval[i]\n",
    "                    row_data[f'headway_{start_hour:02d}-{end_hour:02d}h'] = headway_val\n",
    "            \n",
    "            data.append(row_data)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_interval_labels(self) -> List[str]:\n",
    "        labels = []\n",
    "        for i in range(self.n_intervals):\n",
    "            start_hour = i * self.interval_hours\n",
    "            end_hour = (i + 1) * self.interval_hours\n",
    "            labels.append(f\"{start_hour:02d}-{end_hour:02d}h\")\n",
    "        return labels\n",
    "    \n",
    "    def get_optimization_info(self) -> Dict:\n",
    "        current_vector = self.get_optimization_vector()\n",
    "        valid_headways = current_vector[current_vector < self.constraints.no_service_headway_value * 0.9]\n",
    "        no_service_count = len(current_vector) - len(valid_headways)\n",
    "        \n",
    "        return {\n",
    "            'n_routes': len(self.routes),\n",
    "            'n_intervals': self.n_intervals,\n",
    "            'interval_hours': self.interval_hours,\n",
    "            'total_variables': len(current_vector),\n",
    "            'service_periods': len(valid_headways),\n",
    "            'no_service_periods': no_service_count,\n",
    "            'service_coverage_pct': 100 * len(valid_headways) / len(current_vector) if len(current_vector) > 0 else 0,\n",
    "            'mean_headway': valid_headways.mean() if len(valid_headways) > 0 else np.nan,\n",
    "            'min_headway': valid_headways.min() if len(valid_headways) > 0 else np.nan,\n",
    "            'max_headway': valid_headways.max() if len(valid_headways) > 0 else np.nan,\n",
    "            'std_headway': valid_headways.std() if len(valid_headways) > 0 else np.nan,\n",
    "            'interval_labels': self.get_interval_labels(),\n",
    "            'user_min_headway': self.constraints.user_min_headway,\n",
    "            'user_max_headway': self.constraints.user_max_headway,\n",
    "            'baseline_total_vehicles': self.vehicle_calculator.baseline_total_vehicles,\n",
    "            'baseline_vehicles_by_interval': self.vehicle_calculator.baseline_vehicles_by_interval\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE WITH TIMING\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== CREATING HEADWAY OPTIMIZATION DATA STRUCTURE (FIXED VERSION) ===\")\n",
    "    \n",
    "    gtfs_path = '../data/external/study_area_gtfs_bus.zip'\n",
    "    \n",
    "    total_start = time.time()\n",
    "    opt_data = HeadwayOptimizationData(\n",
    "        gtfs_path=gtfs_path,\n",
    "        date=\"20230814\",\n",
    "        interval_hours=3,\n",
    "        user_min_headway=5.0,\n",
    "        user_max_headway=120.0,\n",
    "        min_headway_multiplier=0.5,\n",
    "        max_headway_multiplier=2.0,\n",
    "        default_operating_hours=(6, 22),\n",
    "        fallback_headway=30.0,\n",
    "        no_service_headway_value=9999.0,\n",
    "        default_round_trip_time=60.0\n",
    "    )\n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(f\" TOTAL PIPELINE TIME: {total_time:.2f} seconds\")\n",
    "    print(f\" Average time per route: {total_time/len(opt_data.routes):.3f} seconds\")\n",
    "    print()\n",
    "    \n",
    "    # Show summary\n",
    "    summary_df = opt_data.get_route_summary(include_interval_details=False)\n",
    "    print(\"Core route summary:\")\n",
    "    print(summary_df[['service_id', 'route_name', 'agency', 'avg_headway', 'round_trip_time']].round(1).head(10))\n",
    "    print()\n",
    "    \n",
    "    opt_info = opt_data.get_optimization_info()\n",
    "    print(\"Optimization setup:\")\n",
    "    print(f\"  Total decision variables: {opt_info['total_variables']} ({opt_info['n_routes']} routes  {opt_info['n_intervals']} intervals)\")\n",
    "    print(f\"  Time intervals: {opt_info['interval_labels']}\")\n",
    "    print(f\"  Service periods: {opt_info['service_periods']}/{opt_info['total_variables']} ({opt_info['service_coverage_pct']:.1f}%)\")\n",
    "    print(f\"  User constraints: {opt_info['user_min_headway']:.1f} - {opt_info['user_max_headway']:.1f} minutes\")\n",
    "    print(f\"  Baseline fleet size: {opt_info['baseline_total_vehicles']:.1f} vehicles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60ecbb73",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute '_format_flat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/IPython/core/formatters.py:406\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    404\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/core/frame.py:1175\u001b[39m, in \u001b[36m_repr_html_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1171\u001b[39m else:\n\u001b[32m   1172\u001b[39m     max_rows = get_option(\"display.max_rows\")\n\u001b[32m   1174\u001b[39m # when auto-detecting, so width=None and not in ipython front end\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m # check whether repr fits horizontal by actually checking\n\u001b[32m   1176\u001b[39m # the width of the rendered repr\n\u001b[32m   1177\u001b[39m buf = StringIO()\n\u001b[32m   1179\u001b[39m # only care about the stuff we'll actually print out\n\u001b[32m   1180\u001b[39m # and to_string on entire frame may be expensive\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/format.py:1074\u001b[39m, in \u001b[36mto_html\u001b[39m\u001b[34m(self, buf, encoding, classes, notebook, border, table_id, render_links)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:88\u001b[39m, in \u001b[36mHTMLFormatter.to_string\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lines):\n\u001b[32m     90\u001b[39m         lines = [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:644\u001b[39m, in \u001b[36mNotebookFormatter.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28mself\u001b[39m.write(\u001b[33m\"\u001b[39m\u001b[33m<div>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    643\u001b[39m \u001b[38;5;28mself\u001b[39m.write_style()\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[38;5;28mself\u001b[39m.write(\u001b[33m\"\u001b[39m\u001b[33m</div>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.elements\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:94\u001b[39m, in \u001b[36mHTMLFormatter.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.should_show_dimensions:\n\u001b[32m     97\u001b[39m         by = \u001b[38;5;28mchr\u001b[39m(\u001b[32m215\u001b[39m)  \u001b[38;5;66;03m#   # noqa: RUF003\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:267\u001b[39m, in \u001b[36mHTMLFormatter._write_table\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mself\u001b[39m.write(\n\u001b[32m    262\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<table\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mborder_attr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(_classes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_section\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    263\u001b[39m     indent,\n\u001b[32m    264\u001b[39m )\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.header \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_row_idx_names:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindent_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;28mself\u001b[39m._write_body(indent + \u001b[38;5;28mself\u001b[39m.indent_delta)\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.write(\u001b[33m\"\u001b[39m\u001b[33m</table>\u001b[39m\u001b[33m\"\u001b[39m, indent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:403\u001b[39m, in \u001b[36mHTMLFormatter._write_header\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28mself\u001b[39m.write(\u001b[33m\"\u001b[39m\u001b[33m<thead>\u001b[39m\u001b[33m\"\u001b[39m, indent)\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.header:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_col_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindent_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_row_idx_names:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m._write_row_header(indent + \u001b[38;5;28mself\u001b[39m.indent_delta)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:383\u001b[39m, in \u001b[36mHTMLFormatter._write_col_header\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    382\u001b[39m         row.append(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m row.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_columns_formatted_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    384\u001b[39m align = \u001b[38;5;28mself\u001b[39m.fmt.justify\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_truncated_horizontally:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transit_opt_env/lib/python3.12/site-packages/pandas/io/formats/html.py:611\u001b[39m, in \u001b[36mNotebookFormatter._get_columns_formatted_values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_columns_formatted_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    610\u001b[39m     \u001b[38;5;66;03m# only reached with non-Multi Index\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_format_flat\u001b[49m(include_name=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Index' object has no attribute '_format_flat'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    service_id route_name  agency  avg_headway  min_headway  max_headway  \\\n",
       "0         1221         A1  OP6801    52.320346     5.000000        120.0   \n",
       "1         1302         A1  OP6801    59.623204     5.000000        120.0   \n",
       "2         1303         A1  OP6801    58.956044     5.769231        120.0   \n",
       "3         1304         A1  OP6801    47.879630     8.500000        120.0   \n",
       "4         1305         A1  OP6801    65.729167    11.875000        120.0   \n",
       "..         ...        ...     ...          ...          ...          ...   \n",
       "273       7986         29  OP8945   140.000000    30.000000        120.0   \n",
       "274       7987         29  OP8945    90.000000    30.000000        120.0   \n",
       "275       8242         81   OP932    28.000000    11.000000         60.0   \n",
       "276       8243         81   OP932   180.000000    90.000000        120.0   \n",
       "277       8398          9   OP932   180.000000    90.000000        120.0   \n",
       "\n",
       "     intervals_with_service route_color  round_trip_time  \n",
       "0                         7      000000             80.5  \n",
       "1                         8      000000             98.9  \n",
       "2                         4      000000             98.9  \n",
       "3                         6      000000             94.3  \n",
       "4                         4      000000             80.5  \n",
       "..                      ...         ...              ...  \n",
       "273                       3      000000            119.6  \n",
       "274                       4      000000            119.6  \n",
       "275                       4      000000            108.1  \n",
       "276                       8      000000            133.4  \n",
       "277                       8      000000            216.2  \n",
       "\n",
       "[278 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transit_opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
